"","x"
"1","A tremendous amount of time and effort has been (and continues to be) devoted to measuring democracy, or more specifically, assigning annual scores to countries on specific indicators of democracy. But what, exactly, do these scores tap? What is the nature of the underlying latent construct, democracy? Investigations of these foundational questions appear to be rare. As Munck and Verkuilen lament, “…with a few notable exceptions, quantitative researchers have paid sparse attention to the quality of the data on democracy that they analyze …To a large extent, problems of causal inference have overshadowed the equally important problems of conceptualization and measurement” (2002, 5–6). There are some important exceptions to this general observation. For instance, Bollen (1993) demonstrates validity problems with several additive indices of democracy caused by rater biases in the original assignment of values to the indicators. Gleditsch and Ward (1997) extensively describe the coarseness of the Polity index, casting doubt on the level of measurement of the scale. And Coppedge and Reinicke (1991) take greater care than most researchers in evaluating the assumptions of the additive index, constructing a Guttman scale from a set of indicators of polyarchy.         "
"2"," Munck and Verkuilen (2002) detail many of the deficiencies of current methods. We concur with their assessment and their conclusions: i.e., a good measure of democracy should identify the appropriate attributes that constitute democracy, each represented by multiple observed indicators; have a well‐conceived view of the appropriate level of measurement for the indicators and the resulting scale; and should properly aggregate the indicators into a scale without loss of information. Most applications are deficient on at least one of these counts. For instance, in selecting the number of indicators, researchers tend toward “minimalist” definitions using only a few variables, which are often insufficient to separate out different gradations of democracy (Munck and Verkuilen 2002, 10–12). Some researchers even operationalize democracy with a single indicator, seeing approaches based on multiple indicators as unnecessarily complicated (e.g., Gasiorowski 1996). However, the hope that a solitary indicator circumvents these measurement issues is illusory; indeed, most scholars agree that democracy is multifaceted, and hence not well characterized by a single indicator.         "
"3","Among scholars who operationalize democracy via multiple indicators, there is no agreement regarding how one should aggregate the information in the indicators, a data reduction task whereby we assign a score to each country‐year observation, given the scores on the indicator variables for that country‐year. The democracy scores provided by the well‐known Polity data set (Marshall and Jaggers 2002b) are combinations of indicators with an a priori specified weighting scheme. The apparent arbitrariness of the weighting/scoring scheme aside, the particular scoring rule used in Polity appears to discard much of the variation in the indicators: e.g., as Gleditsch and Ward (1997) observe, many different coding patterns across the Polity indicators are assigned the same Polity score, generating “lumpiness” in the distribution of Polity scores. Many researchers, apparently concerned by this feature of the Polity scores, reduce the Polity scores into three classifications: autocracy, anoncracy, and democracy (variations on the tripartite classification of Marshall and Jaggers 2002b, 32–33). This variation in extant measurement procedures suggests that there seems to be no settled method for aggregating indicators of democracy, or for evaluating justifications of these rules. Even some careful, rigorous investigations ignore the issue of aggregation/scoring. For instance, in a study of rater bias in coding indicators, Bollen (1993) takes the resulting additive indices as given and does not examine the question of how the indicators are aggregated to form democracy scales. Gleditsch and Ward (1997) describe many problems with Polity scores that are symptomatic of the arbitrary aggregation scheme, but do not investigate how one could improve the resulting scale. Only Coppedge and Reinicke (1991) deal directly with the aggregation issue, but their study is limited by the restrictive and deterministic assumptions of Guttman scaling.1"
"4","A final deficiency is that scholars who either create or use measures of democracy seldom confront the issue of measurement error. That is, quite aside from the arbitrariness of an ad hoc aggregation rule, almost all simple aggregations presume a completely deterministic and perfect measurement process, ignoring that each of these indicators is an imperfect representation of democracy. As Bollen observes, “it is worthwhile to point out that in the typical multiple regression model, researchers assume that their democracy measures contain no random or systematic measurement error” (1993, 1218). Since most of the indicators Bollen considers are measured with error, any composite index must also be measured with error. Thus whenever democracy appears as an explanatory variable in empirical work, there is an (almost always ignored) errors‐in‐variables problem, potentially invalidating the substantive conclusions of these studies. The consequences of measurement error in regression models are well known, yet worth briefly repeating.2 There are no adverse effects when the dependent variable is measured with error (the additional error is subsumed in the regression error), yet quite consequential effects when one of the independent variables is measured imperfectly. Estimated slopes are biased and inconsistent. With only one poorly measured variable (e.g., the democracy index), the coefficient on that variable is attenuated, while the others are biased and inconsistent in unknown direction and magnitude.3"
"5","The approach we present below explicitly confronts the fact that like any latent variable, democracy is measured with error. We show how a recent study of civil wars warrants reassessment in light of the measurement error inherent in democracy. Our contribution is to show that there are principled, statistical methods for using indicators of democracy to arrive at measures of regimes. To recapitulate, our position is that democracy is a latent variable, and cannot be measured directly, but that indicators of democracy (of varying degrees of fidelity) are available. Thus, measuring democracy is an inferential problem. Specifically, we address two questions: (1) how to best aggregate the information in the indicators, and (2) how to ensure that whatever uncertainty exists in the resulting measure or classification of democracy propagates into subsequent statistical uses of the measure. In particular, we show how to guard against a false sense of security when using measures of democracy as an independent variable in a regression analysis. Inferences about the effects of democracy on some outcome of interest should reflect the fact that democracy is a latent variable, measured via a limited number of imperfect indicators.            "
"6","Many different collections of indicators of democracy have been employed at one time or another in studies of international relations and comparative politics (see the enumeration in Munck and Verkuilen 2002). We base our empirical analysis on the extensively used measures from the Polity Project (Marshall and Jaggers 2002b). Polity IV covers the period of 1800–2000 for some 184 countries, for a total of 13,941 country‐years;4 more important, all of the indicators used to construct the aggregate measure are accessible and well documented, unlike some alternative measures. The summary measure used widely in empirical applications is a country‐year's “Polity score,” ranging from −10 to 10, created from five expert‐coded categorical indicators: (1) Competitiveness of Executive Recruitment (Xrcomp), (2) Openness of Executive Recruitment (Xropen), (3) Executive Constraints/Decision Rules (Xconst), (4) Regulation of Participation (Parreg), (5) Competitiveness of Participation (Parcomp). Table 1, adapted from Marshall et al. (2002), illustrates the contribution of each value of the indicators to the Polity score.         "
"7","A sixth variable, Regulation of Executive Recruitment (Xrreg), is not used directly in the calculation of the Polity score, but affects the coding rules for the other indicators. The six indicators sort into three categories: executive recruitment (XR), executive constraint (XCONST), and political participation (PAR), which define the alternative “concept variables” (Exrec, Exconst, and Polcomp). Exrec is constructed from Xrreg, Xrcomp, and Xropen; Polcomp is defined by Parreg and Polcomp; while Exconst is identical to Xconst. Additional information on the dataset is available in Marshall and Jaggers (2002a), but two aspects of the data are worth mentioning here. First, all of the indicators are ordinal except Xropen. Xropen = 4 (“Open”) has two different Polity contributions, depending on the value of Xrcomp. Despite being the highest category, “Open” polities are not necessarily electoral democracies, but include polities that chose chief executives by elite designation; thus, the original coding is nominal. In our discussion, the category “Open” has been split into two categories, “Open, Election”(4E) and “Open, No Election”(4NE). Second, using either the six components or the three concept variables returns the same Polity score; there is no loss of information in moving from six indicators to the three concept variables.5"
"8","The aggregation or scoring rule for the Polity index is extremely simple; usually a one category increase on any one of the ordinal indicators generates a unit increase in the Polity score. But is this the most appropriate aggregation rule for these indicators? Can the Polity indicators be treated as interval measures? Should moving from 1 to 2 on indicator j have the same contribution to the resulting measure of democracy as, say, moving from 3 to 4 on the same indicator? Moreover, do all indicators tap the latent construct (democracy) equally well? That is, should a move from 1 to 2 on indicator j have the same impact as an increase from 1 to 2 on indicator k? In short, to what extent is the aggregation rule employed by Polity supported by the data?         "
"9","We address these issues with the following statistical model. We treat democracy as a latent, continuous variable. The ordinal Polity IV indicators for each country‐year are modeled as functions of the unobserved level of democracy, via the following ordinal item‐response model. Let i= 1, … , n index country‐years and j= 1, … , m index the Polity indicators. Let k= 1, … , Kj index the (ordered) response categories for item j. Then our model is            "
"10","For the uninitiated, it may help to note that item‐response models are analogous to factor analysis models, with item‐discrimination parameters analogous to factor loadings; the similarities between the two models are elaborated in Takane and de Leeuw (1987) and Reckase (1997). That said, there are some important differences between factor analysis (as conventionally implemented) and our fully Bayesian, item‐response approach. In a Bayesian analysis, the goal is to characterize the joint posterior density of all parameters in the analysis. This means that the latent variables x are estimable and subject to inference just like any other parameters in the model. Thus, the latent variables have a different status in an item‐response model than in conventional factor analysis. The typical implementation of factor analysis is as a model for the covariance matrix of the indicators (and not for the indicators per se), without the identifying restrictions necessary to uniquely recover factor scores, and hence the multiple proposals for obtaining factor scores conditional on estimates of a factor structure (e.g., Mardia, Kent, and Bibby 1979, sec. 9.7). Contrast the item‐response approach in which the observed indicators—the “response” part of “item‐response”—are modeled directly as functions of the latent variables. Incorporating the latent variables as parameters to be estimated comes at some cost: the number of parameters to be estimated is now potentially massive (i.e., one latent trait per country‐year), but with the desktop computing resources now available to social scientists, estimating a fully Bayesian ordinal IRT (item‐response theory) model for the Polity data poses no great challenge.         "
"11","An important assumption underlying both IRT models and factor analytic models is local independence, the property that the indicators yij are conditionally independent given the latent variable xi: i.e.,               "
"12","The Polity indicators are patently not locally independent. This is clear from the sparseness of the cross‐tabulations of the Polity indicators in Table 2. Certainly, we do not expect patterns of complete independence in the table; Table 2 does not condition on the unobserved level of democracy, and since both indicators are presumably related to democracy, we should observe a relationship. Nevertheless, of the 24 possible combinations of values between Xrcomp and Xropen, only eight are observed.6 Not observing all possible combinations is hardly unusual and of itself does not constitute a violation of local independence. But in this case, the proliferation and pattern of empty cells in Table 2 clearly identifies a pattern of dependence in the coding of the two variables. Most egregiously, if Xrcomp is 0, then Xropen is always 0. Irrespective of the underlying level of democracy, if we observe Xrcomp = 0, then logically Pr(Xropen = 0) = 1. The extreme sparseness in the first row and first column suggests a deterministic relationship rather than an unlucky random draw of cases. This dependency holds for every value of both variables of Xropen and Xrcomp, resulting in a nearly diagonal distribution of the cases through Table 2. A similar pattern emerges for Parreg and Parcomp, displayed in the lower half of Table 2.            "
"13","A solution to the local independence problem is to combine the information from the six indicators, some of which are conditionally dependent, creating a smaller number of locally independent indicators. For Polity, the concept variables Exrec, Polcomp, and Exconst are three ordered indicators with 11, 12, and seven categories, which preserve the ordinal information in the six Polity indicators, yet can be considered locally independent. The resulting logistic IRT model is easily estimated via the simulation methods (Markov Chain Monte Carlo methods) described in the appendix.            "
"14"," Table 3 presents the estimated discrimination parameters and thresholds for each item. All of the items discriminate well with respect to the latent trait, with Exconst (Executive Constraints) providing the highest discrimination, and Exrec (Executive Recruitment) with the smallest discrimination parameter. None of the indicators are unrelated to the latent trait, but there is variation in item discrimination: some of the Polity indicators tap the latent trait better than others, and any scale measure based on the Polity indicators ought to reflect this (as our measure does).         "
"15","In addition to assuming equal importance of the three indicators, the Polity calculation imposes restrictive assumptions on the way movement within any given indicator contributed to the final score. In additive, linear scales (such as Polity), the ordered indicators are treated implicitly as interval measures, with the level of the underlying construct increasing linearly for every advancement to the next highest category, on any given indicator. This constitutes an extremely strong assumption, and one that is likely false, given the pattern of threshold estimates in Table 3. For instance, for the Polcomp indicator, the largest distance between thresholds occurs between categories 5 and 6, but these two categories have exactly the same Polity contribution. There are a few exceptions; for instance, our estimates suggest that collapsing 4 and 5, and 7 and 8 on Polcomp and 7 and 8 on Exrec is reasonable. Nevertheless, it is generally the case that the pattern of threshold estimates we obtain does not conform with the a priori specification of the Polity calculation.         "
"16","In Figure 1 we compare (1) the posterior means of the latent traits from our ordinal IRT model; (2) factor scores from classical factor analysis, using “regression” scoring (ignoring the ordinal nature of the indicators); and (3) the Polity IV scores themselves. For clarity and simplicity, we restrict the comparison to the year 2000. Figure 1 shows the three pairwise scatterplots among the three candidate measures in a matrix of scatterplots; above the diagonal are the Pearson correlations among the three estimates. These correlations are all very large, and we might conclude that these measures of democracy are interchangeable. However, closer inspection reveals that at any given level of Polity, there is considerable variation in the range of corresponding latent traits found by the other two methods (our ordinal IRT model and classical factor analysis), or vice versa.         "
"17","                 Comparison of Ordinal IRT Posterior Means, Factor Scores, and Polity, 2000                            Note: Line for OLS local linear regression fits (span = 1/2, tri‐cube kernel) are superimposed.                     "
"18","In particular, the S‐shaped pattern in the mapping between Polity and our IRT estimates (bottom left panel of Figure 1) reflects the artificial “top‐coding” in Polity: a score of 10 on Polity arises via the “maximum” response profile (11,12,7). This corresponds to an extremely high level on the latent scale underlying our IRT model, and the cluster of cases with this set of responses looks quite distinct from the rest of the data. Likewise at the bottom end of the Polity scale, there is considerable divergence with our estimates, due to the different weights our ordinal IRT model assigns to different indicators.         "
"19","In Table 4 we closely inspect the dispersion of Polity scores within each decile of our estimated democracy scores (again, these are the posterior means of xi in the ordinal IRT model). In just two deciles (the very top and the second to bottom) is the dispersion of Polity scores reasonably small. Elsewhere we find a wide range of Polity scores at any given level of the latent trait recovered by our model. So, although the correlation between our estimates and Polity is high, there is actually a surprising amount of divergence between the two approaches. For instance, a country‐year that we would find, say, to lie in the 60–70% range on our democracy scale could have a Polity score between −2 and 6, a range that covers 40% of the 21‐point Polity scale. Thus, if one were to treat our scores as “true scores,” then the Polity scores look somewhat unreliable.         "
"20","Of course, a key feature of our approach is that we do not have to treat our estimates of latent democracy as “true scores”: in our fully Bayesian analysis, we recover not just point estimates of latent democracy (means of the marginal posterior densities of latent levels of democracy, xi) but also confidence intervals (quantiles of the marginal posterior densities). This makes it easy to compute and assess the measurement error in each country's latent level of democracy. Although we compute estimates covering the entire data period, for clarity and simplicity we concentrate primarily on the estimates for 2000 only.            "
"21"," Figure 2 displays the estimates for all 153 countries which received Polity IV codings in 2000. Unlike the Polity scores, we are able to provide measures of uncertainty for each estimated latent score. The estimated scale ranges from Autocracy to Democracy from left to right. We summarize the marginal posterior density of each country‐year's xi with a point (the posterior mean) and a line covering a 95% highest posterior density (HPD) region.7"
"22","                 IRT Posterior Means for 2000                            Notes: Countries are ordered by their posterior means. Error bars indicate 95% highest posterior density regions.                        "
"23","The striking feature of Figure 2 is that the measurement error increases in the extremes of the latent trait distribution. Countries that are estimated to have either extremely high or extremely low levels of democracy also have substantially larger levels of measurement error. This is actually a familiar result in IRT modeling. A country receiving an extremely high set of scores on the observed indicators is like the student in our classes who correctly answers all the questions on a test: we know that the student is at the top of the class, but until we see the student start to get items wrong, we cannot put an upper bound on our estimate of the student's ability. Countries assigned the maximum/minimum scores on the Polity indicators are like these students; we know that these countries are the most/least democratic in our data, but we do not get a precise estimate of the level of democracy in these countries.            "
"24"," Figure 2 illustrates a considerable overlap in the HPD intervals for each country, suggesting that the uncertainty accompanying each estimate of the latent trait is large enough to make comparisons of latent levels of democracy difficult, in the sense that we cannot unambiguously make statements of the sort “country a has a higher level of democracy than country b.” If that is the question (and it is a perfectly proper question to ask), then Figure 2 only tells part of the story. Since the latent traits are random variables, each with a marginal posterior density, the difference between any two latent traits xi and xj is also a random variable, with a variance equal to the variance of xi plus the variance of xj minus twice the covariance between xi and xj. Figure 2 displays the pointwise confidence intervals of the latent levels of democracy, a function of the variances, but does not show anything about the covariances. To assess the precision with which we can make pairwise comparisons of levels of democracy, we compute the difference between the latent trait and that for the United States in the year 2000, i.e., δi=xi−xUS, and (of course) the uncertainty in that quantity.            "
"25","In Figure 3 we graph the equivalent of a p‐value for the one‐sided hypothesis that H0 : δi=xi−xUS > 0.8 Seventy countries, or roughly one‐half of the 153 countries available for analysis in 2000, have p‐values greater than .05, implying that we cannot distinguish their democracy score from that for the United States at a conventional 95% level of statistical significance. Figure 3 reveals that there is a large cluster of countries which have democracy levels essentially indistinguishable from the United States in 2000; these include the advanced, industrial democracies of the OECD and other countries such as Mongolia, Costa Rica, Trinidad and Tobago, and Papua New Guinea. A second set of countries is more distinguishable from the United States, but we cannot determine at typical levels of significance that the United States is assuredly more democratic. Finally, there is little doubt that the remaining countries are less democratic than the United States.            "
"26","                 Probability of Higher Democracy Score than the United States, 2000                         "
"27","So we measure democracy imperfectly, with substantial amounts of measurement error. But how consequential is this? That is, what inferential dangers are posed by using a measure of democracy in data analyses? As stated earlier, it is well known that using “noisy” variables in data analysis generates an “errors‐in‐variables” problem that will lead to biased and inconsistent parameter estimates, and potentially invalid hypothesis tests."
"28","We explore the consequences of measuring democracy with error by replicating a recent study using the Polity data. Hegre et al. (2001) test hypotheses about the relationship between levels of democracy and civil war via duration analysis. Specifically, they use a Cox proportional hazards model to analyze the effect of democracy on time until a country experiences the outbreak of civil war. Their measure of democracy comes from the Polity IIId data collection, in which regime changes are recorded to the exact day whenever possible. A key hypothesis for Hegre et al. is that regimes with intermediate levels of democracy have a higher risk of outbreak of civil war than either democracies or autocracies. Earlier work has found evidence for this “U‐shape” pattern between the occurrence or intensity of civil wars and various measures of democracy or repressiveness (e.g., de Nardo 1985; Ellingsen and Gleditsch 1997; Francisco 1995; Muller and Weede 1990). In contrast to democracies and autocracies, intermediate regimes are         "
"29","                        "
"30","… partly open yet somewhat repressive, a combination that invites protest, rebellion, and other forms of civil violence. Repression leads to grievances that induce groups to take action, and openness allows for them to organize and engage in activities against the regime. Such institutional contradictions imply a level of political incoherence, which is linked to civil conflict. (Hegre et al. 2001, 33)               "
"31","Likewise, intermediate regimes are often transitioning from autocracy to democracy, and regime change itself may be the destabilizing factor promoting civil war, rather than the intermediate level of democracy itself. Hegre et al. are careful to distinguish this possibility in their data analysis, including in their Cox regressions a control for temporal proximity to regime change. The main hypothesis—that intermediate regimes are at higher risk of civil war than either autocracies or democracies—is operationalized by including both the Polity score and its square in the Cox model. Other variables in the analysis include time since the country attained independence, a measure of ethnic heterogeneity, time since the country's last civil war, a measure of economic development (the log of energy consumption per capita, measured in coal‐ton equivalents) and its square, and an indicator of whether the country was engaged in an interstate conflict (as defined in the Correlates of War Interstate War data set); see Hegre et al. (2001) for further details.         "
"32","Our reanalysis is in two stages. First, using a data set made available by Hegre et al., we were able to exactly replicate their results as reported in their Table 2. Using the Polity measure of democracy, like Hegre et al., we found the coefficient on squared Polity score to be negative and distinguishable from zero at conventional levels of statistical significance (p < .01), while the coefficient on Polity score itself is swamped by its standard error.         "
"33","We then reanalyzed the data using our measure of democracy, as follows. We first estimate our measurement model with the Polity IIId indicators, using the recoding scheme described earlier. Then, keeping all parts of the Hegre et al. analysis intact, we merged our measure of democracy into the Hegre et al. data set.9 We then reestimated the Hegre et al. model using a Monte Carlo procedure to let uncertainty in levels of democracy propagate into inferences for the coefficients in the Cox regression model (see the appendix for details).         "
"34","In Table 5 we report results for (1) the Hegre et al. model based on the 1946–92 data, exactly replicating their results; (2) the Hegre et al. model with the Syrian observations omitted; (3) replacing the Polity scores with the posterior means from the IRT analysis; and (4) allowing uncertainty as to a country's level of democracy propagate into inferences over the coefficients in the Hegre et al. Cox model. The consequences of acknowledging the uncertainty in a country's true level of democracy are quite dramatic in this instance: the coefficient on the square of democracy is no longer distinguishable from zero at conventional levels of statistical significance, while other coefficients in the model remain largely unchanged (i.e., comparing the parameter estimates in column 4 with the corresponding estimates in column 2 of Table 5). In short, one of the chief empirical findings of the Hegre et al. analysis is not replicated after we admit the uncertainty arising from measuring democracy with the Polity indicators.         "
"35","Two distinct processes account for the way the Hegre et al. finding is not replicated with our measure. First, our reaggregation of the information in the Polity indicators creates more distinctions among countries than there are in the Polity scoring (by assigning different scores to every country with a distinct response pattern) and reorders the countries with respect to democracy. Second, in our approach, variability due to measurement uncertainty in the latent trait is dealt with explicitly, inducing additional variation in the point estimates from the duration analysis. To separate out the different effects of these two processes, we replace the Polity scores with just the posterior means from the IRT analysis, without propagating the measurement error into the duration analysis. Comparing these results (column 3, Table 5), it is apparent that the Hegre et al. findings are sensitive to our rescoring of democracy. That is, simply reaggregating the information in the Polity indicators—in a way implied by fitting a measurement model appropriate for these data—is sufficient to wash out the quadratic democracy term in the duration model. As shown in Figure 1, our model‐based scoring procedure induces more separation between countries assigned the maximum and minimum Polity values. For countries assigned midrange Polity scores, our model‐based procedure induces a more dispersed set of democracy scores. Conversely, recalling Table 4, many observations which were once separated by large distinctions on the Polity scale are much more similar according to the IRT scale. In short, the model‐based scoring rule we use to aggregate the information in the Polity indicators produces a set of democracy scores that in turn stand in a different empirical relationship with an outcome like time until civil war onset, sufficient to generate estimated marginal effects that are indistinguishable from zero.10"
"36","The comparison between columns 3 and 4 in Table 5 highlights the biases that can result when ignoring measurement error. Allowing for the propagation of measurement error into the duration analysis substantially changes the magnitude of the coefficients for democracy. The coefficient on the linear democracy term in column 4 is swamped by its estimated standard error, and the coefficient on the quadratic term is smaller than its standard error (i.e., |z| < 1). The measurement error accompanying democracy is simply so large as to render it impossible to tease out a quadratic effect on democracy in the duration analysis. This should not be surprising: the sparse amount of information in the Polity indicators means that we can confidently resolve only large differences in democracy (e.g., Figure 3), so little wonder that we fail to be able to resolve a quadratic relationship on democracy in the duration analysis.         "
"37","The lesson here is that taking Polity scores at face value is tantamount to pretending that we know more than we do about democracy, and, at least in this case, a structured approach to the measurement of democracy leads to a measure that is sufficiently different from Polity and sufficiently “noisy” to disrupt one finding in the literature. This said, we stress that our results do not falsify the U‐curve theory and are certainly not the last word in the debate about the relationship between democracy and civil war onset.11 What the results do indicate is that one's conclusions can change dramatically if we do not properly account for error in our measurements, and researchers must consider the possibility that their conclusions depend on the quality of their operationalizations.         "
"38","We also stress that this result—the propagation of uncertainty as to underlying levels of democracy leading to a statistically insignificant estimate of the effect of democracy on a dependent variable—is somewhat rare. In other replication experiments we have noted that a proper accounting of measurement uncertainty leads to a diminuation of the effect one would associate with democracy on a particular outcome, but not enough to render the estimated effect of democracy indistinguishable from zero. This is because in many applications (1) the estimated effects of democracy are very strong and can withstand any attenuation or increased parameter uncertainty due to the propagation of uncertainty arising from the imperfect measurement of democracy; and (2) the statistical models being deployed are relatively simple (e.g., a country's Polity score enters as a single linear term). Our experience is that the risks of “pretending we know more about levels of democracy than we really do” bite when researchers rely on elaborations such as nonlinear functional forms (e.g., the Hegre et al. analysis relies on democracy entering the duration analysis via a quadratic) or highly interactive specifications. In these cases, it is not surprising that the purported effects of democracy dissolve in the face of measurement uncertainty: given the uncertainty that accompanies extant measures of democracy, we simply will not be able to resolve a relatively flamboyant functional form on democracy in a regression‐type analysis. In short, there simply is not enough information in the Polity indicators to support particularly elaborate models of the way democracy structures outcomes."
"39","Even though the Polity data have been used in hundreds of studies of comparative politics and international relations, some scholars are skeptical of the properties of the measure, and rightly so. Using a formal, statistical measurement model, we show how to make best use of the Polity indicators, leveraging their strengths against one another, to obtain estimates of a given country's underlying level of democracy. Our approach—an ordinal item‐response model—improves upon the widely used Polity democracy scale in several respects. Like a factor analytic approach, we rely on the relationships among the Polity indicators to tell us how to weight each indicator's contribution to the score we assign for any given country; our item‐discrimination parameters are the equivalent of factor analysis' factor loadings. But unlike conventional factor analytic models, we embed each country's level of democracy as an unknown parameter in the measurement model, and recover not only point estimates, but also the entire joint distribution of democracy scores for all countries. Assessments of measurement error and its consequences are easily obtained via this approach. We show that there is considerable error in the latent levels of democracy underlying the Polity scores. Moreover, this measurement error is heteroskedastic; countries found to have extremely high or low levels of democracy also have the most noisy measures of democracy. The consequences are that when we use democracy as an independent variable, but ignore the noise in the democracy measure, the risk of inferential error is high. For instance, in replicating a simple duration analysis relating the level of democracy and the outbreak of civil war, we find that an apparently quadratic relationship is not robust after we properly account for the measurement error in the democracy variable."
"40","We close with two recommendations. First, it is apparent that we need more and/or better indicators of democracy. In this analysis, we rely on five indicators in the Polity data set, effectively reduced to three indicators due to inherent dependencies in the coding of the indicators. Accordingly, we are measuring democracy with a fairly blunt set of tools; contrast other measurement exercises in political science, say survey‐based measures of ideology formed from aggregating 10 to 20 self‐placement items (each with 7‐point scales), or recovering estimates of legislative preferences from roll‐call data (e.g., each session of the U.S. Congress yields hundreds or even thousands of roll calls, giving us considerable ability to distinguish legislators from one another). Consequently, in our application, any possible effect of democracy is subsumed by the overwhelming amount of uncertainty present in the democracy scores. Adding even a few more indicators could improve the reliability of democracy measures considerably. More indicators would imply greater distinctions between observations, and reduce the amount of uncertainty associated with the scores. And by utilizing an appropriate statistical model, aggregating scores involves no additional complications, unlike the problems that occur when creating additive indices."
"41","One could also complement this strategy by moving to a multiple rater system, asking area specialists to give scores on the various indicators (including the existing Polity indicators). Ward (2002) and Bollen and Paxton (2000) illustrate the variability in subjective judgments by coders, as well as potential biases that can arise. Thus, relying on the subjective judgments of one coder can be problematic. A design incorporating multiple raters would have the virtue of not only letting us leverage the indicators against one another (as we do now), but would also let us leverage expert opinions against one another.12 This would be one way of expanding the amount of data available for measuring democracy.         "
"42","Second, while a better measure of democracy is a scientific advance in and of itself, it is even more important to consider the consequences of working with a necessarily imperfect measure of democracy. The methodology we present in this article provides a simple recipe for avoiding the overoptimism that can result when working with noisy measures.13 Failing to properly acknowledge the measurement uncertainty in latent constructs risks inferential errors; scholars finding significant impacts of democracy on various dependent variables may well be wrong or (at least) guilty of overstating matters, pretending that they know more about a country's level of democracy than they really do. Whatever measure of democracy one uses, and however one derives it, we strongly recommend using methods like those we deploy here, ensuring that inferences about the effect of democracy on an outcome variable reflect the fact that a country's level of democracy is the product of an imperfect measurement process, and hence uncertain and error‐prone. Like so many concepts in social science, a country's level of democracy is a fiction of sorts, a manufactured construct, an abstraction rendered in a form amenable for data analysis: the tools we present here let us stop pretending otherwise.         "
