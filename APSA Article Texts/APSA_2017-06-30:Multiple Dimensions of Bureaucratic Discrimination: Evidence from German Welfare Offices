"","x"
"1","The equal application of the law to all citizens is a cornerstone of democratic political systems. Persistent findings of ingroup favoritism, however, highlight that equality before the state does not arise naturally from interactions of democratically minded citizens and state officials; it requires institutions to produce and maintain (Hewstone, Rubin, and Willis 2002; Jolls and Sunstein 2006). A long line of scholarship has ascribed modern state bureaucracies, characterized by their routinized and impersonal decision‐making procedures, a central role in this process (Rosanvallon 2011; Rothstein and Teorell 2008; Weber 2009). Yet, the extent to which modern bureaucracies succeed in treating all citizens fairly and equally is a question of significant debate.         "
"2","A large body of social science research has produced convincing evidence that state officials exhibit significant partiality in spheres including legal bureaucracy (Mustard 2001; Rachlinski et al. 2009), election administration (Atkeson et al. 2010; Cobb, Greiner, and Quinn 2010), and human services bureaucracy (Keiser, Mueser, and Choi 2004; Lipsky 2010). In order to isolate the causal link between ethnicity and bureaucratic behavior, recent scholarship has increasingly used field experiments. Using fictitious information requests, studies have shown that putative members of historically disadvantaged groups are less likely to receive a response from state officials in settings ranging from U.S. states to South African and Chinese bureaucracies (Butler and Broockman 2011; Distelhorst and Hou 2014; Giulietti, Tonin, and Vlassopoulos 2015; White, Nathan, and Faller 2015). Related studies show that ingroup favoritism is present in both directions: White officials in both the United States and South Africa are more likely to respond to requests from putative whites, whereas black politicians favor putative blacks (Broockman 2013; McClendon, 2016).         "
"3","The present study questions how informative response rate differentials are about substantive discrimination. Our argument is straightforward. The quality of a bureaucrat's response is inherently multidimensional—whether a response is received is only one dimension. Depending on how the multiple dimensions of quality are correlated with one another, restricting attention to response rates can produce misleading or outright false conclusions about discrimination. The bias can work in different directions: Ignoring the content of a response may lead researchers to find “false null” results of no discrimination, when discrimination is in fact present. This occurs, for example, when a minority applicant has the same likelihood of receiving a response but is given responses of substantively lower quality. Even more problematically, one group may receive more frequent but less helpful responses than another, falsely leading researchers to conclude that the group is being treated favorably when attention is restricted to response rates."
"4","To our knowledge, only two extant experimental studies have assessed response quality. White, Nathan, and Faller (2015) show that Latinos receive both fewer responses and responses of lower quality relative to putative whites when inquiring about U.S. voter ID laws. Distelhorst and Hou (2014) use a “disclosure” indicator combining response and a coding of quality as an outcome variable, and they also report descriptive data about response quality in the Appendix. In this article, we expand on these studies by discussing the relation between response rates and quality, and utilizing a preregistered measure of response quality that taps different dimensions of bureaucratic discrimination.         "
"5","Specifically, we present evidence from a conjoint experiment involving all 408 German welfare offices. After preregistering the design, hypotheses, and measurement strategy at EGAP, we sent fictional requests to all offices, in which applicants inquired about the application process for cash benefits. The requests were designed to elicit responses that are interpretable in terms of their helpfulness to the applicants. We randomly varied five traits, including the putative requester's ethnicity. We received 321 responses, a response rate of 78%. Importantly, the response rates were almost identically distributed across the treatment conditions."
"6","However, it would have been premature to conclude that no discrimination occurred. In assessing the quality of the answers, we find that putative non‐Germans (Turks and Romanians) received responses that were substantively inferior. Responses to non‐Germans score 27% lower on our main quality measure as compared to responses given to German applicants. Specifically, non‐Germans were more likely to receive responses stating that applying for cash benefits was more administratively burdensome than it is according to national policy. The results hence demonstrate that non‐Germans are not treated equally by the German social policy bureaucracy, though in a more subtle dimension than the response/nonresponse margin typically analyzed in correspondence trials."
"7","We also assess the degree to which discrimination relates to an institutional feature of the German social policy bureaucracy, whereby a minority of offices is run not by the national welfare bureaucracy but by local governments. Observational evidence indicates that discrimination is more pronounced in these types of welfare offices, suggesting that bureaucratic centralization may be helpful in reducing inequality."
"8","When applying for jobs, housing, or benefits, individuals prefer receiving a response to being ignored. Based on this logic, a growing literature uses response rates in correspondence trials to assess whether requesters of different backgrounds are being treated equally. In many cases, this empirical strategy is reasonable. When applying for a job, a callback signals employer interest. Following an ostensibly similar logic, researchers interested in discrimination by state officials have sent requests for information or help and adopted response rates as their primary outcome measure."
"9","There are at least three reasons for this decision. At the level of the individual request, it is plausible that any response is preferable to no response (though exceptions are conceivable). Moreover, whether or not a response was received can be coded transparently, and with little effort involved. Finally, analyses of response rates do not face thorny missing data problems since nonresponse is a well‐defined outcome. Taken together, these factors make response rates a simple and easily implementable measure of how willing state officials are to help applicants of different backgrounds."
"10","However, the helpfulness of replies received is likely to vary significantly. In the studies cited above, Butler and Broockman (2011) sent emails in which citizens asked legislators for help in signing up to vote, whereas Distelhorst and Hou (2014) sent emails in which citizens requested information about a basic welfare program. Even with such simple requests, many kinds of outcomes are possible, ranging from simple responses asking requesters to come to the office to a detailed explanation of the program or procedure. Bureaucrats may even go so far as to solve the problem raised by requesters entirely.         "
"11","This variation in response quality matters for the substantive question of whether some requesters receive better treatment than others. Good treatment is inherently multidimensional. This variation, however, is not considered when restricting attention to response rates. To see this, consider three stylized scenarios."
"12","In the first scenario, assume that the probability of receiving a response is positively correlated with its latent quality. Here, our concern reduces to a measurement error problem. Bureaucrats are characterized by their “helpfulness,” which may or may not be a function of the ethnicity of an applicant. Bureaucrats only respond to queries if their helpfulness exceeds a given threshold. If a response is given, its quality is increasing in the bureaucrat's helpfulness. If a subset of bureaucrats is more (or less) helpful to one ethnic group than another, this materializes as a response rate differential across the groups. The fact that quality is not fully proxied by the response dummy, then, induces measurement error. Importantly, however, differences in response rates are indicative of a helpfulness differential between ethnic groups for the average bureaucrat.         "
"13","However, suppose in a second scenario that bureaucrats are obligated to respond to every incoming query. This could be the case, for example, if there is an effective monitoring system in place and bureaucrats are held accountable by their superiors. In this scenario, response rates would be 100% across the board and hence uncorrelated with the underlying helpfulness of the bureaucrat. Yet, this does not necessarily imply that no discrimination takes place. Drafting responses and doing the requisite research requires effort. Bureaucrats might well be less likely to expend this effort when responding to one group rather than another. In a similar fashion, bureaucrats might consider some groups undeserving of help and may therefore be less likely to write helpful answers (Applebaum 2001; Van Oorschot 2006).1 Thus, although an experiment would find identical response rates across groups, this would not be indicative of equal treatment, possibly producing a misleading study result.         "
"14","Finally, consider a third scenario in which there are two types of bureaucrats: “racists” and “pro‐minority” administrators. “Racists” only respond to requests from putative majority requesters. “Pro‐minority” administrators respond to everyone, but they put extra effort into their responses to requesters from the minority group. In this scenario, minority requesters as a group get fewer but receive qualitatively superior responses than requesters from the majority group. Across groups, response rates and response quality are inversely correlated. In this situation, a correspondence trial restricting attention to response rates would find discrimination against the group with lower response rates. However, considering the divergence in response rates and response quality across groups, it would be difficult to determine which group is being discriminated against."
"15","In short, focusing exclusively on response rates in correspondence trials may be a mere measurement imperfection without problematic implications for findings (scenario 1). However, it may also lead to unwarranted or at least misleading findings of no discrimination (scenario 2) or of discrimination (scenario 3). Many more scenarios are, of course, imaginable."
"16","These arguments do not, in our view, render the literature on response rates obsolete. Its results are empirically credible, especially when interpreted narrowly: as results about response rates. However, at a minimum, additional research assessing the quality dimension of bureaucratic responsiveness in correspondence trials seems warranted."
"17","The present article focuses on the German social policy bureaucracy. Two main features render it of particular interest. First, social norms surrounding tolerance are by many accounts very strong in contemporary Germany (e.g., Art 2005; Blinder, Ford, and Ivarsflaten 2013). Second, contemporary Germany is increasingly ethnically diverse. Almost 20% of the population are either of non‐German nationality or have an immigration background (i.e., at least one migrant parent), according to the 2011 Census. Experimental research on the German labor and housing markets has found that immigrants face significant hurdles to equality (Kaas and Manger 2012; Schmid 2015). Yet, to our knowledge, no study has systematically examined discrimination against non‐Germans by the German welfare state.            "
"18","Our study focuses on a component of the German welfare state that is particularly contested: the system of means‐tested cash benefits frequently dubbed “Hartz 4”. These benefits are collected by six million individuals (about 7% of the population) and constitute the backbone of the German social safety net. In 2014, there were six million recipients, about one million of whom were non‐German nationals.2 Participating households receive, on average, 735 Euros (US$840) per month in benefits. In order to receive benefits, individuals have to present themselves at local welfare offices, which are called Jobcenter. News reports have repeatedly suggested that non‐Germans face discrimination at these offices (Grunau 2014), but there is no systematic evidence to support this hypothesis.            "
"19","In order to systematically study response quality, responses elicited by the request must be interpretable with little ambiguity and high transparency.3 After initial research, we decided to base our instrument on two questions that measure the applicant's trustworthiness in the eyes of bureaucrats, and the effort bureaucrats are willing to expend to respond to the question.4"
"20","The first question was designed to induce the bureaucrat to state a legal fact about the application process to the applicant. Specifically, the applicant—having stated that he or she lives in a shared apartment with cotenants who are his or her friends—asked whether paperwork from his or her cotenants was required when submitting an application for benefits. Importantly, rules governing the program and the welfare office website clearly state that documents about nonrelatives who are cotenants do not have to be submitted. However, applicants have an incentive to hide family or partner relationships with other members of their households to receive additional benefits. This is because total benefits are substantially higher for a group of single individuals applying individually than they would be for the same group of individuals applying as a couple or a family.5 As a result, hiding family or partnership ties in applications is a common way of “gaming the system”. Bureaucrats who mistrust non‐Germans might withhold the information that no cotenant documentation is required, believing that this signal about the simplicity of the application would encourage false declarations. However, when preparing an application, bureaucrats have to take the information provided by applicants at face value. The answer bureaucrats give to this question can therefore be interpreted as a signal about whether the bureaucrat deems the applicant trustworthy. In addition, from the applicant's perspective, a correct answer reduces the perceived logistical burden of applying.            "
"21","The second question inquired what kind of paperwork was required in order to apply for benefits. The documents required vary to some degree according to individual circumstances. Nevertheless, all applicants are required to produce a core set of documents, which includes a photo ID, a rental contract, documents on additional housing cost (heating bills, etc.), bank statements, their social security certificate, their health insurance card, and proof of income for the past three months, as well as statements relating to ownership of assets. Listing all of these documents in an email requires effort on the part of the bureaucrats. It also helps prepare prospective applicants for the application process.6"
"22","To study the effects of ethnicity and other request characteristics on response quality, the instrument randomly varied five aspects of the request: the applicant's ethnicity, gender, and skill level, as well as the formality of the email and whether the applicant mentioned a lawyer. The treatments are summarized in Table 1. The instrument is reproduced in the online supporting information (SI). Interacting these characteristics yields 48 unique types of requests, which were randomly assigned to all 408 welfare offices.            "
"23","The key treatment of interest, A, varies the applicant's putative ethnicity among three groups: Germans, Turks, and Romanians. Turks represent the largest group of immigrants in Germany (Schönwälder 2013, 637) and have long been the focus of the discourse on immigration and discrimination. Romanian migrants have only become the subject of political debate more recently in the context of free movement within the European Union.            "
"24","The second treatment, B, varies the applicant's gender, resulting in six aliases in total. We used lists of common names in Germany and in Romania, as well as among Turks in Germany, to find aliases that are reasonably similar to each other while clearly signaling ethnicity.7"
"25","The third treatment, C, varies the applicant's putative skill level. Here, we varied the profession the applicant claims to have excecised before. We chose two professions that are frequently exercised independently and relatively gender‐balanced empirically. Our choice of the skilled job was physical therapist, which requires extensive skills training and a certificate, and our choice of the unskilled job was a cleaning person.            "
"26","The fourth treatment, D, varies the formality of the request. To this end, we sent out two versions of the email. The first email contained no mistakes and was written in a relatively accurate formal and distant tone, whereas the second version included grammatical and spelling mistakes.8"
"27","For the final treatment, E, we experimented with casually mentioning a lawyer. The treatment was motivated by the fact that most applicants have very little understanding of the application process and their legal rights, weakening their position vis‐à‐vis the bureaucracy. Moreover, there is anecdotal evidence that bureaucratic behavior in German welfare offices changes in the physical presence of external counsel.            "
"28","We spelled out our main hypotheses in the preregistration document, which we briefly summarize here."
"29","Besides a general tendency to discriminate against non‐Germans, we expected foreigners to be treated differently based on their origin: Since recent public discourse made immigration from Romania highly salient and connected it explicitly to welfare use, we expected Romanians to be treated less favorably than Turks (BBC 2014).               "
"30","Given discrimination against females in the German labor market (Diekmann, Engelhardt, and Hartmann 1993), labor market integration for women might be more difficult. We therefore hypothesized that bureaucrats would focus their efforts on males, leading to higher discrimination for females.               "
"31","We expected the skills treatment to have an effect because skills are directly related to the likelihood of success in the integration programs mandated by Hartz IV, and hence to the length of participation in the welfare program.               "
"32","Besides occupational skills, the level of formality of the request is also a strong signal of basic language and writing skills, which we expected to affect responses in a similar manner.               "
"33","Although the casual mentioning of a lawyer is only a very slight hint that an applicant might be more informed about the application process and knowledgeable about his or her rights, we hypothesized that this intervention would have a positive effect on response quality.               "
"34","In addition, exploiting the conjoint nature of the experiment, we study how discrimination against non‐Germans relates to other nonethnic characteristics of the requests. This is important because it allows us to investigate whether bureaucrats discriminate simply because they dislike non‐Germans (taste‐based discrimination) or because they use ethnicity cues to infer other information about applicants (statistical discrimination; Becker 1957; Phelps 1972). If discrimination against non‐Germans were attenuated for those requests displaying higher skills and knowledge relative to other requests, this would be considered evidence of statistical discrimination.               "
"35","As described above, a particular feature of the welfare offices is that some of them are run entirely by local governments (Optionskommunen). We hypothesized that decentralization increases the room for discretion of local bureaucrats, heightening the probability that biases affect service delivery (Fording, Soss, and Schram 2011).               "
"36","Finally, we hypothesized that the formality of requests would affect the formality of responses. However, as we discuss in the preregistration document, formality is not a useful indicator of response quality since it is unclear whether formal language is a desideratum for applicants; it may both express respect and project professionalism, but also work as a deterrent. Therefore, we were primarily interested in whether responses mirrored the requests that were sent in terms of their formality.               "
"37","Our units of observation are welfare office districts, of which there were 408 in early 2015. Within a welfare office district, there is typically one main office and multiple subbranches spread throughout the district. All email addresses were manually collected directly from the districts' websites. Since 2005, local governments have been able to choose to run the welfare bureaucracy independently (Hassel and Schiller 2008)—an option 105 districts made use of in early 2015. As can be seen in Figure 5 in the supporting information, these centralized and independent agencies are fairly evenly spread across Germany, though there are some differences between federal states.            "
"38","Before rolling out the experiment, a pretest was conducted to ensure that the requests elicited meaningful responses. The pretest utilized 24 randomly sampled offices, which received the email in November 2014. The pretest induced one small change; the Turkish female name was changed from Aylin to Ayse because two bureaucrats had mistaken the alias for a male.9 The main wave of the experiment was implemented in January 2015, when the requests were sent to the remaining 384 welfare offices. Randomization was performed by blocking on whether agencies are part of the national bureaucracy or managed independently to reduce variability.10"
"39","Originally, a smaller second wave of the experiment was scheduled to be implemented a few weeks later. It would have involved emails to the subbranches in the 61 districts where multiple emails were available. However, upon reading the responses of the main wave, we noted that emails had occasionally been internally forwarded among bureaucrats within a given district. This meant that sending a similar request would have considerably increased the risk of detection. The protocol was therefore changed—a decision made before any outcomes were coded or analyzed.            "
"40","As outlined in the preregistration document, we recorded a variety of discrimination measures grouped into main outcomes and other outcomes, described in the “Balance” subsection. The three main outcome measures are the response dummy, the response quality, and the friendliness of a given response, which we discuss in turn."
"41","The first main outcome is a simple response dummy, where automatic emails from a server are excluded."
"42","Second, and most important, we constructed a substantive quality variable based on whether the two questions contained in the request were answered appropriately. The coding of this measure requires some discussion given its significance for the study. In the preregistration document, we stated that we would assign 0 points in case no response was received; 1 point if a response was received that did not contain answers to either of the two questions; 2 points if one question was answered partially; 3 points if two questions were answered partially or one question was answered fully; 4 points if one question was answered fully and the other question partially; and 5 points if both questions were answered fully. In our pre‐analysis plan, we defined full and partial answers as follows."
"43","For the cotenant question, an answer is considered full if it states that no documentation from cotenants is required, and partial if the question is acknowledged but not clearly answered."
"44","For the document question, an answer is considered full if it enumerates or includes a link to all documents required, and partial if it either includes an incomplete list of documentation or includes remarks explaining that documents have to be brought only to finalize an application, not for an initial meeting. In case any question was answered incorrectly for either of the two questions, a point was to be deducted."
"45","After implementing the experiment, we noted that the preregistered coding scheme for the document question had two shortcomings. First, it is unnecessarily coarse, lumping together answers that mention only one type of document with answers that mention seven out of eight. Second, coding whether responses explain that documents have to brought in later in the process, instead of simply counting documents, complicates both the coding process and the interpretation of the resulting measure."
"46","Since our goal is to measure the effort expended by bureaucrats and the value delivered to prospective applicants, we believe that a granular measure of the share of documents mentioned is most appropriate. To this end, we counted how many of the eight required types of documents were listed and divided the number by 4 in order to produce a range from 0 to 2. The reasoning behind this choice is that, at the margin, mentioning one additional document requires effort on behalf of bureaucrats, and helps prospective applicants prepare for the process. Below, we report results using both the preregistered measure and the new linear measure."
"47","Both measures were independently and blindly coded by the two authors. To this end, before any coding began, all emails were completely anonymized, removing any information that would have made it possible to infer an agency's treatment status. Overall, the two sets of codings yield a Pearson correlation coefficient of 0.99 for the cotenant question. For the document question, the correlation coefficient is 0.978 and 0.934, for the preregistered coding scheme and the linear coding scheme, respectively. In the empirical section, we use the average of both coders."
"48","The third main outcome is the friendliness of emails, coded subjectively by both coders on a 7‐point scale. On these measures, owing to the flexibility of the concept, inter‐coder reliability was considerably lower, with a Pearson's R of 0.22."
"49","Besides these three main outcomes, we also recorded secondary outcome measures, including whether the response contained a formal greeting or goodbye, or both; the number of spelling mistakes; the number of grammatical and punctuation mistakes; whether the emails had a formal tone (coded subjectively by both coders on a 7‐point scale, correlated at only 0.16); the length of the email; and the time it took bureaucrats to respond."
"50","Table 5 in the supporting information displays the descriptive statistics for the study. The overall response rate was 78%—an exceptionally high rate for this type of study.11 The average response time was 39 hours (Response duration), and responses were an average of 616 characters in length, excluding signatures (Response length).            "
"51","Regarding the substantive questions, the average coding of the cotenant question was 0.95 points (Cotenant average), while the average for the document question was 0.27 for the linear measure (Document linear) and 0.70 for the preregistered measure (Document PAP). We combined the scores for both questions to two comprehensive response quality indexes (Quality linear and Quality PAP).            "
"52","Of all responses, 94% contained a formal greeting (Formal greeting) and 94% contained a formal goodbye (Formal goodbye). On average, responses contained 0.2 typos (Typos) and 1.1 grammatical mistakes, including punctuation (Mistakes).            "
"53","Our subjective coding of a given email's tone was done on a scale ranging from 1 (very unfriendly) to 7 (very friendly), captured in the variables Friendliness coder 1 and Friendliness coder 2. The average score of both coders was 4.1 (i.e., the emails were friendly on average; Friendliness average). However, as mentioned above, correlations between coders were quite low. Finally, regarding Formality, the coders yielded an average 4.1 (Formality average).            "
"54","In addition to our outcome variables, Table 5 in the supporting information also reports descriptive statistics for the five pretreatment covariates at the agency level. The variables above the dotted line were preregistered; the ones below were not preregistered and are therefore not used in the empirical analysis. First, we obtained the unemployment rate at the welfare office district level from official records (Unemployment; average of 7%). Second, we indicate which of the 16 German federal states the agency is located in (State). Third, we report whether the agency is independently organized (Independent). Fourth, Migrants measures the percentage of citizens with immigration backgrounds in each district according to the 2011 Census.12 Fifth, we recorded the fraction of appeals and lawsuits against agencies that were successful (Appeals) from national welfare agency databases. We wanted to use this variable as a proxy for the legal quality of decision making but did not realize at the time of preregistration that it contains missing values in 59 districts (15% of observations). We therefore decided not to include this variable in the benchmark empirical analyses, though we conduct a detailed analysis including this variable in Tables 16 and 17 in the supporting information.            "
"55","Aside from these five preregistered control variables, we report statistics for three additional agency‐level variables: the number of email addresses posted online (Addresses; 1.5), the regional direction under which the office is organized (Region; 10 in total), and whether the office is in East Germany, that is, the former German Democratic Republic (East).            "
"56","Since randomization was faithfully executed, the distribution of covariates should be similar across treatment conditions. To assess balance, in Tables 6–8 in the supporting information, we split the samples across the five treatment conditions, again reporting the sample size, mean, and standard deviation of the eight pretreatment covariates. In SI Table 6, we split the sample along the ethnicity treatment conditions, demonstrating that there are no discernible differences across the three treatments. The final three columns report p‐values from t‐tests, testing whether the means of the variables are different. Of these, one test for the difference between the share of migrants, between the offices receiving putatively Turkish and Romanian requests, yields a marginally significant difference. In SI Table 7, we split the sample along the gender and skill treatments. Offices in the male and female conditions exhibit significant differences in their share of migrant population and their likelihood of being located in East Germany. Finally, in SI Table 8, we assess the balance across the legal backing (endorsed) and formality treatments, finding one significant deviation between informal and formal requests. We conclude that randomization produced a well‐balanced sample and report estimations with and without adjustment for covariates below.13"
"57","Our benchmark analyses estimate the effects of the five main treatments on our three main outcome measures. We estimate the following ordinary least squares (OLS) regression equation:               "
"58","Table 2 displays the main results. No treatment condition has a statistically significant effect on the response dummy (Any response). In particular, a foreign name is equally likely to receive a response compared to a German name. Female applicants are 2.1% less likely, whereas unskilled applicants are 2.8% more likely to receive a response. Applicants who do not mention a lawyer are 2.6% less likely to receive a response, and informally written emails are 4.9% less likely to be answered. None of these differences, however, are statistically significant (or marginally so).            "
"59","Importantly, the absence of significant response differences demonstrates that nonresponse is not systematically linked to treatment status. To buttress this finding, we additionally assess whether there are any treatment combinations that experience significantly lower response rates. To do so, we note that the conjoint design of the study produces 155 unique trait counterfactuals one can compare. Specifically, these combinations represent treatment counterfactuals (e.g., female vs. male), where the remaining treatments are either randomly distributed—as is the case in the models discussed thus far—or fixed at one or several specific traits (e.g., skilled male). Overall, there are 31 comparisons per treatment, which adds up to 155 unique comparisons given the five overall treatments.15"
"60","For all of the 155 combinations, we ran regressions of the unique treatment indicator on the response dummy. In Figure 1, we report p‐values from all 155 models. Only seven models yield significant differences in the response dummy. Overall, the p‐values are almost uniformly distributed. This is strong evidence, although it cannot be proven definitely, that response rates are unrelated to treatment status.            "
"61","Nonresponse Analysis"
"62","Note: The figure plots the coefficients (left figure) and p‐values (right figure) from regressions of the response dummy on all 155 unique trait counterfactuals.                        "
"63","Having established that response rates are unrelated to treatment status, we turn to our main quality outcome. As can be seen in columns 2–4 of Table 2 as well as in Figure 2, putative non‐Germans receive responses of substantively and statistically significantly lower quality. The linear measure in Model 4 yields a treatment effect estimate of 0.29.            "
"64","Quality Density"
"65","Note: Density of quality PAP and quality linear measures.                        "
"66","Models 2 and 3 present results of the coarse preregistered measure, coding nonresponses as zeroes (Model 2) or as missing (Model 3). Coding nonresponses as zeroes, as we had preregistered, would have allowed us to compare aggregate response quality across treatment conditions in the event that response rates differed between treatment conditions. Doing so comes at the expense of implicitly weighting response rates and response quality. However, as shown above, response rates are unrelated to treatment status, allowing us to focus on quality differences among responses received. In any event, the resulting point estimates are relatively similar in both models, though insignificant in Model 2 (p‐value .121). The following discussion focuses on the linear measure of response quality among responsive offices. Figure 2 displays the estimated density of response quality separately for putative Germans and foreigners, using both the linear and the preregistered quality measures.            "
"67","The female, unskilled, and unendorsed treatments also induce lower‐quality responses (0.05, 0.23, and 0.13, respectively). These differences, however, are not significant, though they are in line with Hypotheses 1–3. The difference between the skilled and unskilled conditions is marginally insignificant when using the linear measure, and marginally significant when using the preregistered measure. The difference between responses to formal and informal requests is negligible (0.02)."
"68","The additional outcomes in Models 4–6 further explore qualitative discrimination. Interestingly, we do not find that non‐German aliases receive significantly shorter emails. The estimated length reduction is a mere 47 characters. The other treatment statuses do not elicit significantly longer or shorter emails either. Indeed, the coefficients for the gender and skill treatment are in the opposite direction of our hypotheses."
"69","To further assess the relationship between length and quality, in Figure 3 we plot response quality on the y‐axis and the order response length on the x‐axis. Quality increases slightly with length, but the slope is steeper in the German condition than in the foreign conditions. This highlights the benefits of coding response quality manually as opposed to relying on simpler measures of quality, such as response length.            "
"70","Quality of Responses by Length of Email"
"71","Note: This figure plots the linear quality outcome by ethnic treatment status and email length order where 0 is shortest. The solid lines represent nonparametric LOESS curves with 95% confidence intervals in gray; the dashed lines plot the means. The upper right figure plots the length by order, demonstrating a highly similar trend across treatments. The bottom figure presents the density of the linear quality measure across treatments.                        "
"72","While a manual coding of quality has clear advantages in terms of measuring a relevant dimension of bureaucratic behavior, it also forces researchers to make decisions about coding schemes. Our preanalysis plan laid out measures designed before implementation of the experiment. However, different choices would have been similarly plausible and arguably superior, notably with regard to the document question."
"73","Table 3 investigates the robustness of our findings to alternate codings of the document question. As argued above, the linear measure is our preferred measure of response quality, since it measures both bureaucratic effort and value delivered to the prospective applicant at the margin. In contrast, the preregistered measure coarsens the information contained in the number of documents received and relies on the vague notion of “acknowledging” a question.            "
"74","Yet another approach would be to only assign points to responses that list all required documents (All or nothing), a somewhat extreme coding rule. We report the results of this measure in Models 7 and 8 and note that it does not change results appreciably. Finally, a coarsening but less extreme approach would be to separate out the many responses that list one or two essential documents (typically photo ID and/or rental contract; 1 point) from responses that list three or more documents (2 points), and those that mention no documents (0 points). This (Intermediate) approach results in slightly higher estimates, though for a dependent variable with a larger mean (1.64 as compared to 1.21 for the linear measure).            "
"75","Next, we test our hypotheses regarding friendliness and formality, the former of which was labeled a headline outcome. Columns 5–6 in Table 2 demonstrate that there are no significant differences across the five main treatments on either outcome measure. All estimates are remarkably close to zero. In column 8 of Table 2, we show that the mistakes per responses are also statistically indistinguishable across treatments, with differences remarkably close to zero across all traits.            "
"76","Taken together, we interpret these results as evidence that German welfare offices discriminate against non‐German applicants, and that they do so along the margin of response quality, not response rates."
"77","In the supporting information, we assess the robustness of these findings by estimating the same models controlling for covariates and including fixed effects (SI Table 9). The estimates are highly similar in size and significance to those reported in Table 2. Moreover, in the same table, we also run models where we drop the 24 pretest observations that were gathered two months prior to the main wave, which used a different Turkish female given name. In SI Table 11, we drop all observations from East Germany, as we had preregistered. In both cases, the estimates are essentially unchanged.            "
"78","Second, we revisit the issue of the preregistered Appeals control variable, which represents the share of successful appeals to agency decisions and is our proxy for the legal quality of decisions. Unbeknownst to us at the time of preregistration, the variable exhibits missingness in 15% of observations. In dealing with this problem, three points merit discussion. First, we note that the variable is balanced across treatment conditions (see Tables 6–8 in the supporting information). Second, in SI Table 16, we demonstrate that, regarding the quality outcome, including the Appeals variable reduces the point estimates for the foreign treatment while slightly increasing the estimates for the other treatments. However, this is driven by the smaller sample size due to the missingness, not due to its inclusion as a control. To see this, note that when repeating the analysis for the subset of observations without missingness—without including Appeals as a control—the estimates are essentially unchanged. Third, in SI Table 17, we apply mean and multiple imputation to the missing observations of the Appeals variable. Both methods recover the original estimate of around 0.3 for the foreign treatment."
"79","Finally, in the supporting information (Figures 6–9), we demonstrate that all headline estimates are corroborated when using randomization inference."
"80","When conducting multiple statistical tests, the probability of falsely rejecting a correct null hypothesis increases with every additional test—the well‐known “multiple comparisons problem” (Humphreys, de la Sierra, and Van der Windt 2013). Exactly how multiple comparisons should be accounted for is a point of significant controversy. When applying the most agnostic Bonferroni method, the p‐value of our key finding, that foreign aliases receive emails of lower quality, would be multiplied by the number of hypotheses. Assuming 15 tests (three key outcomes times five treatments), this would yield a p‐value of .435.            "
"81","The Bonferroni correction, however, is ill‐suited, as it assumes independence between tests, makes a Type 2 error more likely, and fails to incorporate priors about which treatments are likely to generate substantively meaningful effects. In summary, Bonferroni “severely reduces our power to detect an important effect,” as Gelman, Hill, and Yajima (2012, 192) write. To adjust for multiple comparisons without becoming excessively conservative with regard to Type 1 errors, Gelman, Hill, and Yajima (2012) encourage the use of Bayesian multilevel models. Such models partially pool estimates across treatments, thereby shrinking estimates toward the group‐level mean.            "
"82","To assess the robustness of our key finding, we therefore regress the five treatments on the response quality variable using the following equation:               "
"83","In our preanalysis plan, we did not explicitly assign priors for the key parameters of interest and to address the issue of multiple comparisons. The plan does, however, convey our ex ante expectation that ethnicity would affect responses, mentioning, for example, that the nonethnic treatments were added “to investigate the relationship of ethnic‐based discrimination with other social markers.” We therefore used completely agnostic (i.e., punishing) priors for the nonethnic treatments with a mean of zero and a standard deviation taken from the frequentist estimates in Model 4 in Table 2—the standard deviation was 0.126 for all nonethnic treatments. For the foreign treatment, we begin with similarly agnostic priors of zero (upper line in Figure 4), iteratively moving up to a prior on the estimate of 0.5.16 To anchor these priors in the literature, we display point estimates from two related studies, which assess discrimination against ethnic minorities along the quality margin. The first is provided by White, Nathan, and Faller (2015), who, using a similar correspondence trial, find that in the United States, Latinos receive 5.7% less accurate information when inquiring about voter discrimination than non‐Latinos. The second study is a nonexperimental audit study of welfare offices in Washington State by Ernst, Nguyen, and Taylor (2013), who find that nonwhites are 11.6% less likely to receive an explanation of a state‐run welfare program.            "
"84","Estimates for Foreign Dummy Using Bayesian Multilevel Modeling"
"85","Note: The dots represent the estimate of the foreign condition, taken from a multilevel regression of the five treatment indicators on the quality linear variable (x‐axis) under different priors for this effect (y‐axis). The lines represent 95% highest density intervals. The right graph plots the same estimates, while also adjusting the HDI for three outcomes using Bonferroni correction. We ran 10,000 iterations per model.                        "
"86","We plot the estimates and 95% highest density intervals (HDI) from the different regressions based on different priors for the foreign dummy in Figure 4. The right‐hand figure adjusts the HDI for the fact that we tested our hypotheses on three key outcome variables, relying on a Bonferroni adjustment to the HDI. The left‐hand figure does not adjust the HDI. The results indicate that the frequentist estimate for foreigners is robust to multiple comparisons when modest priors are taken into account.            "
"87","The analyses thus far have shown that foreign‐sounding aliases receive qualitatively inferior responses. Which components of the quality measure and which aliases drive this result? To answer this question, Table 4 separately analyzes responses to the cotenant question and the document question, splitting up between the foreign dummy, as well as the Turkish and Romanian names. The first four models report OLS regression without covariate adjustment; columns 4–8 add covariates and state‐level fixed effects.            "
"88","We find that all point estimates are negative across all specifications, highlighting that non‐German aliases receive inferior responses relative to German aliases. Second, comparing across questions, coefficients are much more strongly pronounced for the cotenant question than for the document question. To the extent that these questions can be thought of as tapping bureaucrats' trust (cotenant) and effort (document), the result appears consistent with discrimination based primarily on lower trust toward foreigners. Third, the response quality disadvantage is slightly larger for Turks than for Romanians, contradicting our expectation that Romanians would be more disadvantaged (Hypothesis 1).17 However, note that none of the differences in estimates are statistically significant (Gelman and Stern 2006). We also find that unskilled applicants receive lower‐quality responses to the cotenant question. This effect is roughly similar in magnitude to the ethnicity effect but not detectable in the document question and not significant in all models.            "
"89","As mentioned above, the observed differences in quality could be a result of “well‐intentioned” discrimination, whereby bureaucrats facing putative foreigners modulate their responses on the presumption that foreigners find different kinds of answers helpful. For example, a long list of required documents might deter foreign applicants from applying for benefits. However, we do not think that this concern invalidates our quality measure for two reasons. First and most importantly, if bureaucrats were intent on reducing the perceived logistical burden of applying for foreign applicants, one would expect them to reduce this burden by responding correctly to the cotenant question. However, as Table 4 shows, the quality differential between foreigners and Germans is much more pronounced for this question. Second, even assuming that the observed reduction in quality is “well intentioned,” listing fewer documents almost certainly makes the process more cumbersome. That is, even if well intentioned, such behavior would in all likelihood not be helpful to applicants.            "
"90","Next, we utilize the conjoint design of the study to parse out the interactions between the individual‐level traits. Here, we restrict our analysis to the hypotheses spelled out in the preregistration document."
"91","First, in Table 12 in the supporting information, we separate formal from informal requests. The results demonstrate that the response quality effect is higher for putatively foreign applicants with formal requests than for those with informal requests. For the latter group, the quality disadvantage is small and statistically indistinguishable from zero, whereas for the former group, requests receive a substantial reduction by 0.5 points (a statistically significant difference). This finding contradicts Hypothesis 6, which states that discrimination against foreigners is mitigated by more formal writing. Instead, the observed pattern might be explained by more formal requests reducing perceptions of applicants' need. Consistent with this possibility, unskilled applicants with formal requests receive emails of lower quality (0.4 point reduction)."
"92","Second, in Table 13 in the supporting information, we split up the sample along applicants mentioning (endo) and not mentioning lawyers (unendo). Here, our hypothesis that unendorsed foreign applicants' emails receive lower‐quality responses than endorsed foreign applicants is confirmed, though the estimates are not significantly different.            "
"93","Finally, in Table 14 in the supporting information, we parse out differences between skilled and unskilled applicants. Interestingly, skilled foreign applicants receive emails of slightly lower quality than unskilled foreign applicants.18"
"94","We now turn our attention to the bureaucratic organization of the offices under study. In particular, we hypothesized that independent welfare offices run by local governments are more likely to discriminate than those embedded in the national bureaucracy (Hypothesis 7). In Table 10 in the supporting information, the sample is split into “independent” and “centralized” offices. Recall that in centralized offices, work is jointly administered by the national welfare agency and local governments. Independent offices, on the other hand, are run entirely by the local government in a given district."
"95","Although estimate variability is high due to the small sample size (76 observations), the estimate of the quality disadvantage for foreigners in independent offices is about twice as large as in centralized offices. Two words of caution, however, are in order. First, the difference in the estimates, though sizable, is not significant. Second, the difference may be due to selection bias."
"96","Having emphasized these caveats, we report that the finding is consistent with a literature on the effects of centralized welfare administrations. Fording, Soss, and Schram (2011), for example, argue that more centralized bureaucratic arrangements are less conducive to biased behavior by officials in the United States. If bureaucrats are subject to increased monitoring and have less discretion in centralized versus decentralized arrangements, this could help explain differences in discriminatory behavior even if individual‐level bias is regionally uniform.            "
"97","This study used a conjoint experiment to assess whether German welfare offices treat requests from German and non‐German applicants equally. Relying on a request designed to elicit substantively meaningful variation in responses, the trial provided evidence that prospective benefit applicants with foreign‐sounding aliases are no less likely to receive responses in general. However, putative foreigners receive emails of significantly lower quality. The finding has two key implications for the study of discrimination in the public sphere."
"98","First, the trial overcomes what we think is an empirical shortcoming in the existing literature. By restricting attention to easily observable dimensions of interactions—above all, response rates or lengths—researchers run the risk of making potentially faulty inferences about substantive discrimination. Had the present study only measured response rates and lengths, one would have inferred that German welfare offices treat all applicants equally. However, as was shown, such a reading would have been wrong: Responses sent to putative foreigners were, on the whole, less helpful to applicants in a way that is substantively important. The reduction in quality we report plausibly affects applicants' perceptions of the burdens involved in applying for benefits, impacting their decision of whether or not to apply.19"
"99","Arguably, there is no straightforward and sensible way of determining the substantive importance of response rates relative to the information value contained in responses. But at a minimum, we believe that future studies that use information requests should attempt to measure the quality of responses in order to avoid the pitfalls we have highlighted. While it is certainly beneficial to define quality measures ex ante using preanalysis plans, the weaknesses of our preanalysis plan, which appear with the benefit of hindsight, highlight the importance of being exceedingly careful in the specification of measurements, priors, and key estimands of interest."
"100","Second, the findings give rise to an interesting substantive question, namely, why discrimination occurs along the quality and not the response dimension. This is surprising given that most previous studies have found significant response rate differentials. We see two potential explanations."
"101","On the one hand, our finding may be driven by specific aspects of bureaucratic organization. Discrimination along the quality margin instead of the response margin is arguably more difficult to detect by superiors. If German welfare office bureaucrats are subject to more stringent monitoring than bureaucrats previously studied in the literature, discriminatory bureaucrats might be inclined to discriminate on the response quality margin in order to obscure discrimination vis‐à‐vis the administration. This may explain why we do not find discrimination along the response margin. We believe that the interplay between bureaucratic organization and biases in services provision is a promising avenue for future research (Fording, Soss, and Schram 2011).         "
"102","On the other hand, the finding may be driven by a psychological mechanism, whereby biased bureaucrats may be more likely to discriminate in a fashion that is less cognitively salient to them—especially in the presence of strong antiprejudice norms. Blinder, Ford, and Ivarsflaten (2013) suggest that citizens try to control their prejudiced thoughts and actions in order to comply with such norms. However, citizens' ability to do so varies across situations. In our case, if ignoring a query is more cognitively salient as a prejudiced act than drafting a less helpful response, this might explain the divergence between the two dimensions we observe.         "
