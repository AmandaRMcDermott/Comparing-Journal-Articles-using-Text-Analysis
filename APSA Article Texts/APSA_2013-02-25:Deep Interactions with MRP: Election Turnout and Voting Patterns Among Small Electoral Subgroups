"","x"
"1","We develop the notation in the context of a general three‐way structure:"
"2","The population is defined based on three variables, taking on levels . For example, in our model of income  ethnicity  state, J=(5, 4, 51). Any individual cell in this model can be written as j=(j1, j2, j3). We index the three factors as k=1, 2, 3.            "
"3","We further suppose that each of the three factors k has Lk group‐level predictors and is thus associated with a  matrix Xk of group‐level predictors. The predictors in our example are as follows: for income (k=1), we have a  matrix X1 whose two columns correspond to a constant term and a simple index variable that takes on the values 1, 2, 3, 4, 5. For ethnicity (k=2), we only have a constant term, so X2 is a  matrix of ones. For state (k=3), we have three predictors in the vote choice model: a constant term, Republican vote share in a past presidential election, and average income in the state (we also will use the classification of states into regions, but we will get back to this later). Thus, X3 is a  matrix.            "
"4","Finally, each of our models has a binary outcome, which could be the decision of whether to vote or for which candidate to vote. In any case, we label the outcome as y and, within any cell j, we label yj as the number of Yes responses in that cell and nj as the number of Yes or No responses (excluding no‐answers and other responses). Assuming independent sampling, the data model is , where  is what we want to estimate: the proportion of Yes responses in cell j in the population.            "
"5","For some purposes we are interested in displaying the estimated 's directly, for example when mapping voter turnout or vote intention by state, with separate maps for each age and income category (see Figure 4). Other times we want to aggregate across categories, for example summing over race to estimate votes by income and state (Figure 2) or averaging nationally or over regions to focus on demographic breakdowns.            "
"6","In the latter cases, we poststratify—that is, average over groups in proportion to their size in the population. We might be averaging over the voting‐age population, or the voting‐eligible population, or the population of voters, or even a subset such as the people who voted for John McCain for president. In any case, label Nj as the relevant population in cell j, and suppose we are interested in : the average of 's within some set JS of cells. The poststratified estimate is simply               "
"7","When the Nj's are known, or are treated as known (as in the case of the voting‐age population; see the “Data Sources” section), poststratification is easy. When the Nj's are merely estimated, we continue to apply (1), this time plugging in estimates of the Nj's obtained from some preliminary analysis. This should be reasonable in our application, although in more complex settings, a fully Bayesian approach might be preferred in order to better propagate the uncertainty in the estimated group sizes (Schutt 2009). For the remainder of this article, we shall treat the Nj's as known.            "
"8","We fit a model that includes group‐level predictors as well as unexplained variation at each of the levels of the factors and their interactions. This resulting nonnested (crossed) multilevel is complicated enough that we build it up in stages."
"9","Classical logistic regression. To start, we fit a simple (nonmultilevel) model on the J cells, with cell‐level predictors derived from the group‐level predictor matrices X1, X2, X3. For each cell j (labeled with three indexes as j=(j1, j2, j3)), we start with the main effects, which comes to a constant term plus (L1−1) + (L2−1) + (L3−1) predictors (with the −1 terms coming from the duplicates of the constant term from the three design matrices). We then include all the two‐way interactions, which give (L1−1)(L2−1) + (L1−1)(L3−1) + (L2−1)(L3−1) additional predictors. In our example, these correspond to different slopes for income among Republican and Democratic states and different slopes for income among rich and poor states. The classical regression is formed by the binomial data model along with a logistic link, , where X is the combined predictor matrix constructed above.            "
"10","Multilevel regression with no group‐level predictors. If we ignore the group‐level predictors, we can form a basic multilevel logistic regression by modeling the outcome for cells j by factors for the components, j1, j2, j3:               "
"11","We can also write (2) in more general notation by summing over subsets S of :               "
"12","Multilevel model with group‐level predictors. The next step is to combine the above two models by taking the classical regression and adding the multilevel terms; this is a varying‐intercept regression (also called a mixed‐effects model):               "
"13","Multilevel model with varying slopes for group‐level predictors. The importance of particular demographic factors can vary systematically by state. For example, individual income is more strongly associated with Republican voting in rich states than in poor states. Gelman et al. (2007) fit this pattern using a varying‐intercept, varying‐slope multilevel logistic regression. Our model is more complicated than theirs, but the same principle applies: we will fit the data better by allowing regression slopes—not just intercepts—to vary by group.            "
"14","We implement by allowing each coefficient to vary by all the factors not included in the predictors. In our example, the coefficients for the state‐level predictors (Republican presidential vote share and average state income) are allowed to vary by income level and ethnicity, while the coefficient for the continuous income predictor can vary by ethnicity and state. The general form of the model combines (2) and (3) by allowing each batch of coefficients in (3) to vary by group as in (2). To write this more general form requires another stage of notation in which the coefficients for any set of group‐level predictors can be labeled  and whose components come from a distribution with mean 0 and standard deviation . This is analogous to the varying intercepts which are labeled , as before.            "
"15","Adding a multilevel model for one of the group‐level factors. The final model includes classical logistic regression as a baseline to shrink to, and then this model's coefficients vary by group (in our example, varying by ethnic group, income category, and state).            "
"16","Adding region as an additional predictor. We are already using state as one of the groups in the model, but we can add region as an additional predictor to capture effects that can be found for large areas of the country but perhaps do not have enough data to be captured by the state‐level groups that are already in the model. We do this by expanding S from the set of subsets of  to the set of subsets of , where  will now refer to the region‐level varying intercept, and including all relevant interaction terms. Because region is created as a direct mapping of state, there are no interactions between state and region (these interactions would be nonsensical and would add no additional information to the model). The final model, then, is:               "
"17","Many of our survey data come with weights. When fitting regressions to such data, it is not always necessary to include the weights. Simple unweighted regression is fine—as long as all the variables used in the weighting are included as regression predictors. The population information encoded in the survey weights enters into the analysis through the poststratification step (see Gelman 2007, for example).            "
"18","Here, however, we are modeling based on only three factors (ethnicity, income, and state), but the survey adjustments use several other variables, including sex, age, and education. Ultimately we want to fit a complex model including all these predictors, but for now we must accept that our regression does not include all the weighting variables. Thus, our model must account for variation of weights within poststratification cells."
"19","Within each cell j, we make two corrections. First, we replace the raw data estimate with , the weighted average of the outcome measure, y, within the cell. Second, we adjust the effective sample size for the measurement to account for the increased variance of a weighted average compared to a simple average, using the correction:               "
"20","Putting these together, we account for weighting by using the data model , where , and . The resulting  will not in general be integers, but we handle this by simply using the binomial likelihood function with non‐integer data, which works fine in practice (and is in fact simply the weighted log‐likelihood approach to fitting generalized linear models with weighted data). This falls in the category of quasi‐likelihood methods (Wedderburn 1974).            "
"21","We ultimately would like to perform fully Bayesian inference for our models, but for now, we have been using the approximate marginal maximum likelihood estimates obtained using the glmer() program in R (Bates and Maechler 2009). Such estimates are sometimes justified on their own theoretical and computational grounds (e.g., Skrondal and Rabe‐Hesketh 2004), but here we are considering them as approximations to fully Bayesian inference. Recent work on multilevel modeling and poststratification gives us confidence that this approach works well in estimating demographic and state‐by‐state breakdowns from national surveys (Lax and Phillips 2009a, 2009b).            "
"22","For our running example, the lmer() model looks like this:model.fit <‐ lmer(y ∼z.inc*z.incstt + z.inc*z.repprv +"
"23","(1|inc)+(1+z.inc|eth)+(1+z.inc|stt)+"
"24","(1+z.inc|reg)+"
"25","(1|inc.eth)+(1|inc.stt)+(1|inc.reg)+"
"26","(1|eth.stt)+(1|eth.reg),"
"27","family=binomial(link=“logit”))"
"28","Where the vectors here have length J= J1J2J3 and, for each element j: y is a two‐column matrix indicating the number of Democratic and Republican voters in cell j (adjusted for varying survey weights). Table 1 describes each of the variables in the computational model and lists the analogous term from the statistical model. inc, eth, and stt are index vectors running from 1–5, 1–4, and 1–51 indexing the grouping factors in the model; reg indicates the region of the country, which is mapped directly from stt; z.incstt and z.repprv are state‐level predictors of income and previous Republican vote that have been centered and rescaled (hence the “z”) and have been expanded to length J by repeating over the index stt; z.inc is the 1–5 inc index after it has been centered and rescaled (thus including it as a linear predictor as well as nonmonotonically); and reg.eth, reg.inc, stt.eth, stt.inc, and eth.inc are the interaction terms. Notice that z.incstt and z.repprv are considered part of  and  because they are included only as group‐level predictors for these variables. In contrast, z.inc is both a group‐level predictor (for the income cells) and a varying slope (for the other cells), so it is included in all of the s.            "
"29","Our model includes income as a continuous variable (through the z.inc term) and also as a categorical factor (through the inc terms). Including both in the same model allows a nonlinear fit that partially pools toward linearity, thus given both the flexibility of the categorical fit and the statistical efficiency of including a linear term for an approximately linear predictor (see section 12.6 of Gelman and Hill 2007).            "
"30","In future versions of the model, we can also include a term of the form (1 | inc.eth.stt) to allow saturated interactions. In the meantime, we estimate the residual cell‐level variance and compare it to the (design‐effect‐adjusted) binomial variance. If the residual variance is much higher than would be expected from the sampling model, this implies that three‐way interactions should be included. In the models fit for the present article, this was not the case. We have developed a freely available R package called mrp, which implements all of these steps, including the ability to fit the model with fully saturated interactions.            "
"31","When social scientists present data, they tend to use tables instead of graphs, despite the ability of graphs to translate large amounts of data in clearer and less obtrusive ways (Kastellec and Leoni 2007). This is especially true when it comes to the presentation of regression estimates. Dozens of numbers with too many digits are squeezed into a tiny space, the reader drawn to the stars showing significant effects. Substantive effect size is generally interpretable for single coefficients, but what about interactions? Two‐way interactions can sometimes be understood but are rarely teased out in any detail, and interpretability of three‐ and four‐way interactions is virtually impossible.            "
"32","We take the opposite approach here and in our research in general, viewing graphical data visualization as a key step in understanding model fit and building confidence in our inferences. Our approach is to build a full model in stages: build a simple version of the model; graph results to check fit; make the model more complex; graph results to see if and how the model fit changes; continue until reaching the final model. An example of this is Figure 1, which shows the evolution of a simple model of vote choice in the 2008 election for state  income subgroups. This is a parallel coordinates plot, showing estimates for non‐Hispanic whites only. The first panel shows the raw data; the second panel is a simple model where state coefficients are allowed to vary, but the (linear) income coefficient is held constant across states; the last panel allows the income coefficient to vary by state. Three states—MS, OH, and CT—are highlighted to show important trends.            "
"33","These simple models and visualizations reveal quite a bit about the data. In the first panel we can see that raw estimates are noisy and insufficient to reveal any clear structure, despite a sample size exceeding 15,000. The second panel indicates high state‐level variance and is suggestive that higher income is tied to higher McCain vote. The third panel shows that this simple story is insufficient: there is a wide variance in the income coefficient, with richer voters supporting McCain in Republican‐leaning states but supporting Obama in Democratic‐leaning states. This distinction is theoretically similar to (and more extreme than) the relationship between income and voting found in Gelman et al. (2008).            "
"34","We prefer the graphical strategy in general, but even more so in the present project due to the implausibility of checking each parameter estimate for each of our models and the futility in trying to do so, as deep interactions would be uninterpretable in this setting. Instead of trying to interpret regression coefficients one at a time or in conjunction, examining fitted subgroup estimates facilitates a more natural interpretation of the model. In other words, it is easier to notice when subgroup estimates seem right, while regression coefficients are more difficult to assess. For example, when we started this analysis, we knew a priori that our estimates for Obama's vote share among African American groups needed to be high, over 90%, but we could not know what regression coefficient was plausible, as the coefficient could change drastically depending on functional form.            "
"35","Another example of the power of graphical model checking is shown in Figure 2. While iteratively building our model, it became clear that there were problems in our estimates, especially as they related to ethnicity.2 These graphs represent a better way of looking at the data as a whole—they indicate McCain's share of the two‐party vote in each income/state cell, estimated for all voters (in black) and non‐Hispanic whites (in gray). While some states have similar black and gray trend lines, they diverge tremendously in some cases. Any method for fitting an elaborate model should come with procedures for evaluating it and building confidence. The state‐by‐state plots in Figure 2 are, we believe, a good start on the way to the general goal of tracing the mapping from data to inference.            "
"36","For estimates of cell population size, we use the 5% public use microsample (PUMS) of the long‐form Census for 2000, which has a sample of size 9,827,156 among voting‐age citizens. When broken down into subgroups, this yields, for instance, a weighted estimate of 4,596 white women in Kentucky aged 45–64 with college educations and incomes over $100,000, or 156 black men in North Carolina aged 30–44 with postgraduate degrees and incomes under $20,000. Because of the large sample size of the PUMS data and the fact that population‐size estimates are not our primary quantities of interest, we treat these PUMS numbers as truth. For 2004 and 2008, we use the American Community Survey (ACS), a large national sample that gives much of the same information as the long‐form Census (enough information to construct the same subgroups in each of the years). We use the 2004 ACS (N = 850,924 for voting‐age citizens) for our 2004 estimates, and we use the pooled 2005–2007 ACS (N = 6,291,316 for the same group) for our 2008 estimates. Again, for now we take the weighted ACS values as exact numbers of the voting‐age population in each subcategory.3"
"37","To construct turnout estimates, we use the Current Population Survey's (CPS) post‐election Voting and Registration supplement, conducted every two years in November and generally considered to be the gold standard on voter turnout, especially when it comes to estimating turnout for demographic subgroups. The survey does not ask people how they voted, but it asks whether they voted. We can compare the survey results, nationally and at the state level, with actual number of votes. We use Michael McDonald's “highest office” vote totals.4 The CPS comes close to these numbers. For example, 131,304,731 people voted for president in 2008, representing an estimated 57% of the voting‐age population and 62% of the voting‐eligible population. The CPS turnout estimate is 68% for voting‐age citizens. This estimate is higher than McDonald's estimates, most likely due to vote overreporting bias, but the CPS generally has less overreporting bias than other surveys like the American National Election Studies.         "
"38","For each election, we use the CPS to estimate the probability that a voting‐age citizen will turn out to vote, given his or her demographics and state of residence (N = 68,643; 79,148; and 74,327 in 2000, 2004, and 2008 after removing missing data). We know the actual number of voters for each state and perform a simple adjustment so that overall turnout matches the state totals, as follows. Let  indicate the number of voters for each state , and let S denote the set of cells such that j is in state s. We derive the adjusted turnout estimate  for each cell  as follows:            "
"39","where abs() is the absolute value function and min() is a function that finds the  that minimizes the expression. This process simply applies a constant logistic adjustment  to each cell in state s to make sure that the total number of estimated voters is correct. We assume here that overreporting bias is consistent across cells within state. Because the CPS data have a vote overreport bias,  is usually negative.         "
"40","We are interested in differences in turnout rate by demographic group, so it is important to consider whether overreport bias is consistent across demographic groups. In the 1980s, scholars investigated demographic correlates of overreporting in the American National Election Studies (ANES). Though evidence is mixed, overall there were no consistently strong relationships between demographics and overreporting, with the exception of African Americans slightly overreporting more than whites (Abramson, Anderson, and Silver 1986; Abramson and Claggett 1984; Katosh and Traugott 1981; Sigelman 1982). Bernstein, Chadha, and Montjoy (2001) revisited the data, arguing that overreporting is more likely among people who are under the most social pressure to vote, such as educated people, partisans, and minorities in minority districts, but Cassel (2003) showed that these findings are model‐specific and the effect is generally small in typical model specifications. In terms of the CPS data used in this study, McDonald (2007) recently showed that demographic descriptions of the electorate are approximately the same when using the CPS data and voter registration files, in contrast to using exit polls, which show a younger electorate with more minorities. In many ways, then, the CPS data are the “gold standard” of survey data on voter turnout.         "
"41","To construct vote choice estimates, we use the National Annenberg Election Survey in 2000 and 2004 and Pew Research pre‐election polls (N = 31,719; 43,970; and 19,170 in 2000, 2004, and 2008 after removing missing data). These surveys get large samples by aggregating rolling cross‐sections and waves conducted over several months. The model is of the same form, and we do a similar adjustment for vote choice as in equations 6 and 7 above, substituting the estimated number of voters  instead of population size Nj. Because vote choice does not suffer overreporting bias,  is usually smaller in magnitude here.         "
"42","Now that our model and graphical approach are fully described, we present examples of the type of analysis that can be done using this method. We fit numerous models using the framework described above, using the following covariates: state, region, ethnicity, income, education, and age. Eventually we want to include additional demographics such as sex, religion, number of children, and others, and we are currently working on software which will allow model fitting in this higher dimensional space."
"43","Figure 3 shows the distribution of geographic/demographic subgroups in the 2008 presidential election. In each of these graphs, the x‐ and y‐axes show McCain vote and election turnout, respectively. Moving from left to right, we add additional demographic covariates—state and ethnicity are shown on the left, family income is added in the middle,5 and age is added on the right.6 Bubbles are sized proportionally to population, and colors indicate ethnicity: white = non‐Hispanic white, black = African American, red = Hispanic, green = Other, all drawn with transparency to increase visibility.7 By the end of the full demographic expansion,  groups are plotted in on the right.            "
"44","This type of graph helps us confirm top‐level trends on race‐based voting and turnout, and it builds confidence in our estimates. The left graph shows that, as expected, African Americans in all states voted overwhelmingly for Obama. Hispanic voters and other nonwhites also voted heavily Democratic, while white voters are spread out and more likely to vote for McCain. In terms of turnout, Hispanics and Others voted less than other groups as a whole. As we add covariates, the bubbles become increasingly dispersed. Although mainstream political commentary tends to think of demographic groups (especially minorities) as homogenous voting blocs, they exhibit substantial heterogeneity. For example, consider African Americans in North Carolina. In a state that went 50–49 for Obama, they comprised roughly 20% of the population, had 72% turnout (similar to the state total of 71%), and voted for Obama 95–5. However, looking more closely we can see that the richest African Americans in North Carolina “only” voted for Obama 86–14 with a turnout of 84%, while the poorest went 97–3 with 53% turnout. These differences (11 points in vote choice and 31 points in turnout) are substantial. As another example, let us compare Hispanics to non‐Hispanic whites in New Mexico, another important swing state. As a whole, Hispanic turnout was much lower (53% compared to 74%), but there was basically no difference among the richest and most educated (89% to 93%)."
"45","The important takeaways here are that (1) there are substantial and important differences between subgroups, even within demographic categories, and (2) our method captures those differences while keeping estimates stable and reasonable. This is in line with Figure 1: there we showed that raw estimates are too noisy to be interpretable and that increasingly complicated statistical models help reveal trends in the data. Here we show the same thing with more variables included.            "
"46","One of the important features of the MRP framework is that we can look at the overall distribution of estimates as well as combine estimates in any way we please. We can, for example, combine estimates to examine shifts in vote choice for demographic/geographic subgroups. It is well known that states, when measured in the aggregate, tend to shift uniformly from election to election (Gelman and Lock 2010). This can be referred to as a homogenous partisan swing—for example, the average change in Republican vote from 1996 to 2000 was 5.6 points with a standard deviation of 3.3 (after removing Washington, DC, as an outlier). That is, after accounting for the national swing toward Bush, most states were within 3–4 points compared to their relative position in 1996. The standard deviations for the 2000–2004 and 2004–2008 swings (excluding DC) are 2.4 and 3.8, showing similar stability.            "
"47","When we break the electorate down by demographics, though, the homogenous swing breaks down. It is easy to show that there was an enormous difference between ethnicities—for example, whites had a 3.3% shift toward Obama and nonwhites had a 7.8% shift—but again a single demographic cut hides much of the variation. Figure 4 displays public opinion change among whites as a series of maps broken down by age and income. Although almost every state moved toward Obama as a whole, this graph clearly shows subgroups that resisted the aggregate electoral forces and moved toward McCain, sometimes by substantial margins. These anti‐Obama groups are mostly poorer and older white voters, especially in the South and Appalachia.8"
"48","As mentioned, our framework is not just a way to look at state‐level estimates; rather, it allows us to combine subgroups in any way we please. For the following example, we move to national trends by examining change in turnout levels from 2004 to 2008. Turnout went up as a whole this election, but the upward turnout swing was not uniform. One of the main storylines of the 2008 campaign, in fact, was Obama's ability to energize a new group of voters, especially minorities and young people. Figure 5 evaluates that claim by breaking out the turnout swing by age, ethnicity, and income. Each plot here actually shows a number of things. The histograms show the distribution of age/ethnicity group by income—going from left to right in each plot shows low to high income—while the trend line shows the turnout change. The aggregate turnout increase (3.6%) is plotted as the horizontal reference line, with another reference line at 0% change.            "
"49","The main point that we would like to highlight here is that the turnout swing was primarily driven by African Americans and young minorities. These groups are highlighted with a thick box and lines because they are the only groups with a total turnout change over 5%. Although the popular consensus would imply that young white voters also increased their turnout, that is simply not the case. Poor younger whites indeed turned out at higher rates than before, but this is a small subset of that overall group, as shown in the histograms. The incorrect interpretation that has often been given is driven by improperly combining all young people into a single group. By breaking them out, we see that there is a big difference between white young people and minority young people. Of course, our framework allows us to break this out by state and to show the final turnout levels for each subgroup, as shown in Figure 6. Young white turnout is low, hovering in the 30–40% range for most states.9 Hispanic and other ethnicities also remain low in turnout levels.            "
"50","This article has introduced and described our method for producing estimates of turnout and vote choice for deeply interacted subgroups of the population: groups that are defined by multiple demographic and geographic characteristics. Although regression models have been used for decades to infer these estimates, MRP is an improvement over traditional methods for several reasons. Multilevel modeling allows estimates to be partially pooled to take advantage of common characteristics in different parts of the electorate, while poststratification corrects for the underlying distribution of the electorate."
"51","Our method improves upon even the most recent implementations of MRP, though, by modeling deeper levels of interactions and allowing for the relationship between covariates to be nonlinear and even nonmonotonic—in other words, we let the data define the appropriate level of nonlinearity and interaction between covariates. Our method also respects the design information included in survey weights, and lastly, it makes aggregate adjustments to make sure our final estimates are reasonable. At a substantive level, we have been able to integrate the study of vote choice and turnout at a level of specificity that has not been possible before."
"52","We use MRP to make inferences in the presence of sparse data. Given that our model is necessarily imperfect, we can interpret our estimates as smoothed versions of the data. In addition to working on making the model more realistic (for example, by including nonlinearity and interactions), it makes sense at each stage to compare the MRP estimates to corresponding raw‐data summaries so that we and other consumers of the analyses can understand the effects of the modeling assumptions on the inferences."
"53","Adding these layers lets the data speak more freely to the final estimates, but it imposes challenges in interpreting the final model. As a result, we recommend a gradual and visual approach to model building: build a simple model, graph inferences, add complexity to that model in the form of additional covariates and interactions, graph, and continue until all appropriate variables are included. The purpose of intermittent graphing is to ensure that model estimates remain reasonable and that changes induced by additional covariates or interactions are understood. Because there will eventually be too many interactions to be interpreted by simply looking at the coefficients, it is important to graph final estimates as a substitute or in addition to the coefficients alone. The model builder with domain‐specific knowledge will more likely find it easier to interpret and understand final estimates—for example, among African Americans, 90% support for Obama is easier to interpret than a coefficient of 2.56, although both may infer the same thing."
"54","We have used the U.S. presidential elections of 2004 and 2008 to illustrate this process and have found a number of nonobvious trends, mainly focusing on the 2008 campaign between Barack Obama and John McCain: (1) Although demographic subgroups are often described as monolithic aggregates—especially when it comes to ethnicity—they are in fact quite diverse when broken down by other characteristics like income and education. (2) States as a whole essentially display a “homogeneous swing” between elections, but demographic subgroups within those states show more variability. (3) The Obama coalition was weakened by older, white low‐income voters who moved away from him in the election, foreshadowing the difficulty he had convincing this group to support his health care initiatives in 2009 and beyond. (4) Despite media reports to the contrary, there was not a substantial turnout swing among young white voters; in fact, most of the increase in turnout came from African Americans and other young minorities. Lastly, (5) despite modest increases, turnout among young white people and among Hispanics is still low in comparison to other demographic groups."
"55","Through this article, our focus has been both introductory and descriptive: introductory because we have provided inferences for a relatively small number of demographic/geographic combinations, and descriptive because we have only briefly touched on substantive topics as illustrations, while intentionally avoiding deep causal questions. Although these methods can certainly be used in conjunction with other tools of causal inference, the purely observational data are inappropriate for that task. We have also ignored issue opinion entirely.10 Still, given the uncertainties surrounding demographic voting trends and their interaction with state‐to‐state variation, we feel these methods can be used to derive better survey estimates and set up a firm foundation for future researchers to study fundamental questions using the best possible data.         "
