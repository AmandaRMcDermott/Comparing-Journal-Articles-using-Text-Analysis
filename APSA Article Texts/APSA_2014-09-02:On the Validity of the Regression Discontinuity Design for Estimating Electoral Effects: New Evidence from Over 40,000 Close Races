"","x"
"1","The intuitive appeal of the RD design in the analysis of elections derives from the idea that candidates who win and lose close elections should be comparable on average. This comparability depends on the assumption that the candidates or parties under consideration do not have complete control over the vote share they receive. If this were not the case (e.g., if better‐resourced candidates could examine their opponent's final vote total and then decide whether to increase their own) then the winners and losers of close elections may well differ systematically. Lee (2008) formalizes this logic, showing that a comparison of narrow winners and losers identifies the average treatment effect of winning at the threshold as long as there is an exogenous random chance component to candidates' vote shares that has a continuous density (also see Hahn, Todd, and Van der Klaauw 2001).         "
"2","A priori, the fundamental continuity assumption that implies candidates do not perfectly control the electoral outcome seems likely to be met, not just because the weather or far‐off current events can influence outcomes (a common justification offered in electoral RD studies), but also because every close election involves (at least) two candidates; the fact that no candidate can control the campaign activities of her opponent would seem to be a strong indication that she cannot perfectly control her own vote share. Nevertheless, in principle it is, of course, possible that certain types of candidates could have a degree of precise control over electoral outcomes that would render the electoral RD design invalid. For example, if incumbent candidates had a systematic ability to convert narrow losses to narrow victories through some combination of legal challenges, electoral fraud, and heroic campaign feats, then close winners and losers would no longer be comparable and the RD design might no longer identify the effect of the electoral outcome."
"3","As noted above, recent evidence suggests that winners and losers are not in fact comparable in close elections for the U.S. House of Representatives. Winners of close elections appear to be disproportionately incumbents (Snyder 2005); they also appear to be disproportionately aligned with the locally dominant party (Grimmer et al. 2012) and, among other things, have more experience and money (Caughey and Sekhon 2011). It is easy to see why such candidates would in general be more electorally successful, but it is less clear why they would disproportionately win what should be essentially coin flips, according to the theory laid out in Lee (2008).         "
"4","Figure 1 offers one view of the problem in the U.S. House of Representatives for the period from 1946 to 2010. For each 0.5 point bin of Democratic vote margin (e.g., all elections where the Democratic margin of victory was between 1.5 and 2 percentage points), we plot the proportion of cases in which a Democrat won the district in the previous election. As expected, there is a smooth, positive relationship between the Democratic margin of victory and the proportion of cases in which a Democrat was an incumbent. However, if we look at the bins immediately on either side of 0, we see a strange phenomenon. In the 59 total cases in which the Democrat won by less than half a percentage point (i.e., the first bin to the right of the threshold that is equivalent to Democratic vote percentages between 50 and 50.25), a Democrat previously won the seat almost 60% of the time; in the 54 total cases in which the Democrat lost by less than half a percentage point (i.e., the first bin to the left of the threshold that is equivalent to Democratic vote percentages between 49.75 and 50), a Democrat previously won the seat only 25% of the time. Within this sample of extremely close elections, we would expect the incumbent party to lose the seat just as often as it wins, but it appears to win a disproportionate share of close races. This highlights the exception first identified by Snyder (2005) and pursued further by Caughey and Sekhon (2011).         "
"5","What accounts for the disproportionate success of the incumbent party in close U.S. House races? Snyder (2005) interprets it as evidence of corrupt electoral manipulation, suggesting that the complexity of the process of collecting and tabulating votes in close elections leaves opportunities for incumbent candidates to somehow tamper with the results of close elections. Grimmer et al. (2012) expand on these ideas in an analysis of a longer period of U.S. House races (1880–2008), showing that (particularly in the earlier period) candidates from the party that controlled local and state offices had a similarly substantial advantage; they suggest that part of the reason why “structurally advantaged candidates” disproportionately win close elections is that they are more successful in post‐election legal battles. While conceding that a convincing explanation for this sorting remains elusive, Caughey and Sekhon (2011) point to the ability of well‐organized campaigns to obtain precise information about likely outcomes and to take extraordinary measures to secure victory in very close races.         "
"6","We return to these explanations for sorting in U.S. House elections below. For now, we note that the evidence of sorting in close U.S. House elections appears to cast doubt on the validity of RD as a strategy for measuring electoral effects not just in the U.S. House but also in a much broader class of electoral contexts. Although close U.S. House races are different in some respects from close races in most other settings (e.g., more money raised and spent, more polling conducted), there would seem to be at least as much scope for precise manipulation of outcomes in many other contexts. In legislative elections in many developing democracies, for example, electoral fraud is more common than in closely monitored U.S. House contests (Lehoucq 2003; Simpser 2013). Polling technology is less widely used in most settings where researchers are interested in using RD to measure electoral effects, but in many of these settings the electorate is much smaller, such that candidates arguably have similarly precise information about likely outcomes. The existing evidence of systematic incumbent advantages in close U.S. House elections may therefore pose a general threat to the validity of RD‐based electoral studies.         "
"7","In the subsequent sections, we assess the nature of this threat by examining evidence from other electoral settings. This evidence informs our subsequent theoretical analysis which asks what mechanisms could account for the anomalous patterns in the U.S. House."
"8","In principle, in electoral RD designs, as in other RD designs, one could check for differences between narrow winners and losers in as many pre‐election characteristics as one can measure. In assessing the validity of electoral RD designs across various political settings, we focus on the role of incumbency: does the incumbent party disproportionately win close elections? We focus on incumbency for three reasons, which we can characterize roughly as an empirical reason, a statistical reason, and a theoretical reason."
"9","The empirical reason for focusing on incumbency is that although existing studies have pointed out differences between winners and losers in a variety of characteristics, all of these differences can be viewed as proxies for incumbency. Caughey and Sekhon (2011) test for imbalances in the largest set of background covariates, showing that in addition to the incumbent party, candidates who received a higher vote share in the previous election, spent more money, or were predicted to win (among other differences), were more likely to win very close elections.6 As shown by Table 1, however, the covariates Caughey and Sekhon (2011) study are so highly correlated with the party of the incumbent that after controlling for the party of the incumbent, the evidence of imbalance in the other covariates disappears. In the leftmost column of that table, we report the full list of covariates for which Caughey and Sekhon (2011) find substantial imbalance. To document imbalance, they restrict attention to close elections (defined as those with a margin of less than half a percentage point) and compute the mean difference for each covariate between districts in which the Democrat wins and districts where the Democrat loses. The middle column (labeled “Original Specification”) reports the p‐value corresponding to their test of the null hypothesis that this expected difference is zero.7 In the rightmost column, we report p‐values from another analysis that differs only in that incumbency (i.e., “Democratic Win”) is added as a control.8 The fact that none of these p‐values is below .1 indicates the high degree of collinearity between incumbency and each of these covariates. This suggests that focusing on incumbency may be sufficient for detecting similar patterns in other electoral settings: imbalance on incumbency produces imbalance on these other variables as well, and the purported imbalances on these other variables go away once we account for incumbency.9"
"10","The statistical reason for focusing on incumbency is a concern about multiple testing. If we test for differences between winners and losers in a large enough set of variables, we will eventually find it by chance even if the assumptions underlying RD are in fact met. Future studies may seek to test other variables while applying corrections for multiple testing, but here we focus on the single variable that is purported to be the most problematic and conduct the same battery of tests across many different electoral settings."
"11","The theoretical reason for focusing on incumbency is that it confers electoral benefits in a variety of electoral settings around the world (Ariga 2010; Hainmueller and Kern 2008; Horiuchi and Leigh 2009; Katz and King 1999; Kendall and Rekkas 2012).10 Of course, in particular settings, other factors may confer systematic electoral advantages: In some local elections, for example, candidates may benefit from belonging to the party controlling a higher‐level office; in other settings, being part of a political dynasty may be particularly politically advantageous (e.g., Dal Bó, Dal Bó, and Snyder 2009; Querubin 2011). Unlike these factors, incumbency status is well defined and easily measured in all single‐seat electoral systems and is thus a natural attribute to focus on as we look for systematic differences between winners and losers of close elections.         "
"12","We analyze data for every partisan, single‐winner, plurality/majoritarian electoral setting where data could be collected and assembled. This sample includes national legislative elections in every country that has held competitive plurality elections continuously since at least 1960 and local elections in several politically significant settings. In total, we analyze 20 electoral settings in 10 different countries. The data sets are listed in Table 2; in Appendix A in the Supporting Information (SI), we provide the source of each data set and details on how we handled issues such as redistricting and multiparty competition.11 We follow Caughey and Sekhon (2011) in choosing a reference party for each setting (e.g., the Democrats in U.S. data sets; the Conservatives in U.K. data sets) and calculating vote margins and incumbency status with respect to that party of interest. The vote margin for the reference party is the difference in vote share between the party of interest and the highest finisher among the other parties. Table 2 reports the number of races in each data set (as well as in the pooled data set) where the margin of victory was less than 10, 2, and 1 percentage points. For example, a bandwidth of 1 includes all elections where the reference party won or lost by a margin of 1 point or less. In a case with only two parties, this would include all cases where the reference party won between 49.5 and 50.5% of the vote.         "
"13","Table 3 assesses whether incumbent parties disproportionately win close elections in a variety of settings. Our basic strategy is to test for an “effect” of winning an election at time t on incumbency status at time . We carry out this placebo analysis using three common RD approaches. The “difference‐in‐means” analysis compares the mean values of the placebo outcome (an indicator for whether the reference party won the previous election) in narrow windows above and below the electoral threshold.12 “Local linear” analysis similarly tests for a jump in incumbency status at the threshold where the party of interest's vote margin changes from negative to positive, but it does so by fitting linear regressions on each side of the electoral threshold to account for a potential slope of the regression function in the window around the threshold. “Polynomial” does the same thing but with a third‐order polynomial regression. For each type of analysis, we summarize the results by reporting the p‐value on the test for a jump at the threshold, using italics to signal that the placebo treatment effect is negative, (i.e. that incumbents appear to do worse). In SI Appendix B, we present these results graphically and for more specifications. Specifically, in Figures B2–B5, we present the results from the local linear specification for all possible bandwidths between 0.5 and 5. These graphs also present the point estimates for readers interested in interpreting the substantive size of the point estimates directly and show that the results are robust across many specifications.         "
"14","As expected, our tests uncover the imbalance in the U.S. House in the post‐World War II period (row 3). Previous papers have focused on the difference‐in‐means specification, and we replicate this result for other RD specifications as well. However, for the U.S. House in the previous period as well as for the U.S. House in the entire period since 1880, we fail to find evidence of incumbent advantages in any specification at the .05 level. Turning to the other U.S. contexts (i.e., statewide offices since 1946, state legislatures since 1990, and mayors since 1947), we find no evidence of an advantage for the incumbent party in any specification. This finding is particularly interesting given that existing explanations for incumbents' disproportionate success in the postwar U.S. House would seem to apply at least as strongly to these other contexts. Outside the United States, we similarly fail to find any evidence of an advantage to incumbent party candidates. Out of 96 tests shown for non‐U.S. data, we do not find a single p‐value below .05. When we pool all of the data into a single data set (bottom row of the table), we similarly find no evidence of incumbent advantages. The one case where the p‐value is below .05 is the difference‐in‐means analysis with a bandwidth of 1, but a closer investigation of this reveals that the difference‐in‐means estimate is highly biased upward, since it ignores the strong positive slope within the bandwidth (see Figure B1 in the SI appendix, which plots the relationship between lagged incumbency and the margin of victory for these close races and shows that even within a 1 percentage point bandwidth, the difference‐in‐means estimator provides a poor approximation to the limits from below and above of the regression functions toward the threshold). Given this bias, we do not view this estimate as evidence of imbalance.13"
"15","Figure 2 provides a graphical summary of the results in Table 3. In the left panel, we plot the histogram of the t‐statistics of the tests in the first column of Table 3—difference‐in‐means estimates of the difference in lagged victory rate between close winners and losers for a bandwidth of 0.5. The t‐statistics are evenly distributed around 0 except for a single outlier above 3: the U.S. House in the post‐World War II period. In the right panel, we include all of the (nonpooled) tests from Table 3. Again, the distribution appears to be roughly unimodal about 0, except for a right tail; every one of the t‐statistics greater than 1.96 comes from the U.S. House in the post‐World War II period. We present these results graphically and for many more specifications in SI Appendix B (Figures B2 and B4).         "
"16","As noted above, our placebo tests focus on (lagged) incumbency because our analysis in Table 1 suggests that incumbency accounts for most of the imbalances reported in existing studies for the U.S. House. It is good practice, however, to check for balance in the lagged running variable (Imbens and Lemieux 2008), that is, the vote margin in the previous race. Table 4 reports results of the same tests using the same format as Table 3, where the outcome is the lagged vote margin rather than lagged incumbency status. The difference‐in‐means analysis shows imbalance in the U.S. House only at the 1‐point bandwidth for the post–World War II period; in no setting is there consistent evidence of imbalance. Again, we present these results graphically and for many more specifications in SI Appendix B (Figures B3 and B5). Histograms of test statistics are displayed in Figure 3 and indicate a pattern similar to the one in Figure 2: t‐statistics appear to be drawn from a unimodal density centered about 0.         "
"17","In Table 5, we report the results of additional analyses based on the density test suggested by McCrary (2008). In these tests, we assess whether the density of incumbent party candidate vote share is smooth near the electoral threshold. We first separate each data set according to whether the party of interest previously won the seat (“Incumbent” versus “Nonincumbent”) and carry out the McCrary test separately on each series, restricting attention to cases where the margin of victory was within 10 percentage points. If incumbents disproportionately win close elections, we would expect a break in the density of the vote margin at 0—a jump up for the sample of elections in which the party of interest held the seat and a drop down for the sample of elections in which the party of interest did not hold the seat. We do not generally find this pattern; even the results for the U.S. House in the post–World War II period are only borderline significant for the “Incumbent” series. We then recombine the two subsets while flipping the sign of the vote margin for the cases in which the party of interest was not the incumbent; for this combined data set, we would expect a bulge in the density where the adjusted margin is slightly above 0, indicating that the party of interest is likely to narrowly lose when it previously lost and likely to narrowly win when it previously won. As indicated by Table 5, we cannot reject the null of no density jump for any setting except the U.S. House after 1946.         "
"18","The analysis in the previous section indicates that the apparent dominance of incumbent party candidates is limited to the U.S. House in the post–World War II period. What does this mean for the use of electoral RD designs? The most optimistic conclusion is that the disproportionate rate of success among incumbents in close House elections is the result of statistical chance, which would indicate no fundamental problem for electoral RD analysis (although researchers applying an RD to the U.S. House need to take special care). Other interpretations are possible, however. For example, one could conclude that some class of candidates is able to precisely control electoral outcomes in many settings, but that this advantaged class varies across settings. If so, we might find imbalance in incumbency status only in the U.S. House (and only in the post‐WWII period), even though the assumptions behind the electoral RD design are violated more widely."
"19","In order to clarify the significance of the imbalances in the postwar U.S. House, we briefly discuss the theoretical mechanisms through which incumbents (or other structurally advantaged candidates) could exert fine control over the outcomes of close elections. Along the way, we assess the plausibility of those mechanisms in the case of the U.S. House. In the end, we conclude that none of the current explanations for the imbalance observed in the U.S. House are satisfying. This suggests that this imbalance might be the result of chance. Nonetheless, researchers must think carefully about these potential mechanisms, whether they are present in a particular electoral setting, and whether they might bias estimates arising from future RD designs. We also use this discussion to motivate our next section, which provides a set of best practices—both theoretical and empirical—that future researchers should employ when implementing RD designs in electoral settings."
"20","Explanations for systematic advantages of incumbents (or other advantaged candidates) in close elections can be crudely divided into two categories: those that focus on pre‐election behavior, like the campaign efforts that Caughey and Sekhon (2011) discuss, and those that focus on post‐election behavior, including the processing of ballots and the recount process. We consider each type of explanation in turn.         "
"21","There are several theoretical requirements for any pre‐election explanation for imbalance. For example, advantaged candidates must have access to additional (but costly) resources that they only employ when necessary, they would have to obtain extremely precise information about their expected vote share, and the opposing campaign must lack the ability or willingness to do these same things. Here, we focus on the most salient of these requirements: information.         "
"22","Recall that the imbalance observed in the U.S. House is present for only a tiny window around the electoral threshold, where the Democratic win margin was less than 0.5 percentage points (i.e., those elections where the Democratic two‐party vote percentage is between 49.75 and 50.25). If strategic campaigning or other pre‐election behaviors explain this imbalance, then incumbent behavior must vary significantly across small changes in the expected election result. Specifically, their behavior would have to be systematically different in scenarios where they would expect vote percentages between 49.75 and 50, compared to other scenarios where they would expect vote percentages in the bins immediately outside of this range. For example, incumbents would behave differently if they expect to receive 49.9% of the two‐party vote as opposed to 49.7 or 50.1%. Perhaps at 49.9, incumbents exert extra effort in an attempt to win, but at 49.7, they know the cause is lost so they do not bother, and at 50.1, they rest assured of victory and similarly do not bother exerting extra effort. Of course, this explanation assumes that incumbents can reasonably distinguish between situations where they expect to receive 49.7, 49.9, and 50.1% of the vote. In SI Appendix C, we provide a theoretical model of campaign effort and show that incumbent campaigns would have to predict their vote shares within approximately one‐quarter of 1 percentage point (at most), on average, in order for pre‐election behavior to explain the pattern of imbalance that we observe in the U.S. House."
"23","The realities of political polling and congressional campaigns cast serious doubt on the ability of candidates to obtain such precise expectations. Enos and Hersh (2013) provide evidence on the precision of campaign expectations by surveying Democratic candidates and campaign operatives in the run‐up to the 2012 general election. On average, campaign workers mispredict their vote share by 8 percentage points, and this lack of precision does not vary meaningfully across the status of the campaign worker (candidates and high‐level managers are no better than volunteers and lower‐level workers), the competitiveness of the race, the time until the election, or incumbent versus challenger campaigns. For the five “toss‐up” U.S. House races where Enos and Hersh (2013) surveyed the incumbent campaign, the operatives mis‐predicted the election result by 10 percentage points, on average. Statistical models reveal similar levels of uncertainty about the outcomes of close elections. Klarner (2008) generates race‐by‐race predictions for the two‐party vote share in every contested House election in 2008. On average, for contested races, these predictions miss the actual election result by 4.3 percentage points, and the average error exceeds 6 percentage points for the most competitive races. Likewise, the final poll or even the average of many late polls in a close U.S. House race in 2012, on average, missed the actual election result by about 2 percentage points.14 With this information available, then, congressional candidates can hardly tell the difference between situations where they are likely to lose narrowly and those where they are likely to win narrowly. In fact, because election outcomes are so uncertain, modern campaign managers and consultants often aim for 52% of the two‐party vote.15 We do not know how they decided upon this magic number, but the fact that these campaigns do not target the actual threshold suggests that campaign activity is unlikely to explain the precise imbalance.         "
"24","Post‐election explanations for imbalance—revolving around court cases, recounts, post‐election fraud, and so on—are theoretically more plausible. In these cases, candidates might know exactly when to exert costly effort because the initial vote count is public. Whether or not incumbent candidates (or some other class of candidates) can disproportionately win these battles then depends on the specifics of the particular setting. In the case of the U.S. House, Caughey and Sekhon (2011) rule out these explanations after finding that while recounts occur frequently in close races, they rarely reverse the initial result. This is consistent with the idea that incumbent party candidates and challengers both bring substantial resources to election contests and thus incumbents cannot dominate at the recount stage.16 Other post‐election mechanisms would include more flagrantly illegal behavior, such as altering precinct‐level vote tallies after all of the results have been counted. For such a mechanism to account for incumbent dominance in very close U.S. House races, electoral manipulation would have to be widespread, and this type of outright fraud is thought to be rare in this setting and time period (Lehoucq 2003). Moreover, we lack an explanation for why such behavior would be present in postwar House elections but absent in the prewar House and in postwar elections for state legislatures and statewide offices.         "
"25","In sum, we find existing post‐election and pre‐election explanations of observed imbalances in close U.S. House races to be fairly implausible. Outside of structural advantages to incumbents (or some other class of candidates) in manipulating electoral tallies after the election or in winning legal challenges, there exists no convincing theoretical reason to expect close winners and losers of a large election to differ systematically. The implausibility of the mechanisms that have been suggested to explain imbalance in the postwar U.S. House suggests that the success of incumbent party candidates in very close elections likely reflects statistical chance. To be sure, if we look at close elections in the postwar U.S. House in isolation, we observe a degree of incumbent party success that appears unlikely to have arisen randomly.17 However, given a large number of electoral settings, it is likely that this degree of imbalance would emerge in one of them simply by chance. The analysis in this article suggests that the postwar U.S. House may be that exceptional setting in which imbalance arose by chance.18 Of course, this does not preclude the possibility that future work might uncover a more compelling explanation for imbalance in the U.S. House that could lead us to revise this conclusion.         "
"26","In examining the observed imbalance in the U.S. House, as well as in presenting our tests for other electoral offices, we have touched upon the techniques that we believe researchers should employ when validating the RD design in applied settings. The fact that we fail to find problems in numerous electoral settings does not excuse researchers from defending the identification assumptions of their empirical strategies with both theory and data. The burden of proof is on the researcher to justify her assumptions and subject them to rigorous testing. A key advantage of the RD design is that it lends itself to numerous, transparent tests that follow directly from the identification assumptions. In this section, we propose a set of best practices for future researchers. We do not focus on the technical details of the RD design, which have already been clearly laid out in, for example, Hahn, Todd, and Van der Klaauw (2001), Lee (2008), and Imbens and Lemieux (2008).         "
"27","To ensure that RD results are both valid and robust, we propose a three‐step process. Researchers employing the RD design should engage in the following:            "
"28","We now discuss these three steps in detail."
"29","While the RD design is an extremely valuable tool for estimating electoral effects, it is not a panacea. The assumptions of the design are often weaker than those of other designs, but they are not guaranteed to hold. For example, if an electorate is small enough that relevant actors could closely predict or manipulate the vote tally, then the RD assumptions would be invalid. For this reason, the RD design should probably not be used to study the effects of judicial or legislative decisions, where strategic voting, endogenous agendas, or bargaining could lead to systematic differences between successful and unsuccessful motions. As a case in point, McCrary (2008) demonstrates that roll‐call votes in the U.S. House exhibit sorting around the majority threshold, indicating that such votes do not generate a quasi‐random assignment of policy decisions. Similarly, in an electoral setting where all close elections were ultimately decided in courtrooms that often reversed the initial counting of ballots, one could only assume that election winners and losers were comparable if one were willing to assume that the legal process was not systematically biased toward one type of candidate. For these reasons, a researcher must first provide theoretical justification for her design before examining the data. In any new electoral setting, the researcher should ask the following questions: Is the assumption of the RD design, that potential outcomes are smooth at the electoral threshold, defensible a priori? Are there substantive features of this electoral setting that could easily lead the bare winners to be systematically different from the bare losers?            "
"30","Having considered possible threats to the validity of the RD design theoretically, researchers should then test their assumptions to the extent possible. At a minimum, they should conduct tests for placebo effects of the treatment on the lagged outcome variable when possible. We also highly recommend that researchers show additional placebo tests for the lagged running variable, lagged treatment variable, and other pretreatment covariates, if available. These placebo tests should mimic, as closely as possible, the specifications used to estimate the primary quantities of interest. We discuss the choice of specifications below. Additionally, graphs and/or formal tests for sorting based on McCrary (2008) would further bolster readers' confidence in the underlying assumptions and results (see also Imbens and Lemieux 2008 and Lee and Lemieux 2010 for checklists of tests).            "
"31","In performing these placebo tests, researchers and consumers should keep in mind the multiple testing problem. Testing for imbalance on many variables makes it likely that some tests will be statistically significant by random chance. Imbalance should therefore be assessed based on the substantive size of the imbalance, and not only on the statistical significance of the balance test. For example, in our analyses, our failure to reject the null was not a product of large standard errors. The substantive levels of imbalance are quite small; see, for example, Figures B2‐B5 in the SI appendix.19 In addition to its value for assessing the presence of imbalances, this is important in considering the sensitivity of analyses performed on the data; the larger the size of the imbalance, the more sensitive estimates are likely to be. Moreover, multiple testing adjustment could be used to adjust the p‐values from the placebo checks to control the family‐wise error rate.20"
"32","Finally, researchers should assess the extent to which their effect estimates are sensitive to specification. As with many empirical approaches, RD designs leave researchers with some degrees of freedom that can lead to specification searching and false‐positive results. To mitigate these concerns, the researcher should show results for many different bandwidths and specifications (e.g., difference‐in‐means, local linear, polynomial) and also explore sensitivity to the inclusion of pretreatment covariates. The particular specifications should also be justified with theory and data. For example, a difference‐in‐means approach with a large bandwidth would likely lead to a large bias if the slope of the control function is nonzero, and a high‐order polynomial approach with a tiny bandwidth would likely be imprecise and unreliable. Moreover, a local linear specification might be biased if the true regression function is nonlinear within the estimation window."
"33","The researcher should also present her data visually in a transparent way that clarifies the appropriateness of the specification and the sensitivity of the results to changes in the specification. At a minimum, we recommend that researchers show the “main” RD graph that visualizes the relationship between the outcome and the running variable in the benchmark estimation window. Binned local averages should be used to assess the size of the discontinuity and the empirical shape of the regression functions on both sides of the threshold. We also recommend that researchers superimpose predicted values from a flexible control function fitted on both sides of the threshold to help assess the appropriate specification. We also recommend graphs like those we present in the supporting information, in which the point estimate for a given specification (e.g., local linear) is plotted across a large range of plausible bandwidths that are consistent with the specification checks, along with 95% confidence intervals (see also Lee and Lemieux 2010).            "
"34","How should researchers proceed if they want to estimate electoral effects in the postwar U.S. House or another setting where imbalance is present? So long as they have ruled out plausible theoretical mechanisms for the imbalance, researchers hoping to estimate electoral effects in the modern U.S. House should proceed in a similar manner to researchers who discover chance imbalances in experimental data.21 One might still be able to draw inferences from imbalanced experiments given additional assumptions and covariate adjustment.22 One could adjust for imbalance by including lagged incumbency and other pretreatment variables as covariates in the RD analysis or by preprocessing the data through matching or reweighting before conducting the RD analysis. Alternatively, researchers might consider a “donut” RD design (Almond and Doyle 2011; Barreca et al. 2011), where they exclude the small sample of very close elections where imbalance exists.23 It is important to emphasize that all of these fixes require additional assumptions that need to be justified, and extraordinary care is required in order to generate inferences given the presence of imbalances. Even if there is something fundamentally problematic about the RD assumptions in the U.S. House, the RD design may still be the best of all imperfect methods for estimating electoral effects in this important setting, and careful RD analysis may still produce better estimates than we could have otherwise obtained with other empirical strategies. As Caughey and Sekhon write, even in the case of estimating electoral effects in recent U.S. House elections, the RD design appears to be the best option: “Nevertheless, a comparison of the Lee RD estimator with traditional regression approaches to the incumbency advantage reveals that RD relies on weaker assumptions” (2011, 405).            "
"35","Our results should not induce complacency about the validity of RD designs in close elections. However, they should place the documented imbalances in U.S. House elections in the proper context. Our perception is that papers showing disproportionate incumbent successes in the U.S. House (particularly Caughey and Sekhon 2011) have been highly influential among political scientists interested in estimating electoral effects. Absent careful analysis of other electoral contexts, one might conclude that there is something fundamentally problematic about the use of RD to study electoral effects. Evidence of imbalance in the U.S. House may have even made some scholars suspicious of all RD‐based studies, to the point where they lend more credence to other approaches. The RD imbalance literature, to our reading, never intended this reaction. Indeed, Caughey and Sekhon point out that the RD design “still makes weaker assumptions than the usual model‐based alternatives” (2011, 406). We agree strongly with this sentiment, and we hope that the validity tests presented in this article make it clear that the RD design is broadly applicable.         "
"36","To our knowledge, this article provides the most thorough and extensive assessment to date of the validity of the regression discontinuity design in electoral settings. Across more than 40,000 closely contested races in many different electoral settings, we find no systematic evidence of sorting or imbalance around electoral thresholds. Conditional on being in a very close election, incumbents are no better at winning than challengers. We hope that these results will bolster confidence in estimates of electoral effects that arise from RD designs, so long as researchers exercise the appropriate level of rigor. We combine this analysis with a consideration of theoretical mechanisms through which the RD assumptions may be violated, arguing that in the case of the U.S. House, a plausible mechanism has not yet been proposed; this further strengthens our confidence in the validity of using RD to estimate electoral effects."
"37","To aid in this rigor, we have used our analyses as an opportunity to present our recommendations on best practices for applied RD users. When considering the use of the RD design in applied work, researchers should begin by considering theoretical reasons for the violation of the RD assumption. If the assumption appears theoretically plausible, researchers should perform a battery of balance tests on pretreatment covariates and lagged values of the outcome variable, using the same specifications as the analysis on the outcome variable. In performing these tests, researchers should keep in mind that large numbers of tests will lead to some false positives, and so they should place special emphasis on the substantive size of any observed imbalances and/or adjust for multiple testing explicitly. Finally, we recommend that researchers present graphical evidence to support the appropriateness of the specifications used to estimate the effects on the outcome variable of interest and report the estimated effects across a large number of bandwidths and specifications of the running variable."
"38","The RD design provides the opportunity for researchers to assess electoral effects under unusually weak assumptions that mitigate issues of model dependency and omitted variables in all but the most unusual cases. The best practices we propose in this article should allow researchers to apply the RD design, when justified through theory and validation, with the confidence that they have addressed possible problems of imbalance in their data. Though the RD assumption may not always hold, it continues to offer the most plausible, least model‐dependent estimates for a variety of electoral effects across numerous electoral settings."
