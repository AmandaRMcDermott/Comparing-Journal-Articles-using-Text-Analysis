"","x"
"1","We now summarize what other research has demonstrated about the racial gap and develop hypotheses to test later. The presentation is organized in three parts. First, we review literature that points to a disparity between black and white invalidation rates and speculates on its causes. Second, we consider how features of common voting equipment could affect the magnitude of the disparity and hypothesize that DRE and lever machines should be associated with smaller black‐white gaps than other technologies. Third, we identify the few parallel studies that discuss the relationship between race and invalidation for a wide range of voting technologies. Although valuable, these studies have limitations that our research overcomes."
"2","A growing body of evidence suggests that blacks cast invalid ballots more often than whites. In one of the earliest contributions, Hansen (2000) used OLS to analyze precinct‐level data from Palm Beach County, Florida, and uncovered a positive relationship between overvoting and the black percentage of registered voters. Others extended this finding to Broward, Duval, and Miami‐Dade counties (Herron and Sekhon 2001; USCCR 2001) and reinforced it with cross‐county regressions for the entire state (Jewett 2001; Klinkner 2001; Rasmusen 2001; USCCR 2001). Media organizations contributed their own evidence: using data the National Opinion Research Center collected on 175,010 Florida ballots that did not register a valid vote for president, they concluded that rejected ballots were more common in heavily black precincts than in heavily white ones (Fessenden 2001; Keating and Mintz 2001). Multi‐state investigations detected a similar relationship between blacks and uncounted votes (Brady et al. 2001, 26, 40; GAO 2001; HCGR 2001; Knack and Kropf 2001).            "
"3","Researchers have proposed various explanations for these racial patterns. Many contend that blacks are more prone than whites to commit voting errors on average, due to low education, illiteracy, and other socioeconomic factors (e.g., Posner 2001, 80–81). This is undoubtedly part of the explanation, although regression analyses that control for socioeconomic variables still find a positive though attenuated correlation between race and invalidation (e.g., Brady et al. 2001; Fessenden 2001; GAO 2001; Rasmusen 2001; USCCR 2001). Racial patterns of invalidation could also arise if black voters are less experienced than white ones. In Florida, for example, the NAACP sponsored a massive drive that brought many African Americans to the polls for the first time, perhaps contributing to the black‐white gap. Research on the link between inexperience and invalidation has yielded mixed results, however (Holt and Berens 2001; Jewett 2001; Klinkner 2001; Knack and Kropf 2001). Finally, some add that blacks may be less likely than whites to seek or receive assistance in using machines and correcting mistakes, especially where there is racial intimidation or a history of disenfranchisement (e.g., USCCR 2001).            "
"4","If such fundamental factors underlie the black‐white gap, one might assume the problem would be difficult to address. On the contrary, we maintain that certain kinds of voting equipment can go a long way toward minimizing the racial difference in voided ballots. We now develop this hypothesis."
"5","Americans use a wide range of voting machines, some with features that could weaken the ability of socioeconomic differences, relative inexperience, or racial antagonism to produce a black‐white gap in voided ballots. We systematically describe the major types of voting equipment and explain why lever and DRE machines should be associated with smaller racial disparities in invalidation rates than other widely used technologies."
"6","Studies have shown that punch‐card ballots are highly vulnerable to human error. The voter inserts the punch card into a template with candidate names and uses a stylus to dislodge prescored rectangles called chads. A voter may fail to punch the card cleanly, leading to a pregnant, dimpled, or hanging chad that prevents the counting machine from registering a valid vote (Saltman 1988), or could overvote by punching more than one hole for a particular office. Punch‐card ballots do not indicate which chad corresponds to which candidate, making it difficult to verify a vote after removing the ballot from the template. Moreover, a voter who spots an error might need to complete a new ballot, an inconvenient step the voter might not take. Probably for these reasons, punch‐card machines have the highest rate of invalid presidential ballots in the country, 2.6 percent (Brady et al. 2001, 29).            "
"7","Optically scanned ballots overcome some of these problems but do not eliminate the possibility of overvoting or undervoting. With optical ballots the voter must use a special writing instrument to fill in bubbles or arrows. It is possible to spoil an optical ballot by failing to blacken the bubble or arrow completely, by using the wrong kind of pencil or pen, or by marking spots next to multiple candidates. Optical technology is more user‐friendly than punch cards, though, since the names of candidates appear on the ballot itself, allowing people to verify votes if they take the time. Many counties tabulate optical ballots at central locations, but some have the ability to scan ballots at the precinct and alert people who overvoted or undervoted. Counties do not always activate this warning feature, but where they do voters can decide whether to correct mistakes. In November 2000 only 1.4 percent of ballots in counties with optical scanners contained no valid presidential vote (Brady et al. 2001, 29); the rate was probably higher for centrally counted ballots and lower where ballots were tabulated at the precinct (GAO 2001; Keating and Mintz 2001; Posner 2001; USCCR 2001).            "
"8","Alternative technologies exist that preclude overvoting and make it easier to verify choices and correct mistakes. With lever machines the names of candidates appear on cards next to levers that the voter pulls to make a selection. These machines usually prevent the voter from switching too many levers for a particular office. Moreover, the voter is free to review and change any choices before finalizing votes. DREs offer a modern analog to levers. These machines display a list of candidates for a particular office, and the voter pushes a button or toggle switch next to the preferred candidate's name. Doing this highlights the name of the candidate so the voter can verify the choice. On DREs a person can change a vote only by deselecting the currently highlighted candidate and then choosing a new one, a two‐step procedure that prevents overvoting. As with lever machines, the voter can review all choices before registering them officially. The machines can also signal when someone has not voted for a particular office, thereby reducing the risk of unintentional undervoting."
"9","Thus, both lever and DRE machines prevent overvoting, allow citizens to review their selections, and enable them to correct errors without requesting a new ballot. We might therefore expect these machines to minimize invalid ballots. In fact only 1.7 percent of presidential ballots cast on either type of machine in November 2000 were not counted. Judging from the raw averages, these machines beat punch cards but did slightly worse than optical scanners. Recent studies with demographic and political control variables, however, show that lever and DRE machines perform as well as or better than optical scanners (Brady et al. 2001, 29, 34; GAO 2001; cf. Caltech/MIT 2001). We contribute to the debate not by testing which machines minimize voided ballots overall, but by assessing the differential impact of voting technologies on African Americans and whites.            "
"10","Given the machine features summarized in Table 1, we advance the following hypothesis: the black‐white gap should be narrower with lever and DRE equipment than with common alternatives. Our expectation follows directly from the logic in this and the previous section. By preventing overvoting and making undervoting more transparent and correctable, lever and DRE machines reduce the influence of fundamental factors—socioeconomic disadvantages, relative inexperience, and racial antagonism—that might lead blacks to make mistakes or fail to correct them more often than whites. Precinct‐counted optical ballots share many of these advantages when warning systems are active. Before introducing our own tests of this proposition, we review the few pertinent studies that exist.            "
"11","Three studies, conducted concurrently with ours, discuss the relationship between race and invalidation for a wide range of voting technologies (GAO 2001; HCGR 2001; Knack and Kropf 2001).3 Although they offer valuable insights, these studies do not isolate and compare invalidation rates for blacks and whites, as would be necessary to evaluate our hypothesis. Moreover, they rely on proxy variables for racial turnout, conflate absentee and in‐person voters, and conduct analysis at a high level of aggregation. Finally, for reasons not entirely clear, they reach inconsistent conclusions. As we review these studies we emphasize the challenges of measurement and analysis that make our hypothesis difficult to test. This provides a foundation for the third section, which discusses how our special data and methods help overcome the limitations of the existing literature.            "
"12","In a brief study the House Committee on Government Reform (HCGR 2001) compared 40 congressional districts, half with high poverty and large minority populations and half with the opposite conditions. It found that poor minority districts had higher percentages of invalid ballots, but “modern voting technologies”—especially DREs and precinct‐level optical scanners—appeared to narrow the disparity. A more comprehensive study by Knack and Kropf (2001) examined county‐level data from 39 states in 1996. For each type of voting machine the authors regressed invalid presidential ballots on 15 census and structural variables, including the black share of the county population. They detected a positive relationship between African Americans and invalidation, except in counties where voting equipment could be “programmed to eliminate overvoting.” The General Accounting Office (2001) employed similar data and methods but reached a different conclusion. In its regression analysis of county‐level observations from 43 states in 2000, demographic “characteristics of voters did not appear to interact with voting equipment to affect the percentage of uncounted votes” (GAO 2001, 19). These conflicting studies do not provide equally detailed accounts of procedures and results, making it hard to say why they point in different directions.3"
"13","The studies not only disagree, but also do not speak directly to our hypothesis. Simply put, they do not estimate the proportions of blacks and whites that cast invalid ballots under each technology. With those statistics researchers could calculate the black‐white gap by machine type; without them it would be impossible to test the central proposition of this article. Regrettably, one cannot infer black and white invalidation rates from the studies cited above. The coefficient on “percent black” in their regressions measures the marginal effect of race after controlling for education, poverty, voting experience, and many other variables. Although interesting in its own right, this is quite different from estimating how blacks and whites fare, on average, given the characteristics they actually have.3 We posit that certain technologies can narrow the invalidation gap by weakening the impact of fundamental disparities that exist in the real world. For our purposes, then, it is crucial not to impose artificial equality between blacks and whites through the liberal use of control variables. Instead, we need a statistical model tailor‐made to infer, from aggregate election data, how often members of each racial group cast invalid ballots.            "
"14","Three data problems further limit the ability of existing research to address our hypothesis. First, nearly all work relies on proxy variables such as the black proportion of registered voters or the general population to characterize those who actually went to the polls. When the assumptions for unbiased ecological regression are otherwise satisfied, the use of such proxies introduces nonrandom measurement error that depresses estimates of African American and white invalidation, as well as the difference between the two rates.3 Second, except for a few analyses of Florida, research fails to distinguish between in‐person voters, who use the machines in question on election day, and absentee voters, who do not. Special information collected for this study underscores the importance of the distinction. In Louisiana, for example, absentees accounted for only 4 percent of turnout but were responsible for 31 percent of voided presidential ballots in 2000.3 Finally, work outside Florida involves data at a fairly high level of aggregation. The units of analysis, counties or congressional districts, do not differ as widely in racial turnout or ballot invalidation as smaller geographical units (e.g., precincts). Thus, the regression estimates are less precise than they could be. All three studies summarized above exhibit these data limitations, prompting the authors of one to emphasize that its “results should be interpreted with caution” (GAO 2001, 16). In the next section we explain how our unique data and methods overcome these problems.            "
"15","Our research design explicitly addresses the challenges of measurement and analysis that were highlighted in the previous section. We constructed a dataset that includes the racial breakdown of voter turnout by race, distinguishes between in‐person and absentee voters, measures key variables at the precinct level, and covers a wide range of voting technologies. We then employed an extended form of ecological regression to estimate overall invalidation rates for black and white voters under each major type of voting equipment. This allowed us to test our main hypothesis: the black‐white gap in voided ballots should be narrower with DRE and lever machines than with punch cards and optical ballots. We now provide details about our data and methods."
"16","Our dataset contains precinct‐level observations from South Carolina and Louisiana, the only states that officially supply the necessary information. To build the dataset, we merged millions of individual voter history records with demographic data from registration files. This allowed us to determine the race and precinct of origin for every person who cast a ballot in the 2000 election. We also commissioned programmers in the election offices of both states to generate special absentee databases that identified who voted at the precinct polling station and who cast ballots by other means. We then collapsed the individual‐level data (1.4 million cases in South Carolina, 1.8 million in Louisiana) to calculate how many whites and nonwhites used voting machines in each precinct on election day. In our two states, 98 to 99 percent of individuals who voted in the 2000 election were either black or white, so our measure of nonwhite turnout essentially reflected the participation of African Americans."
"17","We next computed the proportion of invalid ballots by precinct. The formula for invalidation in each precinct i was Ii= 1 −Pi/Vi, where P is the number of valid presidential ballots and V is our tally of voters who appeared in person on election day.3 After dropping extreme cases of invalidation (below the 1st or above the 99th percentiles) in each state, we matched our precinct‐level measures with information about the machines voters used. South Carolina and Louisiana together employ the four most prevalent voting technologies in the United States: punch cards, optical scanners, DREs, and lever machines. Thus, data from these states can shed considerable light on our hypothesis.            "
"18","It is worth emphasizing that our treatment of absentee voters not only improves measures of racial turnout, but also corrects a common error in invalidation statistics. In publicly available records for Louisiana, South Carolina, and other states an absentee voter is credited as having turned out in the precinct where she resides, but her votes are tabulated in a fictitious county‐wide “absentee precinct” that bears no relationship to the voter's precinct of origin. Thus, public data overstate the number of voided ballots in proportion to the number of absentees in each precinct. Moreover, if whites are more likely than minorities to vote absentee, using official turnout statistics would lead researchers to overestimate invalidation by whites. We avoid these problems by reconstructing the data from individual records."
"19","Absentee lists for Louisiana are reliable, since an absentee voter cannot receive a ballot until her name is entered into a computerized poll list. Thus, we were able to strip all 76,765 absentee voters from the precinct‐level turnout in Louisiana with a high degree of accuracy. It was more difficult to implement the correction in South Carolina, where the list of absentee voters was incomplete. As evidence of this problem, the number of valid absentee votes for president exceeded the number of certified absentee voters in nine of 46 counties in November 2000. Nevertheless, we removed all known absentees (102,878, a figure larger than the 98,125 valid absentee ballots statewide), and thus significantly reduced the bias in official counts of in‐person turnout."
"20","The descriptive statistics for our dataset appear in Table 2. The key variables for our analysis are invalidation and nonwhite turnout, measured at the precinct level. Compared with county‐level statistics, our dataset contains substantially more variation on the racial variable. The standard deviation around the nonwhite proportion of voters in our dataset was 0.33 in Louisiana and 0.27 in South Carolina, whereas the statistic for U.S. counties (using nonwhite population as a proxy for nonwhite turnout) was only 0.16. According to 1996 Census figures, nonwhites make up more than 95 percent of the population in only one of 3,138 U.S. counties. In contrast, nonwhites represent more than 95 percent of voter turnout in 326 Louisiana precincts (8 percent of the total) and 43 South Carolina precincts (2 percent of the total). This confirms our expectation about the advantages of precinct‐level data. Table 2 also includes measures of poverty, education, and income, which pertain to the total population rather than actual voters and are measured at the county rather than the precinct level (U.S. Census Bureau 1998).            "
"21","The table reveals a diversity of voting equipment and socioeconomic characteristics in South Carolina. In the November 2000 election, 21 South Carolina counties employed DREs, 12 relied on punch card voting systems, and 13 used optically scanned ballots—10 counted at a central location and three counted at the polling station. The average share of voided ballots under the first two systems (5.6 percent and 5.3 percent) exceeded the share under DREs (3.4 percent) by a noticeable margin. The table also shows that counties with optical scanners had more poverty, lower education and income, and larger minority populations than the rest of the state. DREs occupied an intermediate position on most of these dimensions. Overall, minority voters in South Carolina are not disproportionately exposed to inferior technologies."
"22"," Table 2 also summarizes the Louisiana data. Only 12 of 64 parishes employed DREs, but the list includes the five most populous parishes, making the distribution by precinct somewhat less lopsided. Residents of parishes with DREs had higher levels of income and education, but they were also more likely to be African Americans. The most striking feature in the Louisiana dataset is the miniscule proportion of invalid presidential ballots, compared not only with South Carolina but also with the national average of 2 percent in November 2000. In fact, Louisiana can claim one of the lowest recorded invalidation rates in the country, whereas South Carolina shows one of the highest. To some extent this difference arises from the way the two states track voter turnout.3"
"23","Having constructed a new dataset, we used an extended form of ecological regression to estimate invalidation rates for white and nonwhite voters. The fraction of invalid presidential ballots in any particular precinct is given by the accounting identity I=βnTn+βw(1 −Tn), where I is invalid ballots as a proportion of all ballots, βn is the nonwhite invalidation rate, βw is the white invalidation rate, Tn is the nonwhite share of total turnout and (1 −Tn) is the white share. Recall that nearly all nonwhites in South Carolina and Louisiana are black, so in our analysis βn essentially represents the invalidation rate of African Americans. Rearranging these terms gives I=βw+ (βn−βw)Tn. If the parameters βn and βw are constant across precincts, we can estimate them via a Goodman's regression of I on Tn and a constant term (Goodman 1953).            "
"24","It seems unrealistic, however, to assume that βn and βw do not change with the racial composition of districts. In predominantly white precincts, voters of all races tend to be wealthier and better educated than those who live in minority areas. Consequently, βn and βw should be somewhat lower in white areas than in minority ones. The standard Goodman's regression does not allow this variation and thus is vulnerable to problems of aggregation bias, which can occur when the parameters of interest (in this case the invalidation rates) are correlated with the regressors.            "
"25","Our statistical approach rests on work of Achen and Shively (1995), who derive an extended version of Goodman's regression and prove that it helps mitigate the effects of aggregation bias. We relax the assumption that the parameters are mean‐independent of the regressors and instead model the invalidation rates in each district i as linear functions of Tni. Let βni=b1+b2Tni+eni and βwi=b3+b4Tni+ewi. By substitution into Goodman's regression we obtain               "
"26","To convert the estimates of β0, β1, and β2 into measures of b1, b2, b3, and b4, we needed to make an assumption. Only b3, the intercept for whites, is identified by the quadratic regression, but we calculate values for the other bs by assuming that either b2 or b4 is zero. This assumption makes our model less restrictive than the basic Goodman's regression, which constrains bothb2 and b4 to be zero and thus does not allow the invalidation rate of either group to vary with the composition of the precinct. In cases like ours, the added flexibility from letting even one invalidation rate change with Tn reduces aggregation error relative to the basic specification (Achen and Shively 1995).            "
"27","Our criteria for identification are straightforward. Note that β2 represents the difference between b2 and b4. Suppose that the proportion of uncounted ballots increases—or at least does not decrease—for both racial groups as precincts become less white. If the estimate of β2 is positive, we conclude that b2 > b4, which means the invalidation rate among nonwhites increases more quickly than the invalidation rate among whites as Tni rises. Consequently, we set the smaller of these values (b4) to zero, allowing us to solve for b1 and b2. In this example, white invalidation is held constant across precincts, while nonwhite invalidation is allowed to vary with the racial composition of turnout. If instead the estimate of β2 is negative, implying that b4 > b2, we identify the system of equations by setting b2= 0, thereby fixing nonwhite invalidation at a constant level while letting the white rate fluctuate from one precinct to the next.            "
"28","To see whether the racial gap in voided ballots depends on voting equipment, we divided the sample by state and machine type, resulting in five datasets (three for South Carolina, two for Louisiana) with precinct‐level observations. We then ran a quadratic regression for each dataset and used it to estimate invalidation rates for blacks and whites. The next section describes our results."
"29","In line with our hypothesis, the black‐white gap in voided ballots was substantially lower with DRE and lever machines than with punch cards and optical scanners. We present the results in various ways. First, we offer a table of ecological regression coefficients and standard errors. Second, we graph the estimated relationships between nonwhites as a proportion of total turnout and invalidation as a proportion of all ballots. Third, we use the regression results and computer simulation to calculate the gap (with confidence intervals) between black and white invalidation rates under each type of voting equipment. This not only conveys the substantive meaning of our regression results but also offers the most direct evidence concerning our hypothesis. Finally, we consider alternative specifications and find that they do not change our conclusions."
"30","Regression results appear in Table 3, with standard errors in parentheses. These coefficients in themselves are not the primary quantities of interest, but they do suggest two patterns. First, the quadratic term is statistically distinguishable from zero (coefficient more than twice its standard error) in all but one column, giving strong reason to prefer the extended model over the standard ecological regression, which omits this term. Second, the R2 statistics are much larger for punch card and optically scanned ballots, suggesting that race explains a larger share of ballot invalidation in areas that use those technologies. Far from a cause for concern, the low R2 values for DRE and lever machines accord with our hypothesis that racial patterns of invalidation should be very weak with such equipment. To better understand the substantive importance of these results, we turn to graphical analysis and computer simulation.         "
"31"," Figure 1 contains regression lines with confidence intervals for the three types of voting equipment in South Carolina. The horizontal axes measure nonwhites as a proportion of all in‐person voters and the vertical axes give invalidation rates. The plots show that the average invalidation rate increases with the nonwhite share of total turnout in punch card and optical scanner precincts, but there is little relationship between these variables in precincts that use DREs.3 We omit the graphs for Louisiana, where the regression lines have only a slight upward slope.         "
"32"," Regression Lines and 95% Confidence Intervals for South Carolina                      "
"33","Finally, we employed the following algorithm to obtain our key quantities of interest: overall estimates of nonwhite and white invalidation rates, as well as the difference between the two."
"34","                        "
"35","Randomly draw one set of parameters  from their asymptotic sampling distribution, . The tilde over the parameters indicates that they were simulated.                  "
"36","Use the simulated parameters and the identifying assumption discussed in the third section to compute values for , and . (Recall that , and . We identify the system by assuming a value of zero for either b2 or b4.)                  "
"37","Given those values and the observed level of Tni, calculate  and  for each precinct i.                  "
"38","Compute a turnout‐weighted average of the precinct‐level estimates, following the procedure in (Achen and Shively 1995, 121–23). The formulas in this case are  and , where Vni and Vwi are the number of nonwhite and white voters who turned out in precinct i, and Vn and Vw measure the number of nonwhite and white voters in the entire sample. This produces one simulation of βn and one simulation of βw.                  "
"39","Calculate , the racial gap in uncounted ballots.                  "
"40","By repeating this algorithm 1000 times, we obtained 1000 simulated values of , thereby approximating the sampling distribution of the racial difference in invalidation rates. One could also compute the standard error around the estimated gap analytically, but simulation is more convenient and no less accurate in this case (King, Tomz, and Wittenberg 2000).         "
"41","We now provide a numerical example, for punch cards in South Carolina, of how this algorithm generates estimates of the black‐white gap. The regression estimated an intercept of , a coefficient on nonwhite turnout of , and a coefficient on the quadratic term of . These estimates have a 3x3 variance matrix with diagonal elements equal to the standard errors in Table 3. In step 1 we draw one set of betas from a multivariate normal distribution with mean equal to the vector of estimated coefficients and variance equal to their variance‐covariance matrix. Suppose, by chance, we draw exactly the coefficients we estimated, i.e. . In step 2 we note that the quadratic coefficient is negative and identify the model by assuming . This allows us to calculate , and . Step 3 requires the nonwhite share of voter turnout in precinct i. Consider the average punch‐card precinct, where nonwhites made up 22 percent of those who went to the polls. For this precinct we estimate a nonwhite invalidation rate of  and , for a racial gap of .087 − .054 = .033 or 3.3 percentage points. Our sample contains many precincts, though, whose values for nonwhite turnout may be higher or lower than the mean. To complete step 3 we compute  and  for each of the 657 punch‐card precincts, using their actual levels of nonwhite turnout. In step 4 we calculate a weighted average of the 657 values for nonwhite invalidation, with weights proportional to the number of nonwhite voters in the precinct, and make a parallel calculation for white voters. Given the distribution of nonwhite turnout in our data, the weighted averages are  and , implying in step 5 an overall black‐white gap of 8.7 − 4.5 = 4.2 percentage points. This estimate is uncertain because it relies on regression coefficients that are themselves uncertain. The simulation procedure, which repeatedly draws from the sampling distribution of the coefficients, accounts for the uncertainty and allows us to compute confidence intervals around our point estimate for the racial gap.         "
"42"," Table 4 summarizes our estimates of the racial gap in voided ballots for each type of voting equipment. The columns give invalidation rates (with 95 percent confidence intervals) for nonwhites and whites, as well as the difference between the two. In South Carolina, the estimated racial gap is 4.2 percentage points in precincts that use punch cards and 6.2 percentage points in those with optical scanning devices. Confidence intervals around these estimates (2.9–5.4 and 3.0–9.3) are far from zero, suggesting that the racial gap for these two machines probably did not arise by chance. On the other hand, we estimate a difference of only 0.3 percentage points (confidence interval −0.7–1.4) between nonwhite and white invalidation rates in precincts with DREs. For Louisiana, the regressions suggest only a mild relationship between invalidation and race. The values in Table 4 reflect this. We find a racial gap of only 0.7 percentage points for lever machines and 0.5 percentage points for DREs. Neither confidence interval (0.5–0.9, 0.4–0.7) includes zero but the two intervals overlap, so we cannot conclude that either of these machine types leads to a smaller racial difference than the other.         "
"43","We also convey these results graphically in Figure 2. The vertical axis indicates the type of voting equipment and the horizontal axis measures the difference in invalidation rates between nonwhite and white voters. In each customized boxplot, the central dot represents our best estimate of the racial difference, the box covers the interquartile range of simulated values, and the “wings” span a 95 percent confidence interval around the estimate. The plots show that the estimated gap is much smaller with DREs and lever machines than with punch cards and optical ballots. They also convey that the difference is statistically significant: the confidence intervals for the two underperforming technologies do not overlap either the point estimates or the confidence intervals for DREs and levers.3"
"44"," The Racial Gap: Estimates, Interquartile Ranges, and 95% Confidence Intervals                      "
"45","Both technologies in Louisiana were associated with small racial gaps. We attribute this to the equipment voters used, rather than other factors peculiar to that state. To confirm this interpretation we analyzed the invalidation rates of Louisiana's absentee voters, who used punch cards. For reasons discussed earlier invalidation rates for absentees are available only at the parish level, but with 64 parishes we had enough observations for a preliminary analysis.3 A quadratic regression finds that 10.3 percent of nonwhites and 5.3 percent of whites invalidated their absentee ballots, for a racial gap of 5 percentage points. One should not place too much weight on this point estimate, which has a standard error of 5.9 due partly to the small number of observations. Nevertheless, it is consistent with precinct‐level results for punch cards in South Carolina, which increases confidence that voting equipment is responsible for the narrow racial gaps among in‐person voters in Louisiana.         "
"46","To shed additional light on the performance of optical technologies, we considered whether the racial gap depended on where officials counted the ballots: at the polling station or at a central location. Of the South Carolina counties that used optical equipment in November 2000, the vast majority employed central counting but three scanned at the polling place. The estimated gap of 7.1 points (confidence interval 2.2–11.9) in those three counties did not differ substantially from the gap of 7.9 points (confidence interval 1.2–14.5) in areas that tabulated centrally. Further analysis revealed heterogeneity among the precinct‐tabulating counties, though. Orangeburg County exhibited a large racial gap, but in Beaufort and Laurens there was no meaningful difference between our estimates of nonwhite and white invalidation rates. The inferior preformance in Orangeburg may have arisen because it employed a somewhat different warning procedure and ballot design.3 Overall, our data do not point to a clear conclusion about the effects of precinct counting. Other studies with different data find that precinct counting weakens the relationship between African Americans and invalidation (HCGR 2001; Keating and Mintz 2001; Knack and Kropf 2001; USCCR 2001). More research is needed to evaluate the impact of this procedure on racial groups.         "
"47","The results in this article are fairly stable across alternative specifications. Our conclusions did not change when we included a cubic term Tni3, and they became a bit stronger but harder to interpret when we implemented log and logit transformations of the dependent variable.3 To deal with potential heteroskedasticity in the quadratic regression, we reestimated the models using White's standard errors. This widened the confidence intervals around the racial gap for punch cards and optical ballots (2.2–6.2 and 2.2–10.1) but had no effect on the intervals for lever machines and DREs, and thus did not alter our substantive conclusions.         "
"48","Finally, we estimated a model that allowed invalidation rates to vary with socioeconomic conditions, rather than the percentage of nonwhite voters in the precinct. The model used socioeconomic variables for a different purpose than other studies. Regressions by Knack and Kropf (2001) and the GAO (2001) estimate the marginal effect of race after holding poverty, education, and other factors constant. The second section explained why this approach does not allow direct inferences about the invalidation rates of blacks and whites, our key quantities of interest. We recognize, however, that the invalidation rates of these groups may vary across precincts and are probably higher in minority areas than elsewhere. To address this possibility our primary analysis let invalidation rates change with the nonwhite share of voters in the precinct. Here we explore an alternative: let invalidation rates of blacks and whites depend on average levels of poverty and education. This is simply another way to address the potential for aggregation bias, which could arise if black and white inhabitants of the same precinct have socioeconomic commonalities. Unlike other studies, which use controls to equalize (in a statistical sense) the socioeconomic characteristics of areas that people inhabit, we emphasize the racial implications of those socioeconomic conditions and impound them into estimates of invalidation.         "
"49","To do this, we defined βni=b1+b2 Povertyi+b3 Educationi+eni and constructed an analogous equation for βwi. This led us to regress Ii on a constant, Tni, poverty, education, and interactions between the socioeconomic measures and Tni. Our measures of poverty and education contain error—they refer to the overall population rather than people who actually voted, and they are recorded at the county rather than the precinct level—but are the best available data. As before, we ran the regression and drew the parameters from their sampling distribution. We then used actual values of Tni, poverty, and education to obtain simulated values of  and  for each precinct i. Finally we computed a weighted average of the precinct‐level estimates and calculated the racial gap.         "
"50","Consistent with our previous results, the difference was much wider with punch cards and optical ballots than with lever machines and DREs. In South Carolina the estimated racial gaps, with 95 percent confidence intervals in parentheses, were 6.6 (5.7–7.6) percentage points for punch cards and 6.9 (5.4–8.3) for optical ballots, compared with only 2.1 (1.4–2.7) for DREs. Although the estimate for DREs exceeds what we found with the quadratic model, it remains consistent with our principal conclusion. In Louisiana the estimates were 0.8 (0.6–0.9) and 0.8 (0.7–0.9) for lever machines and DREs, respectively.3 Across a variety of specifications, then, the estimated racial gap was narrower with lever machines and DREs than with the alternatives.         "
"51","In the previous section we showed that DRE and lever machines reduce the black‐white gap to a fraction of a percentage point. In this section we deepen the analysis by exploring whether a gap of that magnitude could be due to racial patterns of intentional undervoting, rather than human error. Intentional undervoting occurs when a citizen goes to the polls but opts not to select a presidential candidate. Using opinion surveys and exit polls, we find that intentional undervoting is more prevalent among African Americans than among whites. The difference in rates of intentional undervoting is a few tenths of a percentage point, the order of magnitude of the estimated racial gap with lever machines and DREs. This implies that even the best voting equipment cannot eliminate the racial gap in uncounted ballots, but DRE and lever machines can eliminate most of the gap that arises from human error.         "
"52","Our analysis begins with the American National Election Study, a nationwide survey of the U.S. electorate in presidential and midterm election years. In every presidential election year since 1964, the National Election Study has asked respondents whether they voted and, if so, whether they voted for a candidate for president.3 We pooled the data from all but one of the NES surveys, producing a sample of 11,521 voters across nearly four decades.3 All but 309 of these individuals were either white or African American, so we restricted our analysis to those two racial groups.         "
"53"," Table 5 presents a cross‐tabulation of race and intentional undervoting. White respondents claimed to undervote intentionally at slightly lower rate than blacks: 0.58 percent (0.44–0.75) versus 0.82 percent (.41–1.47), with 95 percent binomial confidence intervals in parentheses. We used simulation to assess whether the difference between these two rates was statistically significant.3 Given the NES data, the probability that blacks undervote at a higher rate than whites is 0.88 corresponding to a p‐value of 0.12 for a one‐sided significance test. Even with the relatively small NES sample, then, we can be fairly confident that blacks profess to undervote more frequently than whites.3"
"54","Exit polls lend more certainty to the conclusion that blacks choose to undervote at a somewhat higher rate than whites. In November 1992 the Voter News Service (VNS) asked a sample of voters, as they left the polls, which presidential candidate they had just voted for. The possible responses were Bill Clinton, George Bush, Ross Perot, Other, or “Didn't vote for president.”3 We combined Clinton, Bush, Perot, and Other into a new category called “voted for president.” The results, tabulated by race, appear in Table 6. The VNS data suggest that blacks undervote intentionally at approximately twice the rate of whites—0.4 percent (0.31–0.58) versus 0.2 percent (0.16–0.25), again with 95 percent binomial confidence intervals in parentheses.3 Although the absolute magnitude of the gap is small, the p‐value for a one‐sided significance test is 0.002, leaving us very certain that blacks report to undervote at a higher rate than whites.3Table 6 also suggests that, in 1992, Hispanic voters were most likely to refrain from voting for president, and that Asian respondents undervoted deliberately more often than whites but less frequently than blacks. The small samples for Hispanic and Asian voters prevent us from endorsing these conclusions with a high degree of certainty, however.         "
"55","Given the infrequency of intentional undervoting and the limited sources of data about it, one should draw conclusions with care. But the best available information suggests that intentional undervoting adds approximately 0.2 (VNS) or 0.3 (NES) percentage points to the black‐white gap in voided ballots. This difference is too small to explain discrepancies of several percentage points that we find under punch card and optical machines. Nevertheless, intentional undervoting could account for much of the racial gap in areas that use lever machines, DREs, and perhaps precinct‐counted optical ballots. Put another way, those technologies do a remarkable job of eliminating the portion of the gap that arises from human error, rather than conscious choice."
"56","The black‐white gap in voided ballots depends crucially on the voting equipment that people use. Based on data from the 2000 presidential elections in South Carolina and Louisiana, we estimated a gap of around 4 percentage points in precincts that used punch cards and approximately 6 percentage points in areas that used optically scanned ballots. DRE and lever machines cut the discrepancy by a factor of ten, leaving a gap of only 0.3–0.7 percentage points.3 We find that much of the remaining difference could be due to intentional undervoting, which African Americans profess to practice at a slightly higher rate than whites.         "
"57","We arrived at these conclusions by constructing an original dataset and analyzing it with ecological regression techniques. The dataset, drawn from South Carolina and Louisiana, exhibits several features that make it especially appropriate for research on the racial consequences of voting equipment. It contains direct measures of turnout by race, distinguishes between absentee and in‐person voters, measures variables at the precinct level, and covers a wide variety of voting technologies. We analyzed the data with quadratic ecological regression, leading to the first estimates of the difference in invalidation rates of blacks and whites across all major machine types."
"58","Our focus on South Carolina and Louisiana offers clear benefits, but it also comes at a potential cost: racial patterns of invalidation in those two states may differ from patterns in other parts of the country. To some extent the generality of our results depends on the mechanism behind the black‐white gap in uncounted ballots.3 If hostility to minority voting contributes to the racial gap, and if such attitudes are especially prevalent in South Carolina and Louisiana, then punch card and optical machines in other states may be associated with smaller black‐white differences than we found. Likewise, if socioeconomic differences underlie the racial gap on punch cards and optical scanners, then we must consider the racial incidence of variables like poverty and education. Where African Americans and whites are more socioeconomically equal than in South Carolina and Louisiana, punch cards and optical scanners should pose less of a disadvantage for black voters. In fact, socioeconomic discrepancies between blacks and whites in South Carolina and Louisiana are similar to those in other southern states (including Florida) and certain northern states (e.g., Michigan, Illinois, Wisconsin) but wider than the national mean.3 Finally, if the relative inexperience of black voters contributes to a racial gap in voided ballots, one must be sensitive to changes in experience across regions and elections. For example, a large percentage of blacks in Florida went to the polls for the first time in 2000, in response to an unprecedented get‐out‐the‐vote drive by the NAACP. The atypical infusion of inexperienced black voters in Florida, where scholars have focused the most attention, makes it all the more informative to consider other states, as well, including the ones in this article.         "
"59","Remarkably, we find that DRE and lever machines nearly eliminate the difference between black and white invalidation rates, even in two states where socioeconomic and attitudinal factors may be less favorable than average. If anything, South Carolina and Louisiana present hard cases for DREs and levers, yet those technologies go a considerable way toward leveling the playing field for black voters. Nevertheless, it is important to view our research in the context of parallel studies on other parts of the country. Our data and methods offer certain advantages, which we have enumerated, but they are also restricted in scope. Thus, it is encouraging to know that other research, focusing on Florida, points in a similar direction. Punch cards and optical scanners, the technologies that performed worst in our study, also generated wide gaps there, but counting ballots at the polling place reduced the gap, just as our reasoning would suggest. The combined weight of studies on Florida and across the nation reinforce our conclusion: the choice of voting technology affects the black‐white gap in voided ballots."
"60","Although we find that lever machines, DREs, and perhaps precinct‐level optical scanners can narrow the gap in invalidation rates between African Americans and whites, such machines may not be best for democracy or most appropriate for the United States. Scholars and policymakers should weigh many factors—in addition to the differential effects of voting equipment on racial groups—as they work to upgrade the nation's voting systems. Cost may enter the calculation, since devices that narrow the racial disparity could be expensive. Moreover, one could explore the potential tradeoff between speed and accuracy: lever machines, DREs, and precinct‐level scanners may create long lines and affect voter turnout, offsetting their advantages on other dimensions. For now, though, we know that the choice of voting equipment can have a significant impact on the racial gap in voided ballots."
