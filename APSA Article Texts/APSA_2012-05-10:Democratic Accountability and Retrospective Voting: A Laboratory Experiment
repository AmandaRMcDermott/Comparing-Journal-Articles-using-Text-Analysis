"","x"
"1","If voters behave according to the traditional theory of retrospective voting—rewarding politicians for producing good outcomes and punishing them for producing poor ones (Key 1966)—then politicians can, in principle, be induced to take actions that benefit the public (Banks and Sundaram 1993; Ferejohn 1986). But the traditional theory of retrospective voting is not fully compatible with the rational choice view of voting behavior (Fiorina 1981), especially when voters face a second type of uncertainty about politicians’ unobserved characteristics (such as their motivation, ideological leanings, or level of competence) and those characteristics affect future policy choices. Rational voters are forward‐looking, so their intention is not to sanction or reward politicians’ past behavior, but rather to select politicians who have desirable characteristics (Ashworth and Bueno de Mesquita 2008; Fearon 1999; Gordon, Huber, and Landa 2007). To the extent that rational voters look to the past at all, it is only to form judgments about politicians’ chances of producing good policies in the future (Downs 1957; Fiorina 1981; Mackuen, Erikson, and Stimson 1992).4"
"2","The distinction between purely retrospective and forward‐looking voting behavior can be subtle, but it has important consequences for the incentives of politicians. If voters focus on sanctioning, they induce politicians to choose policies they believe to be best for voters, but if voters focus on selection, they instead induce politicians to demonstrate to voters that they are “good types,” even if that means ignoring their expertise and choosing policies they know to be detrimental to the public interest. Following this basic logic, a variety of formal models demonstrate that there are many conditions under which elections or reputational concerns provide perverse incentives for pandering (Canes‐Wrone, Herron, and Shotts 2001; Fox 2007; Fox and Shotts 2009; Maskin and Tirole 2004; Stasavage 2004). The models show that dual sources of asymmetric information combine to produce a problem of accountability for rational voters: politicians have better policy information, which they can use to benefit voters, but they fail to do so because forward‐looking voters reward them more for demonstrating they are good types than for producing good policies.5"
"3","The experiment implements a game of incomplete information that focuses attention on the strategic interaction between a politician, who makes policy decisions, and a voter, who decides on the politician’s electoral fate (Fox and Shotts 2009).6 To summarize the game, an incumbent politician first receives a signal about an uncertain state of the world and chooses a policy. Politicians privately know their own types and are also better informed than voters about policy consequences. Voters observe the policy choice and whether or not the choice was beneficial, which allows them to learn something about the politicians’ preferences and level of expertise, and then they choose whether to reelect the incumbent or elect a challenger. The winner of the election then makes a second policy choice and the game ends. Depending on their type, politicians care about policy or reelection while voters care about the pre‐election and post‐election policy choices.         "
"4","Game theory predicts two types of equilibria, one in which retrospective voting is observationally equivalent to forward‐looking behavior (because voters learn more about politicians’ expertise than they do about their preference congruence) and one in which it is not (because voters learn more about politicians’ congruence than about their expertise). In the latter equilibrium, voters condition their behavior only on the politician’s policy choice but not whether the policy choice was beneficial. This leads politicians to ignore their expertise and pander to voters."
"5","The sequence of actions in the game is as follows:"
"6","            "
"7","Nature chooses a state of the world, ω, which is either A or B, where .                  "
"8","Nature chooses the politician’s type, t (described further below), and the type for the challenger, c.                  "
"9","The politician observes t and a signal, s, about the state and chooses a policy, p, from A or B.                  "
"10","The voter observes p and ω and chooses whether to elect the incumbent (v=t) or the challenger (v=c).                  "
"11","Nature draws a new state ω′, and the winner of the election observes a new signal s′ and chooses a new policy p′.                  "
"12","The politician’s type is defined by a triple of three attributes, t= (tM, tP, tQ) where tM is motivation, tP is policy preference, and tQ is quality. Each attribute has two possible values. Motivation may be either office seeking (tM=MO) or policy seeking (tM=MP). Policy preference may be either pragmatic (tP=PP) or ideological (tp=PI). Quality refers to the accuracy of the politician’s information about the state of the world and is either perfect (tQ=QP) or noisy (tQ=QN). Let the distribution of each attribute be described by , , and . The probabilities for each attribute are assumed to be independent. If the voter elects the challenger, the challenger’s attributes are drawn from the same distribution.         "
"13","In general, the politician’s utility function takes on two values, x > 0 for “desirable” outcomes and 0 for “undesirable” outcomes, and depends on the type as follows. An office‐motivated politician prefers to be reelected (regardless of the other attributes). A policy‐motivated politician’s preference depends on the policy preference attribute, policy choice, and possibly the state. More specifically, policy‐motivated politicians who are ideological always prefer to choose policy p=B; policy‐motivated politicians who are pragmatic prefer to match the policy to the state (p=ω).         "
"14","In addition, following Fox and Shotts (2009), politicians’ preferences are assumed to be lexicographic. That is, policy‐motivated politicians care first and foremost about their pre‐election policy choice so that considerations of post‐election policy have no effect on their pre‐election behavior.7 For office‐motivated politicians, lexicographic preferences mean that if they are reelected, their preferences over post‐election policy depend on their policy preference attribute.8"
"15","In each period, the accuracy of the signal the politician receives depends on the quality attribute. Politicians with perfect information receive a completely accurate signal while politicians with noisy information receive an imperfect but informative signal. Formally,  and . The assumption that γ > α > 1/2 ensures that all politicians are better informed than voters.         "
"16","Voters want politicians to choose policies that match the state of the world both before (p=ω) and after (p′=ω′) the election. For each policy that matches the state, the voter receives utility y > 0 and otherwise receives utility 0.         "
"17","Fully rational behavior in this incomplete information setting is described by the concept of perfect Bayesian equilibrium, and there are two types of pure strategy‐perfect Bayesian equilibria in this game.9 Following Edmund Burke’s classic typology of representation, there is a trustee equilibrium where voters induce office‐motivated politicians to use (and therefore signal) their expertise to act in voters’ best interest. There is also a delegate equilibrium in which voters induce office‐motivated politicians to ignore their information and pander to voters (by choosing the same policy the voter would have chosen directly) in order to signal their preference alignment with voters and win reelection. It is important to note that because perfect Bayesian equilibrium assumes that voters are sequentially rational, voters in both types of equilibria are necessarily prospective and forward‐looking. This means that voter behavior in the trustee equilibrium is observationally equivalent to a retrospective (sanctioning) rule, but in the delegate equilibrium, retrospective and prospective behavior are distinct.            "
"18","In both types of equilibria, pragmatic types maximize the probability of choosing p=ω while ideological types only benefit if p=B. (The strategies of policy‐motivated politicians are the same in both equilibria because their payoffs do not depend on the voter’s action due to the lexicographic nature of their preferences.) This implies the following prediction about policy‐motivated politicians’ behavior.            "
"19","               "
"20","For any parameterization of the game, politicians who are policy motivated and pragmatic will follow their signals and choose p=s while politicians who are policy motivated and ideological will always choose p=B.                     "
"21","In either type of equilibrium, the strategies of office‐motivated politicians and voters are mutually dependent. To understand the logic of the strategic interaction between office‐motivated politicians and voters, first note that an office‐motivated politician’s optimal policy choice will depend critically on the voter’s decision rule. If the electoral reward is for outcomes (as in the trustee equilibrium), then they maximize the probability of reelection by choosing the policy to match the signal. If the electoral reward is instead for policy choices (as in the delegate equilibrium), then reelection is guaranteed when p=A.            "
"22","The basic principle underlying the voter’s decision is sequential rationality. Rational voters will reelect the incumbent if and only if they believe the incumbent is more likely to choose a good policy than would a randomly drawn challenger.10 While the general rule is intuitive, the details of the calculation are more complicated and involve two factors: preferences over politicians’ types (the probability that each type of politician will match the policy to the state in the second period) and the voter’s updated beliefs about the incumbent’s type. Because the motivation attribute (tM) has no effect on politicians’ post‐election policy choices, voters care only about the preference (tP) and quality (tQ) attributes of the candidate they elect for the second period.            "
"23","Although there are eight possible types of politicians, from the voter’s perspective these can be grouped into three effective types. Of these, the best type of politician—in terms of the likelihood of choosing good future policies—is one who is pragmatic with perfect information (PP, QP) because he or she will match the policy to the state with certainty. Pragmatic politicians with noisy information (PP, QN) are second best since they are the second‐most likely type to match the policy to the state (which occurs when their signals are correct with probability γ < 1). The worst types are ideological politicians (PI, QN or QP), who are the least likely to match the policy to the state (which occurs only when the state is B with probability 1 −α < γ).            "
"24","The final and most critical step in the voter’s calculation is to make correct inferences about the politician’s type using Bayes’ Rule, knowledge of the initial distribution of types, and expectations of politicians’ strategies. A key tension exists between the voter’s belief that the incumbent may be a pragmatic, perfectly informed politician (the best type) or an ideological type (the worst type). When the voter learns that the state is A, these beliefs both move in directions that point unambiguously to one of the candidates. If p=A and ω=A, the incumbent is both more likely to be the best type and less likely to be the worst type, so it is best to reelect the incumbent. And if p=B and ω=A, the incumbent is both less likely to be the best type and more likely to be the worst type, so it is best to elect the challenger. Whenever the state is B, however, beliefs move in directions that make the voter’s choice more difficult. That is, if p=B and ω=B then the incumbent is more likely to be pragmatic with perfect information but also more likely to be ideological. Similarly, if p=A and ω=B then the incumbent is less likely to be the best type but also less likely to be the worst type.            "
"25","The type of equilibrium reflects the way in which this trade‐off between types is resolved. In a trustee equilibrium, the voter learns enough about the politician’s quality to outweigh any concerns about the likelihood the politician is ideological. In this case, an outcome‐based voting rule is best: reelect the politician if and only if p=ω. Conversely, in a delegate equilibrium, the voter learns enough about the politician’s preference that considerations about quality are set aside. In this case, the voter infers from observing p=A that the incumbent is much less likely to be ideological than the challenger (even if the challenger might be more likely to have perfect information). Thus, in a delegate equilibrium, a policy‐based voting rule is optimal: reelect the politician if and only if p=A. The following hypotheses summarize the equilibrium predictions regarding the behavior of voters and office‐motivated politicians (and their dependence on πQ).            "
"26","               "
"27","If the prior probability that politicians have perfect information (πQ) is sufficiently high, then in a trustee equilibrium office‐motivated politicians will follow their signals (p=s) while voters will use an outcome‐based rule and reelect incumbents if and only if the policy matches the state (p=ω).                     "
"28","If the prior probability that politicians have perfect information (πQ) is sufficiently low, then in a delegate equilibrium office‐motivated politicians will always pander (p=A) while voters will use a policy‐based rule and reelect incumbents if and only if the policy is A. If πQ is extremely low, then this will be the only behavior observed.                     "
"29","For some values of πQ, there are multiple equilibria so that these hypotheses are not mutually exclusive. This is because when πQ is in a middle range, it is sufficiently high for a trustee equilibrium as well as sufficiently low for a delegate equilibrium. As stated in Hypothesis 3, however, game theory makes a unique prediction when πQ is especially low.11 Because the type of equilibrium depends on πQ, a comparative static prediction follows as a corollary of Hypotheses 2 and 3.            "
"30","               "
"31","If the prior probability that politicians have perfect information decreases, then delegate equilibrium behavior is more likely; office‐motivated politicians will be more likely to choose p=A and voters will be more likely to reelect incumbents when p=A.                     "
"32","It is important to reiterate that although the voter’s decision rule is observationally equivalent to a sanctioning rule in the trustee equilibrium and observationally equivalent to a selection rule in the delegate equilibrium, voters actually focus on selection in both types of equilibria (because they are assumed to be forward‐looking). The difference between motivations for using the outcome‐based decision rule in the trustee equilibrium and a true retrospective punishment‐reward rule cannot be overemphasized. When voters use the outcome‐based rule in the trustee equilibrium, they do so only because they want to elect higher‐quality politicians; they infer that when the policy matches the state, the incumbent is indeed more likely to be higher quality (that is, more likely to have perfect information). In contrast, voters will use the purely retrospective voting strategy when they want to induce good policy above all else—even at the cost of lower future‐expected utility from electing a bad type.            "
"33","The baseline experiment implements the accountability model in the laboratory to test whether behavior is consistent with game theoretic predictions.12 All experiments were conducted at the Pittsburgh Experimental Economics Laboratory at the University of Pittsburgh. In the baseline experiments, 88 subjects participated in five separate sessions, each session consisted of between 14 and 20 subjects, and each subject participated in only one session. All subjects were recruited through the lab’s centralized database.13"
"34","Upon arriving at the lab, subjects gave informed consent and were seated at separate computer terminals. All interactions between subjects took place anonymously through the networked computers using software programmed and conducted using z‐tree (Fischbacher 2007). Subjects received strict instructions not to communicate with one another in any way throughout the session. The instructions were presented on their computer screens and read aloud in order to induce common knowledge among the participants. Subjects also received a printed copy of the instructions, which they were encouraged to refer to as often as they needed, and then were given a quiz about the instructions in order to ensure comprehension. The quizzes were also administered through the computers so that subjects privately received immediate feedback about whether or not they answered the questions correctly, including the explanations of the correct answers. Consistent with the lab’s governance policy, no deception or false feedback was used at all in the experiment.            "
"35","Each subject participated in exactly one session and played the game 36 times, 18 times as a “politician” and 18 times as a “voter.” Each play of the game was described to subjects as a “round,” but they were explicitly instructed that each round should be considered as a “separate decision task.” Roles as politicians or voters remained fixed for six rounds at a time, and in every round, one politician was randomly matched with one voter. In order to minimize the possibility of reputation effects, the random‐matching protocol ensured that the expected number of times two subjects were paired throughout the session was approximately equal for any given pair of subjects.14 Thus, some subjects switched roles after a set of six rounds while others remained in the same role. The matching rule also ensured that subjects would gain experience with both roles in the first 12 rounds. In order to preserve anonymity, subjects were not informed of the ID number of the subject they were paired with in any round until after all rounds of the game were played.            "
"36","The subjects played a game that was strategically equivalent to the model described in the previous section. The only difference was that in the experimental game, the sequence of actions is simplified so that politicians chose only the first‐period policy. However, the games are isomorphic, and all of the predictions hold exactly. In every round, there was a 60% probability that the state was A () and a 67% probability that politicians with noisy information received the correct signal (). There was a 75% probability that politicians (both incumbents and challengers) were office motivated () and a 25% probability that politicians were pragmatic (). The probability that politicians had perfect information (πQ) varied by session. In two delegate‐trustee sessions (32 subjects total), πQ= 50% implies that there are multiple equilibria (Hypotheses 2 and 3 both apply). In three delegate sessions (56 subjects total), πQ= 10%. This value of πQ is low enough to guarantee that Hypothesis 3 is the unique prediction (that is, voters will never learn enough about the politician’s quality so that the policy‐based voting rule is optimal). Comparing the sessions with different values of πQ allows for a test of Hypothesis 4 (comparative static).            "
"37","To ensure that voter preferences matched the theoretical model, their payoffs are defined as the sum of a policy component and an election component. For the policy component, if the incumbent matches the policy to the state (p=ω), then the voter receives y= 150“tokens”; otherwise, the voter receives 0 tokens from the policy choice. For the election component, electing a pragmatic politician with perfect information gives the voter 150 tokens, electing a pragmatic politician with noisy information gives the voter 100 tokens, and electing an ideological type gives the voter 60 tokens.15 Thus, the minimum payoff in any round is 60 (when the policy does not match the state and the voter elects an ideological type) and the maximum payoff is 300 (when the policy matches the state and the voter elects a pragmatic perfect type). For politicians, the payoffs are x= 150 tokens for desirable outcomes (according to their type) or 0 tokens.            "
"38","Because the purpose of the experiment is to test voting behavior rather than to test abstract strategic thinking, the language used to describe and implement the game involved a moderate degree of natural and descriptive (but neutral) political context, rather than the abstract language typically used in game theory experiments. The two roles for subjects are described as those of “politicians” and “voters.” Politicians’ attributes are described as their “motivation,”“preference,” and “quality of information.” The pairs of attribute values are “office‐seeking” or “policy‐seeking,”“pragmatic” or “ideological,” and “perfect” or “noisy,” respectively.16 States, signals, and policy choices are described in terms of policies “A” or “B.” Finally, voters either “reelect the politician” or “elect the challenger.”            "
"39","After every round, the computer interface provides subjects with information about the round, including the subject’s own earnings from that round, the incumbent’s and the challenger’s attributes, the value of the true state, the politician’s choice, and the voter’s choice. Subjects find out only the results of their own play of the game and do not learn the results of any games played by other pairs of subjects."
"40","Earnings in the game were denominated in “tokens,” and subjects’ total earnings from all 36 rounds of the game were converted to dollars at the rate of $1 for every 300 tokens. Thus, politicians earn $0.50 in a single round for a “desirable” outcome (e.g., office‐motivated type getting reelected) and $0.00 for an “undesirable” outcome; voters earn between $0.20 and $1.00 in each round. Earnings were paid in cash, privately, to each subject at the conclusion of the experimental session and included an additional $5 “show‐up” payment. Total cash payments ranged from $15.85 to $25.95, with an average payment $21.81."
"41","The use of real‐world context is not typical of game theoretic experiments, so its use warrants further consideration. Most experimental tests of game theoretic predictions use abstract “context‐free” language for describing the decision tasks to subjects, such as labeling the players as 1 and 2 rather than as a “politician” and a “voter.” This is often because the mathematical structure of the games is deemed the most relevant for choice behavior. The actual labels are thought to be strategically irrelevant, and the use of context is sometimes thought to imply a lack of experimental control."
"42","But there are several reasons why context is not only appropriate, but also desirable. First, Hertwig and Ortmann (2001) argue that the key to experimental control is the use of a script (careful instructions that fully describe the game) and that such scripts may or may not involve context. Second, the use of real‐world context provides clues to help subjects recognize and interpret the game and allows them to draw on their previous experience in similar settings. Indeed, Loewenstein argues that “the context‐free experiment is … an elusive goal”—an abstract setting is simply an unfamiliar context—and that “the goal of external validity is served by creating a context that is similar to the one in which … agents will actually operate” (1999, F30–F31).17 Similarly, experiments with signaling games, which are games of incomplete information like the ones here, have shown that context increases the initial level of strategic play and acts as a substitute for experience (Cooper and Kagel 2003). Chou et al. (2009) also suggest that context leads to greater experimental control because it enables subjects to recognize the game as the experimenter intends. Thus, the use of context is not only consistent with experimental practice but also enhances internal as well as external validity.            "
"43","The upper two panels of Figure 1 show that when subjects play the role of policy‐motivated politicians, their choices conform to the equilibrium predictions, thus providing strong support for Hypothesis 1. Across all sessions in the baseline experiment, 95% of pragmatic types chose policy A when the signal was A, and only 17% chose policy A when the signal was B. Overall, 90% of pragmatic politicians’ choices were consistent with rational expected utility‐maximizing behavior (following their signals). Similarly, ideological types chose p=A in only 15% (p=B in 85%) of their opportunities. Note that although the decision problem for policy‐motivated politicians is nonstrategic, as their payoffs do not depend on the voter’s choice, their behavior nevertheless plays an important role in the inferences that fully rational, Bayesian voters make about the incumbent’s type. These results reassure us that simple incentives guide behavior in the way that rational choice predicts and that an important source of voters’ equilibrium beliefs is consistent with the theoretical prediction.            "
"44","Politician Behavior"
"45","The lower panel of Figure 1 shows that office‐motivated politicians generally follow their signals. When they receive the signal A, they overwhelmingly chose p=A in 95% of chances in the delegate‐trustee sessions and 90% in the delegate sessions. Since p=A when s=A is consistent with both types of equilibrium strategies, this result is consistent with both Hypotheses 2 and 3. The more discriminating situation is when s=B, where the two types of equilibrium strategies prescribe different behavior (p=A for pandering and p=B for following signals). In all sessions, subjects only chose policy A in 20% of their chances (19% in delegate only and 23% in delegate‐trustee sessions). Thus, instead of pandering, office‐motivated politicians generally followed their signals (85% in delegate sessions and 87% in the delegate‐trustee sessions). In the delegate‐trustee sessions, this behavior is consistent with Hypothesis 2. But in the delegate‐only sessions, the observed behavior is clearly inconsistent with the equilibrium prediction in Hypothesis 3. Such behavior may nevertheless be consistent with optimal strategic play—that is, it is a best response if voters always use an outcome‐based voting rule.            "
"46","Voting behavior is shown in Figure 2, and the results strongly suggest that voters indeed used an outcome‐based rule in both types of sessions. Voters reelected politicians when policies matched the state 95% of the time when p=ω=A and 87% of the time when p=ω=B. In contrast, when politicians chose a policy different from the state, voters reelected them at much lower rates: in 35% of all cases when p=A and ω=B and in 16% of cases when p=B and ω=A. While the observed outcome‐based voting rule is consistent with the trustee equilibrium (Hypothesis 2) in the delegate‐trustee sessions, it is clearly inconsistent with the unique equilibrium prediction (Hypothesis 3) for the delegate sessions. Thus, both politicians’ and voters’ choices are consistent with game theoretic predictions in the delegate‐trustee sessions but not the delegate‐only sessions.18"
"47","Voter Behavior"
"48","Even though there is no support for the delegate equilibrium point prediction (Hypothesis 3), is there any evidence to support the comparative static prediction that delegate equilibrium behavior is more likely in the delegate session than in the delegate‐trustee sessions (Hypothesis 4)? According to Hypothesis 4, politicians should be less likely to follow their signals in the delegate sessions, but we cannot reject the null hypothesis of no difference in behavior (p = 0.24, one‐tailed). In addition, voters should be less likely to use a retrospective (outcome‐based) voting rule, but neither can we reject the null hypothesis of no difference in voter behavior (p = 0.56, one‐tailed). Thus, there is no evidence that the distribution of politicians’ quality (πQ) affects behavior in the manner predicted by the theory. The remarkable consistency across the two types of sessions, especially of voter behavior, suggests that the equilibrium‐consistent behavior observed in the delegate‐trustee session may not have been because subjects properly deduced their best responses, which is one interpretation of Nash equilibrium theory.            "
"49","But Nash equilibrium theory does not necessarily require equilibrium play to come about purely by introspection. Instead, it can be interpreted as describing stable outcomes. That is, since nonequilibrium behavior is unstable (by definition), observed play should evolve over time toward the equilibrium, especially when the equilibrium is unique. The experimental data suggest otherwise. In the upper part of Table 1, the data are split into the initial and later periods when a subject makes choices as each type of politician. There are only two statistically significant differences in behavior. First, subjects are more likely to choose p=B in later periods than in their initial period as an ideological type. Second, they are more likely to choose p=A in later periods as office‐motivated politicians in the delegate sessions. While this may seem to suggest adaptation toward equilibrium behavior, the data also show that they are more, rather than less, likely to follow their signals, which is inconsistent with learning to play the equilibrium. In addition to showing the differences between initial and subsequent periods, Table 1 also reports trend coefficients from probit models with experience (number of previous rounds at the information set) as the independent variable. The probit estimates reinforce the conclusion that little or no learning takes place over time.            "
"50","Voter behavior over time is shown in the lower part of Table 1, which similarly divides choices into the initial and later periods for each information set and shows the estimated time trends. Across both the delegate and the delegate‐trustee sessions and at every information set, initial and overall choices throughout the experiment are statistically indistinguishable. The time‐trend estimates also show that there was no gradual adjustment of behavior over time. Thus, there is no evidence whatsoever that subjects adapted or learned to play the equilibrium. Instead, there is a stable behavioral tendency for voters to first use an outcome‐based voting rule and for them to adhere to the rule throughout the experimental sessions.            "
"51","Is it possible to pinpoint the source of nonequilibrium behavior? Perfect Bayesian equilibrium reflects a package of rationality assumptions. To what extent is behavior consistent with basic principles of rational choice, to what extent is it optimally strategic, and to what extent do subjects make correct inferences from the information they receive? Clearly, some observed behavior is consistent with rational expected utility maximization. The most obvious is the behavior of policy‐motivated politicians. Their decision problem is nonstrategic, and subjects’ choices in the experimental sessions were generally consistent with their simple incentive structure (Hypothesis 1), albeit with some noise."
"52","In contrast to the decision problem of policy‐motivated politicians, the problem faced by office‐motivated politicians is strategic. The best response for office‐motivated politicians is a function of how they anticipate voters will react. If subjects anticipate that they will be reelected for choosing policy A, then the optimal action is to choose A. If they anticipate reelection for choosing correct policies, then it is optimal to follow their signals. Although subjects’ choices as office‐motivated politicians were inconsistent with equilibrium predictions (Hypothesis 3), their choices were in fact best responses to the outcome‐based strategy actually employed by voters. The data therefore suggest that subjects were able to think strategically and to rationally anticipate how others would respond to the choices they made. Moreover, the fact that there was no distinction between initial and subsequent choices suggests that politicians may have chosen best responses as the result of introspection (thinking about the game) rather than through learning and adaptation.            "
"53","The principal source of nonequilibrium behavior therefore appears to be the voters’ decision‐making process. Even though politicians followed their signals in the delegate sessions, sequentially rational Bayesian voters would have maximized their expected utility by reelecting the incumbent whenever p=A and electing the challenger when p=B. Because there always exist beliefs such that retrospective voting is a best response, the data do not necessarily violate the sequential rationality assumption.19 Nevertheless, retrospective voting is a best response for voters in the experiment only if their beliefs are mistaken. More specifically, the policy‐based voting rule is a best response regardless of whether voters believed (e.g., through introspection) that office‐motivated politicians follow their signals with probability 1 or if voters correctly inferred beliefs from the empirical frequencies of politicians’ choices.20 The data from the baseline experiment therefore suggest that voters failed to use a policy‐based voting rule because they failed to correctly form beliefs about the incumbent’s type.            "
"54","Although subjects’ choices were neither consistent with equilibrium strategies nor with best responses to politicians’ empirical play, they were rather decisive. As noted above, they overwhelmingly reelected politicians who chose policies that matched the state, and there was a clear tendency to elect the challenger otherwise. The level of decisiveness which voters displayed suggests that one common approach to explaining departures from equilibrium, the quantal response equilibrium (QRE) concept of McKelvey and Palfrey (1995, 1998), may not be useful in this context. Nevertheless, it is worth considering the possibility because QRE does help to account for observed behavior in many games. The main idea of QRE is to allow for players’ best responses to be “noisy” rather than deterministic, but although it allows for “mistakes,” it retains the notion of equilibrium—that is, players’ probabilistic choices are best responses to others’ probabilistic best responses. In the logit AQRE, when ω=B, the probability of reelecting the incumbent when p=A is always greater than the probability of reelecting the incumbent when p=B.21 This implies that even noisy best responses are insufficient to cause voting behavior to approximate an outcome‐based or retrospective voting strategy. Thus, the results of the baseline experiment appear to be inconsistent with both perfect Bayesian equilibrium and quantal response equilibrium. The reason for this may be that both equilibrium concepts require beliefs to be consistent with Bayes’ Rule.            "
"55","To investigate possible explanations for retrospective voting behavior, I designed and conducted additional experimental treatments. One possible explanation is the cognitive complexity of the decision problem (Simon 1955): voters fail to make optimal decisions because the Bayesian inference and expected utility maximization problems they face are too difficult. Several treatments test this explanation. The policy information (PI) and information choice (IC) treatments investigate whether the presence of irrelevant information leads voters to use an inferential shortcut while the simplified type (ST) treatment tests whether reducing the complexity of the decision problem reduces reliance on the retrospective voting rule. Another possible explanation is that there is a norm or preference for accountability: voters use a retrospective strategy because they recognize that doing so induces politicians to utilize their information. This is also a form of bounded rationality because it fails to recognize the importance of selection incentives and therefore involves an error in reasoning. The forward payoff (FP) treatment explores the latter possibility.         "
"56","In each of the additional treatments, subjects play a modified version of the baseline game in which the hypothesized source of nonequilibrium behavior is removed. The game theoretic predictions for voter behavior in all of the modified games are equivalent to the delegate equilibrium prediction in which voters optimally use a policy‐based voting rule, so game theory provides the basis for the null hypothesis of no difference between the baseline and additional treatments. But if the behavioral hypotheses about the sources of retrospective behavior have merit, then voters will make choices consistent with the equilibrium more frequently in the additional treatments than voters did in the baseline experiment."
"57","In the delegate equilibrium, the optimal policy‐based voting rule is to reelect the incumbent if and only if the incumbent chooses p=A, regardless of the observed value of ω. Knowledge of ω is therefore irrelevant. But if voters are unable to make valid inferences about the relative probabilities of different types of politicians, they may not recognize this fact. Instead, if they are forward‐looking, they might incorrectly reason that because matching the policy to the state is a good outcome, good types are always more likely to have produced good outcomes than bad types. This line of reasoning may be stimulated by the mere presence of information about the state. That is, voters may be unable to ignore strategically irrelevant information (Healy, Malhotra, and Mo 2010), just as individuals are unable to ignore irrelevant information in forming evaluations and judgments in many other situations: e.g., “hindsight bias” (Fischhoff 1975), “outcome bias” (Baron and Hershey 1988), and the “curse of knowledge” (Camerer, Loewenstein, and Weber 1989).            "
"58","To test this possibility, I designed two treatments. The policy information treatment exogenously removes strategically irrelevant information and is identical to the delegate sessions of the baseline experiment except that voters only observe the policy p and do not observe the state ω. Note that because the politician’s incentives are identical to the baseline, the voter’s inference problem is identical to the baseline. However, if subjects condition their vote on the only information available to them (the policy choice), I expect that they are more likely to use a policy‐based voting rule than in the baseline.            "
"59","The presence of strategically irrelevant information is endogenous in the information‐choice treatment, which measures the extent to which voters (mistakenly) think that additional information is useful. In the IC treatment, voters first observe only the policy p, like in the PI treatment, but then choose whether or not to acquire information about the state by paying a small fee of 10 tokens before making a vote choice. In the perfect Bayesian equilibrium, voters would forgo acquiring information and use a policy‐based voting rule. I expect that subjects who are deterred by the information cost are more likely to use a policy‐based rule than in the baseline. On the other hand, if subjects believe that having more information is better and are willing to pay a small cost for it, then I expect those subjects to use the same outcome‐based voting rule they use in the baseline experiment.            "
"60","There were 36 subjects who participated in two sessions of the PI treatment and 30 subjects who participated in two sessions of the IC treatment.22 Table 2 compares the voting behavior of subjects in the baseline with subjects in the PI and IC treatments who only have strategically relevant information. The results show that when irrelevant information is exogenously removed in the PI treatment, subjects are more likely to use a policy‐based voting rule: they are more likely to reelect the incumbent when p=A and less likely to reelect the incumbent when p=B. The differences from the baseline are statistically significant, although their magnitudes are not overwhelming. In the IC treatment, where the absence of irrelevant information is endogenous, the small information cost was enough to deter most subjects (71%) from learning about the state. These subjects were more likely to reelect if p=A than in the baseline, but not any less likely when p=B. Interestingly, subjects were also more willing to purchase information about the state when the policy was B (35%) than when the policy was A (22%).23"
"61","Table 3 shows that subjects in the IC treatment who purchased irrelevant information about the state were somewhat more likely to use an outcome‐based retrospective voting rule than subjects in the baseline experiment. When the policy was A and correctly matched the state, subjects reelected politicians at every opportunity they had to do so (i.e., a 100% reelection rate). Conversely, when the policy was A but did not match the state, voters never reelected the incumbent. When the policy was B and correctly matched the state, the reelection rate was 96% and when the policy did not match the state, the reelection rate was 13%.            "
"62","The results of the PI and IC treatments indicate that the use of irrelevant information is partly responsible for retrospective voting, but that removing such information is not sufficient to induce subjects to use the optimal policy‐based voting rule. This suggests that other features of the inference problem may still pose a challenge for voters."
"63","In the baseline experiment, there are eight possible types of politicians but they take only two possible actions, so perfect separation of politician types is not possible. Applying Bayes’ Rule in this situation is neither straightforward nor intuitive. The simplified type treatment investigates whether the difficulty of the decision task is a factor that helps explain behavior (Kotovsky, Hayes, and Simon 1985; Simon 1990).            "
"64","The ST treatment simplifies the type space by reducing it to two types: politicians are either pragmatic or ideological, with each type equally likely. There is perfect correlation between the motivation and preference attributes so that pragmatic politicians are all office seeking and ideological politicians are all policy seeking, and both types have noisy information.24 All other parameters remained the same as in the baseline experiment so that voters received 100 tokens from electing a pragmatic type and 60 tokens from electing the ideological type (in addition to 150 tokens if p=ω).            "
"65","In the ST treatment, a delegate equilibrium exists. To see why, note that if pragmatic politicians always choose p=A and ideological politicians always choose p=B, then voters can perfectly infer the politician’s type from observing the policy choice. It is therefore sequentially rational to use a policy‐based voting rule and for pragmatic (office‐motivated) politicians to always choose p=A.            "
"66","However, no trustee equilibrium exists for any parameters of the ST treatment. To see why, suppose that pragmatic politicians follow their signals while ideological types choose p=B. Because politicians’ information about ω is always noisy, there is some probability that p=A and ω=B. When voters observe this, they infer (with certainty) that the politician must be a pragmatic type, as ideological types never choose p=A. The voters’ best response is therefore to use the policy‐based voting rule.25 But then if the voter uses a policy‐based rule, an office‐motivated politician who observes the signal B will deviate to choosing policy A (which guarantees reelection) rather than following the signal and choosing policy B (which does not).            "
"67","By reducing the type space, the voter’s Bayesian inference problem is much more manageable. It certainly does not require complicated numerical weighting of relative probabilities. However, understanding the equilibrium in the ST treatment still requires a degree of strategic sophistication because arriving at the correct posterior beliefs requires an understanding of politicians’ incentives. Nevertheless, reducing the complexity of the decision problem implies that voter choices in the ST treatment should be closer to the equilibrium predictions than in the baseline experiment."
"68","Figure 3 compares voting behavior in the ST treatment (two sessions with a total of 30 subjects) with the pooled data from the baseline. The data clearly support the hypothesis that simplifying the type space induces behavior that is closer to equilibrium. The reelection rate when p=A and ω=B more than doubles from 35% to 71% (, one‐tailed) while the reelection rate when p=ω=B decreases from 87% to 73% (, one‐tailed).            "
"69","                Simplified Type Treatment"
"70","Consistent with the equilibrium predictions, voters tended to reelect politicians who chose policy A, although their decisions continued to be affected by knowledge of the state (99% when ω=A but 71% when ω=B). Subjects therefore seemed to recognize that p=A and ω=B implies the incumbent must have been a pragmatic type.            "
"71","However, in contrast to the equilibrium, voters also continued to reelect politicians at a high rate when the incumbent correctly matched the policy B to state B (73%) even though they should have inferred that an ideological type was more likely to have chosen p=B. The application of Bayes’ Rule is relatively straightforward in this setting, although voters’ failure to fully conform to equilibrium behavior suggests that it remains unintuitive.26 It is unclear from the data exactly why voters continue to reelect politicians when p=ω=B, but it is likely the case that voters continue to have difficulty making correct inferences and that they fail to fully consider the strategic implications of politicians’ actions (Patty and Weber 2007).            "
"72","Another possible explanation for retrospective voting in the lab is that voters follow a norm or exhibit a preference for accountability: purposefully “rewarding” politicians for good outcomes and “punishing” them for bad ones. In other words, they might understand elections in terms of sanctioning and accountability and, moreover, recognize that purely retrospective voting encourages politicians to follow their signals, thereby maximizing the voter’s policy benefits. If so, then it may be that voters are either unaware of selection incentives or that they recognize them but forgo selection in favor of sanctioning."
"73","The preference for accountability implies “punishment” behavior that appears to resemble behavior in ultimatum game and collective action/public goods experiments that also violates sequential rationality (Fehr and Gächter 2000; Ostrom, Walker, and Gardner 1992), but this interpretation is problematic. Ultimatum bargaining involves a division or allocation of benefits, so subjects reject low offers because such offers are essentially unfair or too selfish. Similarly, subjects in public goods games are willing to punish free‐riding—another form of selfish or opportunistic behavior. In contrast, the electoral accountability game does not involve divisible benefits, so the motives for behavior do not readily admit a fairness interpretation.            "
"74","Furthermore, retrospective voting is not consistent with the interpretation that it involves “punishing” self‐serving behavior while “rewarding” other‐regarding behavior. To see why, suppose that office‐motivated politicians always follow their signals and consider the “bad” outcome where p=A and ω=B. In this case, the politician cannot have been an ideological, policy‐seeking type (the type that most resembles “selfish”) and instead must have had inaccurate information (regardless of whether he or she was office or policy motivated). In this case, voters “punish” the politician not for acting selfishly, but instead for acting in the voter’s best interest—that, given the politician’s information, maximized the probability of a good outcome for the voter. It just happened to be that the politician was “unlucky” to have had incorrect information. Conversely, when voters reelect the incumbent for the good outcome where p=B and ω=B, they “reward” ideological politicians for acting out of pure self‐interest (that is, aligned with the voter’s interest only by happenstance). Thus, although voters “reward” politicians for good outcomes and “punish” them for bad ones, the preference for accountability appears to be distinct from explanations of behavior in ultimatum game and public goods experiments; it is unlikely to be motivated by fairness concerns or to be a form of retribution for selfish behavior.            "
"75","To test whether a preference for accountability contributes to retrospective voting, the forward payoff treatment removes any temptation that voters may have to sanction an office‐motivated incumbent’s performance by making the politician’s policy choice completely irrelevant to the voter’s payoffs.27 That is, voters are only rewarded in the FP treatment for the type of politician that they elect to office. Thus, rational voters in the FP treatment must necessarily be forward‐looking. Whereas some subjects may have failed to consider the selection problem in the baseline experiment, they are now forced to confront it.            "
"76","The parameters in the FP treatment were the same as in the baseline delegate sessions except that the voter’s payoffs were rescaled so that the minimum payoff was 60 and the maximum payoff was 300 (the minimum and maximum voter payoffs in the baseline treatment). Voters received 300 tokens for electing pragmatic politicians with perfect information, 167 tokens for electing pragmatic politicians with noisy information, and 60 tokens for electing ideological politicians. The rescaling is an affine transformation of the original payoffs, so that the modified game is strategically equivalent to the baseline game in the delegate sessions. The perfect Bayesian equilibrium in the FP treatment is therefore the delegate equilibrium. Even if the results do not perfectly conform to the equilibrium, the preference for accountability hypothesis implies that voters will be more likely to reelect incumbents when p=A and ω=B and less likely to reelect them when p=B and ω=B in the FP treatment than in the baseline experiment. In other words, voters will be less likely to use a retrospective voting rule.            "
"77","Figure 4 shows that in two sessions (36 total subjects), voters indeed were less likely to use a retrospective rule than in the baseline experiment. When p=A and ω=B, voters are more likely to reelect the incumbent than in the baseline: the 52% reelection rate in the FP treatment is a 17 percentage point increase over the baseline (, one‐tailed). Similarly, when p=B and ω=B, subjects in the FP treatment are less likely to reelect the incumbent: the 66% reelection rate is 21 percentage points less than in the baseline (, one‐tailed). Although behavior in the FP treatment represents a significant decrease in retrospective voting behavior, the equilibrium prediction of a policy‐based voting rule (Hypothesis 3) can still be rejected since voters remain more likely to reelect incumbents when p=ω than when p≠ω. Nevertheless, the results provide support for the behavioral hypothesis that voters’ preference for accountability partly accounts for the behavior in the baseline experiment. But even when payoffs from past policy choices are removed and voters must necessarily grapple with the selection problem, they are unable to do so in a fully optimal Bayesian manner, which provides further support for the bounded rationality interpretation.            "
"78","                Forward Payoff Treatment"
"79","The experimental findings presented here pose a challenge for theories of democratic selection and, more generally, for theories of elections that emphasize voter learning. The formal theoretical literature is grounded in a clear and compelling logical argument that rational, forward‐looking voters will focus on selection (Alesina and Rosenthal 1995; Ashworth 2005; Ashworth and Bueno de Mesquita 2008; Fearon 1999), thereby inducing politicians to distort their policy choices and to pander (Canes‐Wrone, Herron, and Shotts 2001; Maskin and Tirole 2004; Stasavage 2004). Yet in a carefully controlled laboratory experiment that closely implements the strategic environment of a theoretical model, subjects do not fall prey to the “delegate trap.” Instead, there is a strong behavioral tendency to vote retrospectively, which in turn induces office‐motivated politicians to act in the voter’s best interest.28 While the findings do not imply that social scientists should entirely dispense with formal models of elections and electoral accountability (as game theoretic models are valuable for explicitly highlighting the strategic relationship between elites and masses), they do call into question important rationality assumptions. Future modeling efforts might retain core rationality assumptions while making suitable modifications in the vein of behavioral game theory (Binswanger and Prufer 2010; Camerer 2003; Schuett and Wagner 2007) or retain notions of goals and preferences while relying on alternative formulations of decision‐making processes such as heuristic or adaptive behavior (Bendor et al. 2011).         "
"80","Two causal mechanisms, both of which are supported by additional experimental analysis, explain why the observed behavior is inconsistent with the strong behavioral assumptions embodied in theoretical models. First, finding the optimal solution to the selection problem is a cognitively demanding task, especially when the solution requires strategic and Bayesian inference. Voters must ask themselves: if an incumbent chose a poor policy, was it because of a mistake or because of the politician’s divergent goals? And if the incumbent chose a good policy, was it because of luck or skill? Drawing the correct inference requires a great deal of cognitive sophistication, likely beyond the degree possessed by the typical citizen."
"81","In the face of cognitively difficult decision problems, boundedly rational individuals tend to fall back on simple decision rules. Traditional retrospective voting is certainly a simple decision rule: reward incumbents for good outcomes and punish them for bad ones. The simplified type treatment indicates not only that the complexity of the decision problem is a partial cause but also that strategic inferences are difficult to make even in relatively simple settings. The information choice treatment reinforces this conclusion."
"82","These results speak to recent debates about whether citizens learn in a “rational,” unbiased Bayesian manner (Bullock 2009; Gerber and Green 1998) or whether information processing is marked by partisan bias and motivated reasoning (Bartels 2002; Gaines et al. 2008; Taber and Lodge 2006). The experimental results suggest that even in the absence of partisan motivations, learning may fail to be fully rational or Bayesian because citizens make inferential mistakes and are unable to correctly utilize the information at their disposal.         "
"83","However, the experimental evidence also suggests that in addition to cognitive limits, a preference for accountability also causes retrospective voting behavior. That is, the data are consistent with the hypothesis that some subjects chose to hold incumbents accountable and thought of the voting problem as one of sanctioning rather than selection. Such reasoning is myopic and boundedly rational because it fails to take into consideration the effects of retrospective voting on future outcomes. When subjects were forced to consider the problem as one of selection in the forward payoff treatment, they were indeed more likely to reward politicians for choosing the correct action, but their behavior still did not come close to that predicted by sequential, Bayesian rationality."
"84","Although the strength of retrospective voting found in the lab is consistent with the voluminous empirical literature on economic voting (e.g., Kramer 1971; Nadeau and Lewis‐Beck  2001; Nordhaus 1975; Norpoth 1996), the results raise important concerns about the interpretation of observational analyses and the rationality of their behavioral underpinnings. First, the experimental evidence suggests a degree of bounded rationality that is inconsistent with not only formal theories but also with theories of prospective economic voting that require sophisticated voters to form rational expectations (e.g., Mackuen, Erikson, and Stimson 1992) or solve signal extraction problems (e.g., Duch and Stevenson 2010). Second, although Fiorina’s (1981) seminal analysis seemed to put to rest any notion that Key’s (1966) simple reward‐punishment theory should be taken seriously, the experimental results suggest that the traditional theory retains a degree of empirical validity.29"
"85","The interpretation of traditional retrospective voting as a heuristic employed by voters when faced with a cognitively complex inference problem also bears a resemblence to the standard rational choice interpretation of retrospective voting as an informational shortcut (Downs 1957; Fiorina 1981), but the interpretations differ in an important respect. In the rational choice interpretation, retrospective evaluations (and party identification in Fiorina’s formulation) are tools for maximizing utility, whereas in the bounded rationality view they are attempts to do so. Psychologists recognize that a heuristic may sometimes be an effective “fast and frugal” solution if it is well suited to the choice environment (e.g., Gigerenzer 2004) but in other situations may also lead to biases and judgmental errors (e.g., Tversky and Kahneman 1974). In the Fox and Shotts (2009) strategic setting, retrospective voting works well because it deters pandering and encourages politicians to act in voters’ interests, but for other types of policy, boundedly rational behavior may instead undermine accountability (Healy and Malhotra 2009).         "
"86","Under what conditions are voters more likely to rely on retrospective voting than other decision rules? Does the use of the heuristic vary with information about the link between policies and outcomes or with institutional variation in the policymaking process? What are the general conditions under which retrospective voting encourages good behavior by politicians? While there is some research that investigates the effectiveness of heuristics in nonstrategic voting environments (e.g., Lau and Redlawsk 2001), many questions about heuristic use in the strategic context of democratic accountability remain for theoretical and empirical investigation.         "
