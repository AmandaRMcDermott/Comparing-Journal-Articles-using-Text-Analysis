"","x"
"1","Social science scholars often work with data sets containing a large number of observations, many potential covariates, or (increasingly) both. Indeed, political scientists now regularly analyze data with levels of complexity unimaginable just two decades ago. Widely used surveys, for instance, interview tens of thousands of respondents about hundreds of topics. Scholars of institutions can quickly assemble data sets with thousands of observations using resources like the Comparative Agendas Project. Moreover, new measurement methods, such as text analysis, have combined with data sources, such as Twitter, to generate databases of almost unmanageable sizes. It is clear that political science, like all areas of the social sciences, will increasingly have access to a deluge of data so vast that it will dwarf everything that has come before."
"2","What statistical methods are needed in this data‐saturated world? Surely, there is no one correct answer. Yet, just as surely, traditional statistical models are not always equipped to take full advantage of new data sources. Traditional models—largely variants of linear regressions—are ideal for evaluating theories that imply specific functional forms relating outcomes to predictors. In particular, they excel in their ability to leverage assumptions about the data‐generating process, or DGP (additivity, linearity in the parameters, homoskedasticity, etc.) to make valid inferences despite inherent data limitations. Although appropriate when testing theories that conform with these assumptions, standard models are often insufficiently flexible to capture nuances in the data—such as complex nonlinear functional forms and deep interactions—when no clear a priori expectations exist."
"3","In this article, we introduce a family of tree‐based nonparametric techniques from the machine learning literature. We argue that, under specific circumstances, regression and classification tree models are an appropriate standard choice for analyzing high‐dimensional data sets. In particular, past research has shown tree‐based methods to be very useful for making accurate predictions when the underlying DGP includes nonlinearities, discontinuities, and interactions among many covariates. Further, tree models require few assumptions. Rather than imposing a presumed structure on the DGP, tree‐based methods allow the data to “speak for themselves.” Thus, our goal in this article is to introduce political scientists to this promising family of methods, which are well suited for today's data analysis demands."
"4","In the next sections, we discuss the promise and perils of high‐dimensional, “large”‐N data sets and introduce the basic logic of tree models. We then provide an overview of the most prominent methods in the literature. Next, we conduct three analyses that demonstrate both the advantages of tree models as well as their limitations. First, we conduct a simulation study to illustrate when tree‐based methods are most appropriate and their performance relative to alternatives. We then apply them to a data set with many potential explanatory variables to generate estimates of the probability of campaigns “going negative,” quantities that we subsequently use within a marginal structural modeling framework to estimate causal effects (Blackwell 2013). Finally, we replicate and extend Ghitza and Gelman (2013) and analyze a large collection of survey responses to estimate attitudes and behaviors of small demographic subgroups, which requires the efficient estimation of “deep” interactions between multiple covariates.         "
"5","Before moving on, it is important to note that the precise role of tree‐based models and other machine learning methods in the social science enterprise is an open question. Some scholars have argued that tree models are valuable tools for testing theories and estimating complex causal effects (e.g., Hill 2012; Imai and Strauss 2011). Yet, tree models were first and foremost designed for making accurate out‐of‐sample predictions rather than for testing theoretical claims. Moreover, the ability to “discover” subtleties in the data is not always a virtue. As we discuss below, the risk of confusing signal for noise in high‐dimensional data is very real, and for some tasks, tree‐based models are overly complex. If we are testing a theory adequately encapsulated by a parametric model, more traditional approaches are not only sufficient, but preferable. Lastly, large data sets and flexible models generally do not remove the burden from researchers for devising suitable theories and having a clear understanding about how predictors affect outcomes. Indeed, failing to take theoretical considerations seriously when building complex models often results in nonsensical findings (Lazer et al. 2014).         "
"6","Thus, in this article, we advocate for the expanded use of tree models for characterizing complex DGPs where the goal is not direct theory testing but rather accurate prediction. That is, we believe tree models can serve as appropriate standard choices when researchers' primary goal is to correctly capture the nuances of a potentially complex but unknown data‐generating process in a setting with many potential predictors related in nonlinear and interactive ways to the outcome. Superficially, our focus on prediction seems restrictive. As we show in our examples below, however, there are many instances in which tree models can contribute meaningfully to essential social science tasks, including estimating causal effects and improving measures of latent traits.         "
"7","When building predictive models using large data sets, quantitative scholars face two countervailing pressures. First, one wishes to leverage the richness of the data to correctly capture the data‐generating process (DGP), thus avoiding model misspecification. A good model would allow for a large number of possible covariates and for complex interactions between them. So too it would allow for nonlinear functional forms and even discontinuous shifts in how a set of covariates is related to outcomes."
"8","The second (and contrary) need is to avoid overfitting the data, a goal sometimes labeled regularization. Overfitting occurs when the model is so complex that it makes predictions based on idiosyncratic features of the data unrelated to the true DGP. In other words, we confuse the noise and the signal in our data, leading both to poor out‐of‐sample predictive performance and an incorrect understanding of the DGP. Overfitting, of course, is a potential problem for any statistical method, but it is particularly endemic for models that contain a large number of predictors, flexible functional forms, and deep interactions.         "
"9","To understand how the goals of flexibility and regularization are at odds, consider a hypothetical example with N = 600 observations of a single outcome variable (y) with two possible predictor variables (). Assume further that the predictors, which take on just 10 integer values, are distributed uniformly. How do we then determine what value of y should be associated with each unique combination of the covariates?         "
"10","One naïve proposal might be to model the outcome based on the average value () observed for each unique combination of the categories in x1 and x2, or “region.” This fully interactive specification would be the ultimate in flexible models, allowing for almost any possible relationship between the covariates and the outcome. The problem, however, is that there is generally not sufficient data to execute this strategy. Figure 1 shows the number of observations that appear in each region in one simulated data set. In this example, the median region has just six observations, and the maximum number of observations in any region is 13. With so little data in each region, we increase the risk of overfitting.         "
"11","Thus, even in a relatively simple world with only two covariates and a modestly large sample size, there is not sufficient data to make valid predictions about the expected value of y for each region. Obviously, this problem becomes exponentially worse as variables are added. With three similar covariates, there would be 103 = 1,000 possible regions, meaning that the majority of regions would be empty. Indeed, it is clear that in a data set with just 20 covariates, even “big data” on the grandest imaginable scale will not be big enough for this strategy to succeed.         "
"12","Standard parametric models circumvent this problem by making assumptions about the DGP. Common regression models, for instance, assume that the value of y increases as a linear function of the (possibly transformed) covariates. The advantage is that we can accurately recover relationships between the covariates and the outcome despite the sparsity of data in each region. The disadvantage is that they eradicate aspects of data that do not conform with their underlying assumptions.         "
"13","The trade‐offs involved are illustrated in Figure 2. The upper‐left panel shows the true DGP for the 600 observations shown in Figure 1. The upper‐right panel shows the estimates generated by the naïve approach of estimating  for each combination of x1 and x2. As expected, this approach leads to significant overfitting: Estimates fluctuate wildly in response to random error rather than the true DGP. On the other hand, the bottom panels show estimates from a simple linear model and a model with polynomial terms and interactions. In both, the estimated relationships between the covariates and the outcome are clearly inadequate and would lead researchers to an incorrect understanding of the DGP.         "
"14","True and Recovered Relationships in Simulated Data"
"15","Note: The true DGP is , where . The simple linear model is , whereas the complicated model is  (where poly is the sequential polynomial‐generating function, d is the highest degree generated, and the × operator generates all main effects and interactions).                     "
"16","Tree‐based models are members of a growing class of methods from the machine learning literature designed to yield a balanced solution to this dilemma—allowing flexible functional forms while avoiding overfitting. Their goal is to specify regions of the covariate space such that the outcome is homogeneous and the number of observations in each region is sufficiently large, yet where the regions themselves are sufficiently numerous and unstructured to allow for complex relationships between covariates and the outcome. In this way, tree‐based models are related to neural networks (Beck, King, and Zeng 2000), kernel regularized least squares (Hainmueller and Hazlett 2014), and other nonparametric techniques.         "
"17","While each of these approaches has its own advantages, tree‐based methods are particularly attractive in offering versatility and ease of use. Tree models are highly flexible, easily accommodating common problems such as missing data, interactions between many variables, and both continuous and discrete outcomes. Further, tree models are easy to interpret relative to other “blackbox” techniques, such as neural networks, although interpretation remains a challenge relative to, say, generalized additive models (Beck and Jackman 1998). Finally, although tree‐based methods perform best when irrelevant variables are excluded, they are relatively adept at ignoring uninformative predictors. While imperfect—inevitably, some irrelevant predictors are chosen in splitting rules—tree‐based methods tend to produce relatively parsimonious models even when offered many uninformative predictors.         "
"18","Although tree models are not unknown in the discipline (e.g., Green and Kern 2012; Imai and Strauss 2011; Kastellec 2010; Muchlinski et al. 2016), they have appeared rarely. At the same time, they are now “go‐to” models in literatures focused on prediction and classification (Hastie, Tibshirani, and Friedman 2009). Our aim in the next sections, therefore, is to introduce the most prominent tree models and showcase their potential in analyzing political science data.         "
"19","At their core, tree‐based models involve two basic steps.1 First, they divide the covariate space into B nonoverlapping and exhaustive regions, , that are relatively homogeneous with respect to the outcome y. Second, they make a prediction, , for all observations that fall within region .         "
"20","To understand this more clearly, consider the classification and regression tree (CART) model. Its first step consists of partitioning the covariate space into (hyper)rectangles. The left panel of Figure 3 displays a partition of a two‐dimensional covariate space into 14 nonoverlapping and exhaustive regions using the same data as depicted in Figure 2. Each region corresponds to unique covariate value combinations, which can be succinctly represented in the form of a binary tree (shown in the central panel of Figure 3 for our example). At each internal node of the tree, the covariate space is split into two distinct regions depending on the splitting rule associated with the node (e.g., ).         "
"21","The terminal nodes, or “leaves,” of the tree correspond to the regions, and constant predicted values () are assigned to each region/leaf. For a continuous outcome variable , CART defines this constant as the mean outcome for all observations within region  ().2 Thus, the model produces a prediction surface for every possible combination of the explanatory variable values. For instance, the right panel of Figure 3 shows the predicted “response surface” corresponding to the regions defined in the left and center panels for our running example. More formally, a tree model for J covariates is a function            "
"22","Choosing Θ optimally will yield a response surface that accurately captures the true relationship between the covariates and the outcome y while avoiding overfitting. Accurately retrieving the response surface is an optimization problem, namely,            "
"23","Since finding the best partition and predicted value combination for a given loss function is computationally prohibitive, CART adopts a heuristic known as recursive binary splitting to find an acceptable solution. This procedure is described in more detail in the supporting information.         "
"24","For all its simplicity, CART is likely to fail in terms of preventing overfitting (Sutton 2005). After all, a tree with the same number of nodes as observations will produce a prediction surface that exactly matches observed outcomes, and that thus wildly overfits the data (as in the naïve example in the second section). A common strategy is to grow large trees and then “prune” them (Breiman et al. 1984). Complexity pruning involves finding a subtree T that minimizes the quantity , where  is the loss function, B is the number of terminal nodes, and  is a prespecified parameter that controls the trade‐off between tree size and fit.         "
"25","The advantage of CART models is that they can be built quickly and are relatively easy to understand and interpret. Depictions of binary trees are a very intuitive means of conveying modeling results (see, e.g., Kastellec 2010, 216). Moreover, single‐tree models easily accommodate complicated interactive relationships, continuous and discrete predictors, and large numbers of irrelevant predictors. However, single‐tree models perform very poorly when uncovering additive relationships (Fox 2000). Further, the algorithmic approach to building a tree leaves us with no means for assessing uncertainty in our estimates. Finally, the sequential nature of the binary recursive splitting algorithm means that the structure of the tree is often highly sensitive to small changes in the observations included.         "
"26","Fortunately, the intuitive logic behind single‐tree methods can be extended in order to successfully address these drawbacks by combining multiple trees that are aggregated to create superior ensemble models. In the next section, we review three methods for creating tree ensembles before turning to our empirical illustrations."
"27","Ensemble methods combine multiple trees of the type defined in Equation 1 in order to better approximate the outcome surface while reducing overfitting. Their general form is            "
"28","Tree bagging—short for bootstrap aggregating—relies on the fact that single‐tree methods can result in very different predictive surfaces depending on which observations are included. This is particularly true with “deep” trees with many terminal nodes. The intuition behind tree bagging is to conceptualize trees fit to different subsets of data as if they were independent draws of a random variable. By this logic, we can reduce the variance in single‐tree estimates of the response surface by fitting many trees and combining them as defined in Equation 2. To the extent the independence assumptions hold, this ensemble model will provide a low‐variance, low‐bias estimate of the true response surface. More formally, tree bagging takes multiple simple random samples of the same data set (with replacement), of size equal to that of the original data set. It then fits a deep tree (with no pruning) to each bootstrapped sample. For M samples, the tree‐bagging model is then .            "
"29","Although the power of tree bagging stems from the assumed independence of the trees, in practice, trees are highly correlated. Random forests (RF) address this pitfall by systematically lowering the level of correlation between trees (Breiman 2001). Specifically, at each splitting stage of the tree‐growing algorithm, the RF selects an optimal splitting rule based on only a random subset of  of the covariates. Moderately small values of a reduce the correlations among trees and improve the performance of the ensemble.            "
"30","While superficially similar to bagging and random forests, tree boosting approaches the problem of creating multiple trees from a very different angle. First, the bagging procedure creates trees independently. Boosting, on the other hand, builds trees sequentially, such that each new tree improves the predictive power of the ensemble. Second, whereas bagging relies on fitting trees to random samples drawn from the data, boosting relies on fitting trees to transformations of the data. The result is a procedure that grows new trees specifically aimed at accommodating observations that the existing ensemble predicts poorly.            "
"31","Boosting approximates a solution to the problem of fitting a sum of trees by adding new trees one at a time, while keeping all existing trees unchanged. At each stage m of this forward stagewise process, boosting solves               "
"32","While the intuition behind boosting is straightforward, optimizing Equation 3 is not. However, the approximating procedure of choice—known alternatively as gradient boosting, multiple additive regression trees (MART), or gradient boosting machines (GBM)—is both extremely accurate and fast. In short, at the mth stage of the process, GBM fits a new tree to the negative gradient of the loss function (). That is, it approximates a solution to Equation 3 with               "
"33","This strategy can create arbitrarily accurate models simply by increasing the number of trees. To prevent this, researchers can prespecify two parameters, in addition to selecting the number of trees. First, we can choose the number of terminal nodes in each tree, denoted B. Note that, given the additive form of GBM, the choice of B also determines the maximum order of interactions in the model—an upper limit that is usually justified substantively, and therefore held fixed at some (preferably low) level. Second, the regularizing role of B is complemented by tree shrinkage, which is achieved by scaling the contribution of each new tree by a factor, , such that the running sum becomes . Setting ν close to zero limits each new tree's contribution to the model's prediction, which in turn increases the number of trees that need to be fit in order to approximate the outcome surface. Intuitively, setting ν to a low value allows the expansion to “learn” the outcome surface slowly (Hofner et al. 2014). On the other hand, setting ν too low can lead to slow rates of learning. In practice, it is common to preset both ν and B and find an optimal number of trees using cross‐validation.            "
"34","Bayesian additive regression trees (BART) are similar to GBMs in that trees in the ensemble are grown to accommodate residuals of the current fit rather than outcomes themselves. Further, the contribution of each tree to the entire fit is regularized so that no one tree dominates the prediction of the response surface. Unlike GBMs, however, tree‐growing and regularization goals are achieved by assuming that the parameters that govern tree construction can be estimated under a hierarchical Bayesian framework (Chipman, George, and McCulloch 2010). This provides both estimates of their expected predicted values and, uniquely, measures of uncertainty.5"
"35","The definition of BART begins by replacing Equation 2 with               "
"36","Relying on a Markov chain Monte Carlo algorithm, BART explores the space of all possible “forests” with M trees, producing a sample of M trees at every step and, with it, a sample of the outcome variable given predictors . So, for instance, if we specify that the model should have 100 trees, BART creates a posterior sample of the 100‐tree models that are likely given both the observed data and our priors. We can then summarize the posterior predicted outcomes in terms of their expected values and variability across draws. The result is a highly flexible, data‐responsive ensemble method, which produces measures of uncertainty in the very process of finding a sum of trees that accurately reproduces a given outcome surface (Hill 2012).            "
"37","In this section, our primary goal was to provide well‐grounded intuition as to how tree‐based models work. However, we provide additional discussions of some important practical considerations in our supporting information, including information about available R packages, approaches to choosing tuning parameters, and ideas of how to interpret the substantive effects.            "
"38","We now provide three examples that showcase the advantages of tree models while also illustrating their relative strengths and weaknesses. First, we evaluate the performance of CART, RF, GBM, and BART models using synthetic data and compare them with several alternative approaches. Second, we use GBM and BART to predict when campaigns will engage in negative advertising. This example illustrates the advantages of tree models when the researcher's primary aim is to accurately recover the response surface for a specific outcome. We use these predictions to estimate the causal effect of negative campaigns on vote share in U.S. elections using the strategy outlined in Blackwell (2013). Finally, we replicate and extend the estimation of subgroup attitudes and behaviors in U.S. elections conducted by Ghitza and Gelman (2013) to illustrate the ability of tree methods to model deeply interactive relationships.         "
"39","We begin by creating 40 different potential covariates—including symmetric and asymmetric variables, continuous and categorical variables, and correlated and independent variables.7 We then create outcomes under three different data‐generating processes (DGPs): an additive and linear specification; a specification with both additive terms and interactions; and a more complicated specification that contains additive terms, interactions, nonlinearities, and discontinuities. In each case, we also ensure that at most 4 of the 40 features are actually related to the outcome of interest, and that each outcome contains some amount of Gaussian error. Finally, for each DGP, we create 100 training sets of 500 observations and a single test set with 3,000 observations. We use these test sets to evaluate the relative predictive strengths of the different methods.            "
"40","We fit four different tree‐based models to each of the training sets: CART, RF, GBM, and BART. In addition, we fit three non‐tree‐based models for comparison purposes: a (Gaussian) kernel‐regularized least squares (KRLS) model, a single‐hidden‐layer neural network (NN), and a generalized additive model. Each of these models requires that we preselect various “tuning” or regularization parameters. For the BART model, we use the recommended default values for the model's prior hyperparameters discussed in Chipman, George, and McCulloch (2010).8 KRLS uses an automated leave‐one‐out cross‐validation procedure to choose its parameters. Further, for the Generalized Additive Model, or GAM, we used a thin plate to smooth over the preidentified relevant covariates in each DGP. This strategy allows us to show just how well tree‐based models perform even compared to an unrealistically well‐specified GAM.9 Finally, for the CART, RF, GBM, and NN, we conducted a fivefold cross‐validation to choose tuning parameters for each model for each of the 100 training sets.10 For the tree models, we searched over the parameter values shown in Table SI‐2 in the supporting information.11"
"41","To evaluate the relative performance of each, we calculate the out‐of‐sample root mean square error (RMSE) by first fitting the model using data from each of the 100 training sets and then evaluating their predictive accuracy using the test set. This results in 100 RMSE values for each model, for each DGP. To provide a meaningful scale to these RMSE values, we normalize them by the best observed RMSE, producing relative RMSE (RRMSE) measures. Thus, an RRMSE of 1.5 would indicate that a model has performed 50% worse than the best observed individual fit, and values closer to 1 indicate better performances.            "
"42","Figure 4 presents box plots of the relative RMSE distributions across the 100 training sets, with a reference line indicating the relative RMSE achieved using a mean model (i.e., a model that predicts test observations using the mean of the test outcome). Distributions corresponding to tree‐based models are shaded in gray.            "
"43","Relative RMSE across 100 Training Sets for Each Model and Each DGP Specification"
"44","Note: Lower values indicate better relative predictive accuracy with respect to test outcomes. The dashed vertical line indicates the RRMSE of a model that simply predicts the mean value of y in the test set (i.e., a mean model). GAM is estimated by smoothing over known predictors independently, and it should therefore be understood to have an unfair advantage over all other models.                        "
"45","The left panel shows the results when the underlying DGP is a simple additive relationship between the covariates and the outcome. Unsurprisingly, a smoothed linear model (viz., GAM) can outperform all others when its underlying assumptions are met. More interestingly, the tree‐based models actually perform comparably well—even without the unfair advantage enjoyed by the GAM model. GBM, for instance, has a median RRMSE that is less than 5% larger than the best GAM, and BART performs similarly well on average. As discussed in the supporting information, the major shortcoming of single‐tree CARTs is their inability to pick up the additive portions of a DGP—an issue illustrated by being one of the worst‐performing models when confronted with a strictly additive DGP. RF tends to do much better than single‐tree models in terms of predictive variance, but it still shares CART's weakness in performing relatively poorly for strictly additive DGPs."
"46","Across the remaining two panels, tree‐based models—particularly tree ensembles—perform consistently well in comparison to other strategies. The other models are either less consistent or make poor predictions through insufficient regularization. The tree ensemble models show relatively good predictive performance under a DGP typical in political science research (viz., the additive and multiplicative DGP used in the central panel of Figure 4) and do even better when the DGP is simultaneously additive, multiplicative, nonlinear, and discontinuous.12 Gradient‐boosted tree ensembles perform well under all circumstances, followed closely by BART and random forests. Overall, then, tree‐based models are shown to perform well under a variety of data‐generating circumstances, offering very little room for researcher manipulation of model specifications and results. We next turn to providing examples of how these models can be incorporated into political science research.            "
"47","When studying dynamic processes, researchers wishing to make valid causal inferences are often faced with a difficult dilemma. On the one hand, failing to include important covariates leads to omitted variable bias. On the other hand, including many of the most important covariates in a dynamic setting may induce posttreatment bias."
"48","To address this concern, Blackwell (2013) outlines a marginal structural modeling (MSM) approach for estimating the effects of time‐varying covariates by relying on estimated inverse probability of treatment weights (IPTW). Blackwell (2013) applies this framework to estimate the effect of negative campaigning during the 5 weeks prior to the election on the two‐party vote share for 144 Democratic candidates in the election cycles between 2000 and 2006. Specifically, the action sequence of interest is whether the candidate has “gone negative” in a given week. We direct interested readers to Blackwell (2013) for a fuller discussion and provide a brief summary of the data and methods here.            "
"49","Assume that for observation i at time period t, we observe action , which represents, for instance, whether campaign i engaged in negative campaigning in week t. To implement the MSM method, one can take the following steps: (1) Estimate the probability of the observed action based on a vector of confounders  and lagged values (), denoted ; (2) Estimate the probability of the observed action based only on a vector of lagged values , denoted ; (3) Calculate the “stabilized weight” for each observation as               "
"50","The critical step is to build a “correct” model of the action sequence . Accurately modeling  is especially important given that the MSM approach requires a sequential ignorability assumption, which states that the weights reflect the influence of all relevant time‐varying covariates. Thus, MSM represents another instance of an increasingly common scenario in political science research where we wish to build models that provide accurate predictions for specific outcomes, but the set of covariates and the functional forms relating them to outcomes are not of direct substantive interest.13"
"51","The problem, of course, is that deciding on the appropriate set of covariates, interactions, and specific functional forms for this model is an uncertain process. For instance, Blackwell (2013, 513) writes, “In order to satisfy the assumption of sequential ignorability, we must gather as many covariates as possible that might influence the decision to go negative ... and are correlated with the election outcome.” Building correctly specified models using traditional methods comes with a number of serious challenges and drawbacks. To begin with, there is a concern that researchers may search the space of potential model specifications until they arrive at one that generates weights that confirm their theory. Further, researchers may feel pressured to include a large number of potential covariates in the specification, which can lead to overly complex models. Tree‐based methods offer a number of advantages to building models that accurately capture response surfaces in these settings, and they do so while requiring minimal researcher intervention in terms of choosing appropriate functional forms or relevant covariates.14"
"52","To illustrate this, we replicate the analysis in Blackwell (2013) using two of the best‐performing tree‐based models in our simulation study above: BART and GBM. As a first step, we replicate the models in Blackwell (2013). Originally, the numerator in Equation 6 was estimated using a logistic regression. However, the denominator quantities in Equation 6 were estimated in separate GAM models for incumbents and nonincumbents. The predictors included in all three of these models are shown in Table 1. The full model specification, which includes several interactions and nonlinear smoothing, is shown in the supporting information.            "
"53","In all, the models included in Blackwell (2013) for calculating the weights are quite complex, requiring the construction of multiple models for subsets of observations as well as specifying multiple interaction and nonlinearities. As in all modeling exercises, these and many other choices must be made by researchers and then justified to readers. However, given the large number of possible model configurations and space constraints in standard articles, not all decisions can be adequately explained. Why, for instance, should we include lagged indicators for negative campaigning from the previous two periods but lagged polling data from only one previous period? Why not interact polling data with the number of weeks left before Election Day? We expect that these choices were made based on a deep familiarity with the data. Nonetheless, we believe that this is an example of a situation where relying on tree‐based methods may provide an approach to model building that is easier to implement and to justify in terms of out‐of‐sample predictive power.            "
"54","To construct our tree models, we first specified the set of potential predictors. The factors included for the numerator in Equation 6 in Blackwell (2013) were chosen for theoretical reasons, and we follow these recommendations. For the denominator, however, we expand the list of covariates to include the full set of 26 variables. Further, we estimate only a single model for incumbent and nonincumbent Democrats, relying on the models themselves to adequately capture any differences across groups. As noted above, the treatment of interest is whether a Democratic candidate has “gone negative” in a given week. Thus, the outcome is a binary indicator for negative advertising as measured for 2,598 candidate‐weeks.            "
"55","After specifying predictors, the next step consists of selecting appropriate tuning parameter values.15 For GBM models, it is best to obtain these values using some form of cross‐validation. Although BART can in principle be cross‐validated, its default parameters have performed very well in a wide variety of settings. Accordingly, we estimate a GBM model using the best‐fitting parameters resulting from a tenfold cross‐validation (viz., number of trees , tree depth ).16 We estimate the BART model using the recommended default parameter settings (see note 8).            "
"56","The next step is to asses the quality of the model fit. For tree‐based models, it is crucial that model fit be assessed based on out‐of‐sample properties since it is possible to arbitrarily improve in‐sample fit by allowing for increasingly complex models. In this case, we calculate fit statistics based on, first, a (separate) tenfold cross‐validation of the same data used for choosing the tuning parameters. Second, we calculated fit statistics using 10% of the original data that were randomly selected to be held back during the process of choosing tuning parameters. Fit statistics for both analyses are shown in Table 2.            "
"57","The first column of Table 2 shows that the predictions from each of the models are highly correlated. Yet, the remaining columns show that the GBM and BART models, despite requiring fewer decisions from the researchers, provide more accurate predictions. Specifically, the Brier scores17 are lower for GBM and BART. Further, the areas under the receiver operator curve (AUROC), sensitivity curve, and specificity curve are all higher for the tree models. In general, therefore, these results indicate that the tree models are to be preferred in terms of out‐of‐sample predictive performance.            "
"58","Although the predictions for specific candidate‐weeks are highly correlated, the product in Equation 6 means that even small differences in predictions can cumulatively lead to different weights.18 These differences are of substantive consequence. Table 3 shows the estimated effect of negative campaigning in the 5 weeks leading up to the election on two‐party vote share for the 144 elections in the data set. Following Blackwell (2013), we estimate separate coefficients for incumbents and nonincumbent candidates. (Full model specifications are shown in the supporting information.)            "
"59","The estimated effect of negative campaigning on vote share as well as bootstrapped confidence intervals for the unweighted regression and the GAM‐weighted regression are shown in the top rows of Table 3. From these competing estimates,19 Blackwell (2013, 514) concludes that the GAM‐weighted MSM uncovers effects that are at odds with previous findings, suggesting that going negative has a discernibly positive and large effect on the vote share of nonincumbents, while having no reliable effects for incumbents.            "
"60","In contrast, the bottom rows of Table 3 show that with more accurate predictions of the action sequence estimated using tree ensembles, the MSM estimates are less divergent from previous findings. Specifically, while the effect of negative advertising for nonincumbents is also positive and reliably discernible from zero at (approximately) the less stringent 90% level, the effect sizes are roughly 20% smaller than those reported in Blackwell (2013). In turn, when considering incumbents, the tree‐weighted MSM models retrieve effects that are negative, large, and reliably distinguishable from zero.            "
"61","Although survey data can provide important insight into how different sociodemographic traits covary with political attitudes and behaviors, it is rarely the case that surveys are deployed at the level needed to produce estimates at the lowest levels of aggregation. For instance, how does one estimate the propensity to vote of white non‐Hispanic men from Oregon? While such information may be of interest to campaigns or researchers, these quantities are difficult to estimate given standard techniques."
"62","To create such estimates, Ghitza and Gelman (2013) use a model‐based approach that produces estimates for small subpopulations using aggregate survey data. Treating subpopulations as cells in a cross‐tabulation of sociodemographic and geographic traits, Ghitza and Gelman (GG) use multilevel models to estimate values as a function of these covariates (and their interactions), producing predicted cell values that are then reweighted (or poststratified) using census‐based population counts to produce final estimates. Specifically, GG correctly argue that the multilevel and poststratification (MRP) approach improves upon previous strategies “by modeling deeper levels of interactions and allowing for the relationship between covariates to be non‐linear and even non‐monotonic” (2013, 773). While the benefits are clear, important questions remain unaddressed: Which demographic variables should be included when estimating attitudes with respect to different political issues? Are all cells different enough to warrant estimation of different values, or are some interactions not relevant? In general, questions of model specification in MRP models remain very important but largely unaddressed (Warshaw and Rodden 2012).            "
"63","Given that tree ensembles are particularly well suited to model precisely these types of relationships (i.e., those that are highly interactive, nonlinear, and nonmonotonic), we argue that they should provide an even better alternative to multilevel models when it comes to estimating quantities of interest for small subpopulation groups. Indeed, as GG clearly articulate, current implementations of MRP struggle to estimate models with saturated, high‐order interactions on large data sets. As we show below, however, tree‐based methods can quickly and reliably estimate models with even deeper interactions than MRP, letting “the data define the appropriate level of nonlinearity and interaction between covariates” (Ghitza and Gelman 2013, 773).            "
"64","To compare the performance of tree models to MRP, we implement an off‐the‐shelf (i.e., using the default parameter definitions) estimation of BART models on the same data as GG, including the same corrections for survey weights and self‐report bias. The data consist of respondents to three waves of the National Annenberg Election Survey (NAES) for 2004 (N = 43,970) and 2008 (N = 19,170) and uses respondents' state of residence, ethnicity, income, and age to model turnout and support for Senator John McCain. While both outcomes are continuous, all predictors are categorical variables that are then contrast‐coded to obtain a set of 64 binary predictors. More details of the model definition are given in Ghitza and Gelman (2013) and in the supporting information.            "
"65","As a first step, we estimated a model using only the covariates included by GG. A simple comparison of the turnout and vote intention estimates for the subpopulations generated by the poststratified BART and MRP models using these data reveals that they are nearly identical. The correlations between the estimates generated using each method are .976 for the turnout and .975 for the vote choice."
"66","However, the advantage of a poststratified BART is its ability to produce truly deep interaction models when the data call for them. To illustrate, consider a model that allows for interactions between state, ethnicity, income, age, sex, education, marriage status, and whether a person has children—the full array of demographic variables contained in the GG data set, which could not be included in their MRP implementation for computational reasons. BART is able to easily estimate such a model, producing interactions whenever the data support them in a way that requires minimal researcher intervention."
"67","The results reveal even more nuance than GG's model originally displayed. For instance, GG focus on African American voters in North Carolina, who voted 95–5 for Obama in a state that went 50–49 for that same candidate. GG find that there was a significant difference between high‐income African Americans, who voted 86–14 for Obama, and low‐income African Americans, who voted 97–3 for Obama. However, further poststratification based on sex reveals that this 11‐point gap in vote choice between rich and poor African American in North Carolina is primarily driven by men. The wealthiest African American women in the state are estimated to have gone 90% for Obama, whereas low‐income African American women went 98% for Obama—an 8‐point difference. Meanwhile, 84% of high‐income African American men were estimated to vote for Obama, whereas 97% of low‐income African American men did the same—a 13‐point difference. Similarly, the gap between high‐income and low‐income African Americans in terms of turnout was estimated at 15% for women but 21% for men.            "
"68","Disaggregating further by education level also reveals interesting conditional relations between demographic characteristics, turnout, and vote choice. Figure 5 shows turnout and vote choice estimates for subgroups defined by state, age, and income, as well as ethnicity and sex. The estimates are shaded to represent different education levels, with darker shades representing more educated subgroups (and bubble size indicating subgroup size). The association between turnout, McCain vote, and education level is strikingly clear. In general, more highly educated people tend to turn out more often. They also tend to support Obama more, although this tendency is strongest among women. This interaction itself (viz., the clustering of more educated groups in the upper‐left portion of the plots for women) is strongest among Latinos and weakest among whites. Thus, using a ensemble of trees has enabled us to estimate attitudes and preferences of even smaller subgroups at very little additional computational costs.            "
"69","Poststratified BART Estimates of 2008 Turnout and Vote for McCain"
"70","Note: Size represents population size, and shade represents education level (darker shades indicate more education).                        "
"71","In this article, we presented tree‐based methods as a promising approach for modeling large data sets in political science. We argued that they are particularly valuable in settings where one wishes to make accurate predictions in the context of a generally unknown DGP with potential nonlinearities, interactions, and many (potentially irrelevant) covariates. In the spirit of other nonparametric strategies used in the discipline, these techniques make few assumptions about DGPs or functional forms relating outcomes to predictors, and the distributional assumptions they do make are often embedded in the chosen loss function. Since researchers are increasingly confronted with larger data sets containing many observations, many possible predictors, or both, we believe that regression and classification tree models are worth considering as a more standard tool in prediction tasks."
"72","To that end, in this article, we have presented a necessarily brief tour of some of the most common tree‐based methods, complemented by three illustrations and a supplementary information appendix aimed at providing applied analysts with both insight as to the strengths and weaknesses of the various models and guidance as to how these methods can be used in practice. It is, in that sense, an invitation to adopt these methods as part of the standard repertoire of statistical tools in the discipline."
"73","Despite their advantages, it is worth emphasizing the limitations of tree‐based models that we noted in our introduction. To begin with, we reiterate that for some tasks, tree‐based models are overly complex and unnecessary. Indeed, tree models are inappropriate in the context of a well‐understood DGP when our aim is to test for relationships with clearly hypothesized functional forms. If the theory can reasonably be represented and tested by a parametric model, tree models are not the right tools for the job."
"74","Likewise, tree‐based methods are no replacement for good research design and rigorous theory building. While the models we have discussed allow researchers to more easily model complexities in large data sets, they do not by themselves overcome common issues of endogeneity, posttreatment bias, and the like. Even a model with high levels of out‐of‐sample accuracy is of limited scientific value when the modeling strategy is poorly thought out. That is, tree models are no exception to the adage, “garbage in, garbage out.” Even more, empirical regularities “discovered” by this nonparametric approach are not necessarily meaningful in a theoretical sense. That some set of variables is predictive of an outcome does not by itself indicate that they are causal or even theoretically of interest.         "
"75","Despite these caveats, we feel that there are many potential uses for tree‐based models in political science. In our illustrations above, we demonstrated how tree models can be incorporated into standard social science tasks such as accurate measurement and causal inference. Other applications include, for instance, imputing missing data (Stekhoven and Bühlmann 2012), identifying fraudulent vote returns (Montgomery et al. 2015), and using covariates to make individual‐level predictions for effectiveness of interventions (Samii, Paler, and Daly 2016). More directly, tree models may prove to be particularly valuable in the context of improving prediction—an increasingly common task in political science research. Our hope is that our discussion and illustrations will entice quantitative students of politics facing increasing demands to make sense of large amounts of social data to explore the rich possibilities offered by tree‐based methods.         "
