"","x"
"1","Political scientists have increasingly turned to field experiments to isolate the impact of various activities on voter turnout (Gerber and Green 2000; Green and Gerber 2004) and voter preferences (Gerber 2004). Experimentation is a research method in which units of observation are assigned randomly to treatment and control groups. Field experiments, as distinct from laboratory experiments, study the effects of an intervention within a naturalistic setting. In this case, the units of observation are cities, the intervention is a radio campaign, and the dependent variable is the closeness of the election as determined by the incumbent's share of the vote. This section describes two experiments. The first occurred in 2005 and generated results on which the initial version of this report was based. On the suggestion of reviewers, we conducted a replication study in 2006 using the same research design.         "
"2","Of the nation's 1,183 cities and towns with populations of over 30,000, 281 municipalities held mayoral elections in November 2005. The cost of broadcast radio advertisements in the various localities ranged from $9 per point in Billings, Montana, to $922 per point in Palmdale and Hawthorne, California.1 The average cost per point in the population of election‐holding cities was $164 per point. Due to resource limitations, we excluded cities and towns where cost for radio advertisements exceeded $111 per point, reducing the population to 151 localities. The average cost per point in the subpopulation of cities was $63.            "
"3","In order to increase the statistical power of our experiment, we sought to create a sample of observations that, within experimental strata, were as homogeneous as possible. We gathered detailed information about the institutional and political characteristics of mayoral elections in each of the 151 cities and matched pairs of municipalities based on criteria thought to affect competitiveness. These matching criteria were voter turnout in the previous mayoral election, incumbent vote share in the previous mayoral election, whether mayoral elections are partisan or nonpartisan, and whether the 2005 mayoral election was contested. All of the cities and towns included in the final sample were municipalities in which the local executive is selected by popular vote (as opposed to appointment by the city or town council). Using the criteria described above, we identified 28 closely matched pairs of cities in an effort to make the treatment group as similar as possible in terms of observable characteristics. Once the matching exercise was completed, we randomly assigned one city in each pair to the treatment group and the other to the control group. The full 28‐pair design is the basis of another report by the authors, which examines the effects of our radio campaign on voter turnout (Panagopoulos and Green 2006). For the purposes of this article, which focuses on electoral competitiveness, we restrict our attention to 33 cities—16 in the treatment group and 17 in the control group—in which an incumbent mayor ran opposed. As we demonstrate below, within the set of 33 observations, random assignment generated experimental groups that have closely balanced observable characteristics.2"
"4","In November 2006, 105 municipalities held mayoral elections. Using the same four matching criteria as in 2005, we repeated the matching exercise to create 11 pairs, half of which were randomly assigned to the treatment group. Of these, 16 cities—seven in the treatment group and nine in the control group—featured elections in which incumbent mayors ran opposed in 2006. The average cost per point for cities in the 2006 sample was $100, raising the average cost per point in the combined sample of 49 observations to $75."
"5","The analyses that follow present details about the experimental results separately for each of the two experiments. We also combine the two experiments to present overall results for the 49 elections."
"6","Localities in the treatment group were exposed to 60‐second radio advertisements that presented a nonpartisan get‐out‐the‐vote message to listeners.3 The size of the media buy was varied in each municipality so that cities or towns were exposed to 50, 70, or 90 gross ratings points (GRPs) of radio advertising. In order to conserve money, purchase of 70 or 90 GRPs was restricted to less expensive media markets. Cities randomly assigned to the treatment group whose cost‐per‐point was less than $30 were treated with 90 GRPs. Cities randomly assigned to the treatment group whose cost‐per‐point was greater than $30 but less than $40 were treated with 70 GRPs. All other treatment cities received 50 GRPs. This design implies that our statistical analysis must control for the cost‐per‐point of radio ads because intercity variation in the volume of GRPs is random within, but not across, strata. (In effect, we will be analyzing three distinct randomized experiments, each occurring within populations with different advertising rates.) Total media expenditures to conduct the experiment in the 49 jurisdictions included in the analysis amounted to $77,166.            "
"7","Radio advertisements were broadcasted from November 1 through November 7 in 2005 and from October 31 to November 6 in 2006. Details about the size of the radio media buy in each municipality included in the treatment group are presented in Table 1. Advertisements were professionally recorded and produced by a partnering political consulting and media firm. A media consulting firm selected the radio stations within each market, favoring stations that reached a broad audience. The media schedule was designed to reach a demographically diverse but receptive audience. Ads were broadcasted during music and news/talk program formats across markets. Springfield, Massachusetts, is a typical example. A total of 70 gross ratings points were purchased to reach voters in Springfield. Ads were broadcasted to capitalize on peak audience times during the work week, early morning traffic (6–10 AM) and afternoon rush hour (3–7 PM) as well as throughout the day (10 AM–3 PM). Additional ads were aired during the weekend. A total of 41 GRPs were aired on WMAS FM (94.7), a popular music station. Twenty‐nine GRPs were aired on WHYN AM (560), a news and talk radio station.4"
"8","Voters in each locality were urged to vote on Election Day, and the ads included the names, incumbency status, and party affiliations (where applicable) of the main candidates in each race. It should be stressed that the intervention was strictly nonpartisan in nature. We were especially sensitive to any elements that could be construed as negative commentary about incumbents.5 The radio scripts were designed to pique voters' interest in the contest and provide the names of the candidates, but scripts make no evaluative remarks. For example, the following sample script was used for Syracuse, New York:            "
"9","                              "
"10","Many people don't realize how important local government is. But think about it. Your local government is in charge of things that affect your life every day: police protection, transportation, garbage collection, tax assessment. From fire departments to libraries to safe drinking water—it's all part of local government."
"11","                              "
"12","Here's where you come in: Voting. If you're a registered voter in SYRACUSE, you have an opportunity to shape the direction of your city by electing the mayor and other local officials. On Tuesday, November 8th, residents of SYRACUSE will vote to decide whether to RE‐elect Democratic MAYOR MATTHEW DRISCOLL or to support his opponent Republican JOANNIE MAHONEY."
"13","                              "
"14","Take part in shaping your city's future. Be sure to vote on November 8th."
"15","                              "
"16","Paid for by the Institution for Social and Policy Studies, a nonpartisan organization that encourages citizens to take an active role in their communities."
"17","Our hypothesis is that this nonpartisan communication, which places all candidates on an equal footing, boosts challengers' electoral performance by mitigating advantages in resources and name recognition that incumbents typically enjoy."
"18","Random assignment ensures that, in advance of the experimental intervention, the treatment and control groups have the same expected levels of electoral competitiveness. One by‐product of random assignment is that the background attributes of the observations in the experimental groups should be similarly distributed. This expectation is easily confirmed using regression. The dependent variable is the assigned level of GRPs, as described in Table 1, and the independent variables are the assignment strata and the four background covariates used to form the sample (past incumbent vote share, past turnout, partisan balloting, and statewide elections). This regression permits an F‐test of the significance of these four covariates, which, as expected, is insignificant: F(4,41) = 0.95, p = .44. Expanding the randomization check to include the number of years the incumbent served in office and the number of candidates running the previous election leaves the result unchanged (F(6,39) = 1.15, p = .35). Having confirmed that random assignment produced balanced treatment and control groups, we now estimate the effects of the experimental ad campaign on competitiveness.         "
"19","The dependent variable in our analysis is the difference between the vote percentage won by the incumbent in 2005 or 2006 and his or her vote percentage in the previous election. This dependent variable has the advantages of simplicity and efficiency: conceptually, we want to know whether the ads cause the incumbents' electoral performance to improve or deteriorate; statistically, examining change rather than levels greatly reduces the amount of noise in the outcome variable. As we point out in the appendix, other constructions of the dependent variable, such as the vote margin separating the incumbent from the closest challenger, produce substantively similar conclusions."
"20","In order to estimate the effects of the radio buys (as measured in GRPs), linear regression was applied to two nested models. The first includes three regressors: radio GRPs and two strata dummies that account for the fact that random assignment was conducted within price strata.             "
"21","The second specification includes as covariates past turnout, partisan balloting, and statewide elections (past incumbent vote share is already part of the model).             "
"22","The results of the two regressions are shown in Table 2, which presents results for the 2005 experiment, the 2006 replication, and both studies analyzed jointly.6 The estimates associated with equation (1) are reported in the columns with the heading “Strata Only.” In both years, the estimated effect of the radio ads is negative, which is consistent with the underlying hypothesis that these radio ads improve the electoral fortunes of challengers. Although the magnitude of the point estimate is larger in 2005 than 2006, possibly reflecting the fact the greater volume of political communications during an even‐numbered year, the difference between the coefficients is small in relationship to their standard errors, which makes pooling across years appropriate. The pooled regression implies that each one‐point GRP purchase lowers the incumbent's vote share by .078 percentage‐points (SE = .059). This estimate implies that in cities where 50 GRPs were purchased, the incumbent's vote margin (relative to the previous election) declined by 3.9 percentage‐points; 70 GRPs lowered the incumbent's performance by 5.5 percentage‐points; and 90 GRPS lowered the outcome by 7.0 percentage‐points. These estimates far outstrip the apparent turnout effects of the radio ads, which appear to be less than 3 percentage‐points per 100 GRPs.7 It appears that the vote choice effect we observe is primarily driven by preference change rather than by mobilization.         "
"23","In an effort to dampen some of the variability associated with these elections, the results presented under the heading “Strata and Covariates” control for the background covariates listed in equation (2). The results are essentially unchanged in terms of the magnitude and statistical precision of the estimated treatment effect (−.088, SE = .062). Unfortunately, these control variables do not improve the precision with which the treatment effect is estimated, as the RMSE increases slightly when these additional degrees of freedom are consumed. Ordinarily, one might not report the results for this regression model, but we do so in order to replicate exactly the analyses that we earlier reported after the 2005 experiment.8 The results suggest both the stability of the estimates over time and the fact that controlling for background characteristics seems to lead to estimates that, if anything, are larger in magnitude than those based on equation (1).         "
"24","Taken together, the OLS point estimates suggest that the treatment had a strong negative effect on incumbent vote share. However, the coefficient of −.078 with a standard error of .059 implies a one‐tailed p‐value of .098. Bootstrapping the regression confirms that 91.6% of the 100,000 replications generate negative estimated treatment effects. Evidently, the statistical precision of the treatment effect falls just short of conventional p < .05 levels. As Gill and Walker (2005) point out, the classical approach to hypothesis testing is equivalent to a Bayesian framework for the special case in which the analyst has noninformative priors (i.e., priors with infinite variance). That special case arguably does not apply here, as this experiment was inspired by widely held prior beliefs about the relative effects of campaign spending by incumbents and challengers. The task for the next section is to specify the priors implied by the extant literature and show how one might update them using the experimental results reported here.         "
"25"," Gill (2002) and Gill and Walker (2005) argue forcefully for the incorporation of priors into assessments of causal effects. The central Bayesian argument that runs through their work is that posterior assessments of causal effects are a blend of prior beliefs and new information. So long as one is able to characterize one's priors in terms of a probability distribution, it is relatively easy to generate a posterior distribution that is a function of both the priors and the experimental results. As Gill and Walker (2005) point out, the practical challenge is characterizing priors with sufficient specificity to support this calculation. In this section, we characterize the prior distribution in general terms by examining the spending effects implied by reported research results, drawing on works with very different modeling assumptions and research designs. We then examine what kinds of posterior distributions would emerge from a range of different assumptions about the location and dispersion of the prior distribution.         "
"26","Extracting priors from the campaign spending literature is complicated by the fact that a great deal of uncertainty surrounds the proper way to estimate the effects of incumbent and challenger spending. As Gerber (2004) points out in his path‐breaking work connecting the observational literature on campaign spending to the experimental evaluation of how dollars translate into votes, the methodological deadlock that has beset the observational literature is precisely the reason for the recent turn to field experimentation.         "
"27","That said, a closer look at the implications of research findings derived from very different estimation approaches show them to be surprisingly similar with respect to the core hypothesis of this article. Table 3 reports the estimates and implications from three well‐known studies of campaign spending in U.S. House elections, all of which regress vote outcomes on the log of challenger spending and the log of incumbent spending.9 Using instrumental variables regression, Jacobson (1990, 340; column 5) obtains a coefficient for challenger spending of 2.877 and for incumbent spending of 1.523. Erikson and Palfrey (2000, 604; column 1), applying OLS to the most closely contested races so as to minimize the endogeneity problem, obtain estimates of 4.11 and 4.04 for challenger and incumbent spending, respectively. Analyzing a sample of repeat challenger‐incumbent contests, Levitt (1994, 788; column 3) obtains 1.04 and 0.61. Although the coefficients differ, they have similar implications when it comes to predicting the effects of a grant of free air time to both candidates.         "
"28","Consider the effects of a grant of $7,500 (the average cost of 100 GRPs, in 2005 dollars) to a challenger spending $10,000 and an incumbent spending $100,000. Table 3 calculates the net vote gain according to each of the three sets of research findings and shows that challengers gain votes at a rate of $1.61 per vote (Erikson and Palfrey), $2.17 per vote (Jacobson), or $6.73 per vote (Levitt).10 The cost per vote for the challenger rises when we next consider a scenario in which the challenger spends $25,000 against an incumbent who spends $100,000. Now the cost‐per‐vote estimates are $4.50, $5.56, and $16.48. When a challenger is overmatched in terms of spending, all of these models imply that an exogenous grant to both candidates greatly benefits the challenger.11"
"29","How do these cost‐per‐vote figures compare with comparable figures from our experiment? The average city had approximately 50,000 registered voters, of whom approximately 20,300 voted.12 The most precisely estimated effect of radio from Table 2 is .078 per GRP, which implies that 100 GRPs produces a gain of 1,583 votes for the challenger. The average cost of one GRP was approximately $75. Thus, the cost per challenger vote is $7,500 ÷ 1583 =$4.74 in 2005 dollars. Given that the typical mayoral election features a grossly overmatched challenger, this figure is quite consistent with the extrapolations derived from the campaign spending literature.         "
"30","Let us now calculate what the cost‐per‐vote estimates in Table 3 imply for the estimated treatment effects reported in Table 2. Radio ads are assumed to be tantamount to a name‐recognition enhancing expenditure of $7,500 on behalf of both the challenger and the incumbent, as both names are mentioned. For the scenario in which the challenger spends $25,000 against an incumbent spending $100,000, the Erikson and Palfrey estimates imply a radio treatment effect of .082 per GRP. Jacobson's estimate implies a radio treatment effect of .066, and Levitt's estimates imply .022.         "
"31","Since the three regressions are based on some of the same House elections data, the estimates are not independent and cannot be aggregated in any straightforward way. However, we can simulate the effects of stipulating one prior or another on the posterior distribution that emerges from the radio experiment results. Table 4 shows how the posterior estimates and their standard errors (Gill 2002, 138) vary across simulated priors, each patterned after the three campaign spending essays. The rows of the table reflect different assumptions about the mean of the prior distribution over possible radio treatment effects. In this table, higher means imply stronger net effects for challengers. The columns of the table reflect different assumptions about the standard deviation of the prior distribution. Higher standard deviations imply greater initial         "
"32","uncertainty about either the credibility of the observational point estimates or their relevance for our application. With very high standard deviations (column 1), the posterior distributions are very similar to the estimates reported in Table 2. As the standard deviation decreases, the posterior results are more strongly influenced by the prior mean. As the lower right‐hand corner of Table 4 indicates, the posterior distribution has a high mean and small variance when either Jacobson‐type or Erickson/Palfrey‐type priors are assumed. A prior of .075 with a standard deviation of .05, for example, implies a posterior distribution with a mean of .076 and standard deviation of .038. With weaker Levitt‐type priors of .025, the posterior mean remains substantively large (ranging from .047 to .077), but the t‐ratio hovers around 1.25. Thus, the empirical results presented here range from convincing to suggestive, depending on which priors one forms based on the campaign spending literature.         "
"33","It should be stressed that even if one's subjective priors were ex ante exactly in line with the eventual results of the 2005 and 2006 experiments, scientific progress is gauged by the degree to which the posterior mean and variance differ from the prior mean and variance. Thus, the case where Jacobson‐type priors of .075 with a standard deviation of .05 meld with new data showing a point estimate of .078 with a standard error of .059 produces an advance even though the posterior mean is .076. Although at first glance it appears that the experiment has simply confirmed what one already suspected based on the literature, there is a profound difference between a posterior distribution of .075 with a standard deviation of .05 (the state of knowledge before the new data) and a posterior distribution of .076 with a standard deviation of .038 (the state of knowledge after seeing the new data). In the former case, the betting odds that this intervention has a positive effect are 14 to 1; in the latter case, the odds are 43 to 1."
"34","As the first field experiment to examine the effects of political advertising on radio, this study offers a number of methodological and substantive insights. In terms of methodology, this experiment demonstrates the feasibility of studying radio's effects using random assignment in real‐world settings. The research paradigm used here is a systematic and reproducible method that can be applied to further research on radio and other forms of mass communication."
"35","To date, field experiments on the effects of the mass media are rare, as most researchers rely on survey research and laboratory experiments. This lopsided balance in favor of survey and laboratory approaches does not necessarily reflect the superiority of these methods. Laboratory experiments leave open the questions of whether listeners in a simulated environment absorb radio messages in the same way that they would under ordinary conditions and whether one can measure outcomes in an unobtrusive and externally valid manner. Surveys are often more expensive than field experiments but not necessarily more reliable. Exposure to radio advertisements is potentially correlated with unobserved causes of voting, particularly if media campaigns are directed at certain segments of the electorate. Absent random assignment, a survey draws on strong substantive assumptions in order to generate causal inferences."
"36","Observational literatures, such as extant work on campaign finance, reach a point at which the remaining uncertainty is not sampling variability, but rather whether the modeling assumptions are correct. Even with a very large number of observations, such that the nominal standard errors have essentially been reduced to zero, there remains the open question of whether the underlying results are biased (Gerber, Green, and Kaplan 2004). To advance a literature that has reached this point, one must adduce experimental evidence (or perhaps evidence based on natural experiments or near‐random assignment). That is the spirit in which this article is written. The observational literature strongly implies but has by no means settled the hypothesis that an equal grant of resources to both challengers and incumbents will generate a net benefit to challengers. Our article does not settle the matter either, but it presents both novel evidence regarding this hypothesis and a fresh research paradigm for evaluating it.         "
"37","By showing that field experimentation is possible, this study opens up a new and potentially valuable methodological path. At the same time, this field experiment has several limitations, most notably problems of statistical power. Because this is the first study to evaluate the impact of radio advertisements on electoral behavior, its statistical power was difficult to calculate ex ante. Now that the research community has a sense of what to expect from a study of this kind, we and other scholars can design follow‐up studies that, in conjunction with ours, will have smaller standard errors. One of the great advantages of randomized experimentation is the potential for accumulating experimental evidence, thereby converging on an underlying parameter with ever‐greater precision. The Bayesian perspective taken in this article breaks away from the classical framework in which effects are declared significant or nonsignificant and instead provides a framework within which causal conclusions can be continuously updated."
"38","This updating process includes the exploration of possible interactions between advertising and electoral context. Additional research must investigate whether the results change when the messages are partisan, when advertising is directed toward other types of elective offices, and when the challengers have varying levels of prior name recognition. This more nuanced line of experiments will illuminate the mechanisms for the posited advertising effect and the scope conditions within which the effect is likely to obtain."
"39","Another limitation of the current study is that it fails to exploit the full power of radio as a medium. Budgetary constraints prevented us from broadcasting more than 90 gross ratings points in any given market. An expanded study would allow us to procure more comprehensive coverage in the treatment markets. The ease with which radio ads are produced also makes it possible to vary message content in future experiments. Voters in the current study, for example, were exposed exclusively to nonpartisan get‐out‐the‐vote messages. Still greater opportunities exist to harness the demographic targeting potential of radio in subsequent experiments to study effects on select audiences using, for example, Spanish‐language stations."
"40","Despite these limitations and the need for additional research, our findings have important substantive implications. For more than a quarter century, political scientists have argued that differential name recognition is an important source of incumbency advantages. A corollary argument is that challengers have more to gain from campaign spending than their better‐known incumbent adversaries. As Gary Jacobson puts it, “[b]ecause voters are demonstrably reluctant to vote for candidates they know nothing about, challengers have a great deal to gain by making themselves better (and, of course, more favorably) known to the electorate. Their level of campaign activity … thus has a strong influence on how well they do at the polls” (1990, 335). If name recognition is indeed the active ingredient that causes challengers to reap disproportionate gains from campaign spending, an exogenous intervention that publicizes the candidates' names in low‐salience elections should, on average, benefit challengers. Our experiment provides important new support for this core hypothesis."
"41","This is by no means the only type of experiment that one could perform in order to test the name recognition hypothesis. Gerber's (2004) study of campaign mail's effect on vote choice suggests an experimental paradigm whereby one could test the differential effects of two alternative messages, one that focuses solely on the incumbent's drawbacks without mentioning the challenger and another that does both. The name‐recognition hypothesis suggests that an obscure challenger should make especially large gains in the latter condition, as a result of increased name recognition. The name‐recognition hypothesis could be tested using an array of standard campaign tactics, ranging from robotic phone calls to voter guides.         "
"42","From the standpoint of public policy, our findings bolster the longstanding argument that even‐handed campaign finance laws can enhance electoral competitiveness. As Primo, Milyo, and Groseclose (2006) point out, this hypothesis has received surprisingly little attention from observational researchers, despite the adoption of public financing laws in seven states. Their analysis of gubernatorial competitiveness between 1978 and 2004 provides some limited support for the idea that public funding enhances competitiveness, but the small number of observations and high level of visibility of gubernatorial candidates make this an imperfect test. It may be years before newly enacted public funding laws generate statistically reliable changes in the electoral competitiveness of legislative elections.13 In the meantime, students of electoral politics may use experiments to speak to this central and enduring policy question.         "
"43","By promoting awareness of upcoming elections and providing minimal information about the candidates, subsidies to both candidates—such as nonpartisan radio ads—appear to reduce the advantages of incumbency. To date, this implication has been at the forefront of the campaign finance literature but never tested directly. The present study contributes the first direct test and confirmation of this claim."
"44","                "
