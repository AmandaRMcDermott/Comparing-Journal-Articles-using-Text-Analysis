"","x"
"1","Our work takes as its substantive foundation the pioneering work of David Mayhew. In his Divided We Govern (1991), Mayhew tackles the difficult issues of measurement and selection in his analysis of lawmaking and assessment of the role of Congress and the president in the policymaking process. His analysis, which focuses directly on lawmaking rather than on indirect measures such as roll‐call votes, provides important information and ideas about measuring the legislative accomplishment of Congress.4 Mayhew increases our understanding of: what type of data is important for studying lawmaking; what defines “important,”“notable,” or “significant” legislation; and the importance of testing theory and hypotheses against actual policy outputs. Of these three contributions, the second is the most opaque.         "
"2","Although existing lists of legislation purport to identify legislation that is “landmark,”“significant,”“innovative,” or “consequential,” what is meant by “ important” legislation is inevitably, if not hopelessly, imprecise. Any characteristics that one could plausibly identify as defining “significant” legislation are themselves plagued by imprecision. For example, Mayhew defines important legislation as that which is “both innovative and consequential—or if viewed from the time of passage, thought likely to be consequential” (1991, 37). What does he mean by “consequential” and “innovative”? Should we measure policy innovation by the percentage of the U.S. Code that is changed by a statute or by how far a policy moves the status quo? Does “consequential” refer to the extent to which a policy changes existing laws, the number of people affected by the legislation, or a measure of the extent of that impact on the affected people? Even if a precise definition were possible, operationalizing the definition appears impossibly complex. For example, although the Civil Rights Act of 1964 and the Voting Rights Act of 1965 are unquestionably two of the most consequential civil rights policies ever enacted in the United States, how are we to assess the consequence and innovation of symbolic legislation such as the act that established Martin Luther King Day as a national holiday or the 1989 Flag Protection Act outlawing flag burning?5"
"3"," Mayhew (1991, 4) utilizes both contemporaneous and retrospective evaluations of the policymaking process—essentially elite evaluations—to assess which legislative enactments meet this standard and qualify as “important.”6 The resulting list has strong validity and can be rationalized ex post, but there is no necessary relationship between the posited criteria of innovation and consequence and whether a statute is sufficiently noteworthy to appear in a review of the legislative session by major newspapers or a policy history. Although innovative and consequential legislation is likely to be mentioned (and therefore captured by the measure), Mayhew admits that coverage of an enactment may also be affected by other characteristics, such as how controversial it is. Certainly legislation that fundamentally changes the nature of government would be controversial, but controversy may also stem from the political environment rather than the enactment itself. It is not implausible that identical legislation might result in substantially different levels of controversy depending on the political environment. Legislation perceived as controversial during an era of political acrimony might pass with bipartisan support at a time of relative calm. Consequently, Mayhew's operationalization of importance using notable legislation effectively identifies three types of legislation: legislation controversial enough to warrant coverage; legislation with a great enough impact to warrant coverage; and legislation innovative enough to warrant coverage.            "
"4","Attempts to enumerate the precise conditions under which a statute may be considered significant lead quickly to a long list of conditions that prove difficult, if not impossible, to operationalize. Even if it were possible to specify precisely what constitutes an “important” statute, the usefulness of such an exercise is doubtful given the likely impossibility of making a determination based on such standards. The difficulty, if not futility, of such an exercise leads us to define significant legislation explicitly in terms of that which is notable. Our working definition of significant legislation is a statute or constitutional amendment that has been identified as noteworthy by a reputable chronicler‐rater of the congressional session.7 This definition is identical to that put forth by Mayhew in his Divided We Govern. Although our measure is more accurately described as a way to identify notable legislation, we follow the usage of others, like Mayhew, and refer to “notable” legislation as “significant” legislation. We acknowledge the slippage that results from this terminology, but it is unclear to us that a superior alternative exists.            "
"5","Following Mayhew (1991), we characterize raters according to whether their assessments are primarily contemporaneous or retrospective. Contemporaneous raters assess legislation at or near the time of enactment. Retrospective raters rely on hindsight to determine the noteworthiness of legislation in the context of both prior and subsequent events.8"
"6","Mayhew's Sweep 1 draws on contemporaneous sources in constructing a list of important enactments and represents the first rater we use. Another contemporaneous source comes from Baumgartner and Jones's Policy Agendas Project (2002, 2004), which collects information on every public statute enacted since 1948. Baumgartner and Jones's list of important enactments is based on the number of column lines devoted to each enactment in the Congressional Quarterly Almanac.            "
"7","Additional sources of contemporaneous assessments are provided by the coverage of the New York Times and the Washington Post. These measures were initially collected and summarized by Mayhew to form his Sweep 1 assessment; subsequently they were independently collected and refined by Cameron (2000) and Howell and his colleagues (2000). The latter combine information collected from these two newspapers with story coverage in CQ and Mayhew's series to construct a four‐category ordinal measure of significance for the period 1948 to 1993. We use an indicator of whether the legislation passes the lowest threshold for nontrivial legislation (“A” through “C” in the coding of Howell et al. 2000).9"
"8","We also use assessments made in the legislative wrap‐ups of the American Political Science Review (APSR) and Political Science Quarterly (PSQ). Each journal summarized the year's proceedings in Congress for the years 1889 to 1925 (PSQ) and 1919 to 1948 (APSR).10 We also use Peterson's (2001) attempts to replicate Mayhew's coding technique for 1881 to 1945 using contemporaneous sources that vary from Congress to Congress.            "
"9","In each case, we recorded and content‐coded all mentions of public enactments and policy changes. If the title of the statute was not present in the text, we searched through the index of the History of Bills and Resolutions in the Congressional Record as well as the index of the Public Statutes at Large to derive a dichotomous measure of whether the statute was mentioned.11"
"10","A second type of rating data we use is retrospective evaluations. Mayhew's Sweep 2 for the 1948 to 1994 period and Peterson's (2001) replication of Mayhew's Sweep 2 for the 1881 to 1947 period are two sources of retrospective ratings. In addition to the retrospective ratings of Mayhew and Peterson, which aggregate the determinations of several different policy histories, we also rely on several general political history and policymaking series. We use 11 period‐specific volumes of the New American Nation series—a “comprehensive, cooperative history of the area now embraced in the United States, from the days of discovery to the present” (Matusow 1984, ix) and the American Presidency Series (see appendix).12 In the American Presidency Series, “each book treats the then‐current problems facing the United States and its people and how the president and his associates felt about, thought about, and worked to cope with these problems. In short, the authors in this series strive to recount and evaluate the record of each administration and to identify its distinctiveness and relationships to the past, its own time, and the future” (Greene 2000, ix). A complete listing of the individual books of these series is listed in the appendix.            "
"11","A fifth source of retrospective ratings is Chamberlain'sThe President, Congress, and Legislation (1946) which contains a detailed history of U.S. policymaking across 10 distinct spheres. A sixth source of retrospective ratings is Reynolds's (1995)“mini‐research report” which culled the Enduring Vision textbook for mentions of important legislation between 1877 and 1948 to test for the effect of divided government on policymaking before World War II. A seventh source is Sloan'sAmerican Landmark Legislation (1984) which compiles a selective list of laws based on: the “important national significance they had at the time Congress passed them” and their lasting effect on “one dimension or another of American life.” Yet another retrospective rater is Light'sGovernment's Greatest Achievements: From Civil Rights to Homeland Defense (2002). A ninth set of retrospective raters are several of the public affairs history books identified in Mayhew'sAmerica's Congress (2000) which we treat as separate raters. Two final retrospective raters come from the work of the Congressional Research Service. Dell and Stathis (1982) andandaa chronicle congressional effort from 1789 (1st Congress) to 1980 (96th Congress) and Stathis's recent solo work, Landmark Legislation 1774–2002 (2003), expands, extends, but does not strictly restate the assessments of Dell and Stathis (1982). Table 1 summarizes the raters we use, including the number of statutes covered and the number of statutes mentioned. Statutes passed during the time period but not mentioned by a rater are counted as being unmentioned.            "
"12","Given the inability to identify precisely how the legislation mentioned by raters corresponds to some acceptable definition of policy significance, we believe the task of constructing the “best” measure is impossible. Consider the task of resolving the differences between the lists compiled by Mayhew (1991) and Stathis (2003) for statutes passed in 1981. Mayhew identifies just two important statutes: the Economic Recovery Tax Act (PL 97‐34) and the Omnibus Budget Reconciliation Act (PL 97‐35). Stathis mentions these and adds the Veterans' Health Care, Training, and Small Business Loan Act (PL 97‐72), Restrictions on Military Assistance and Sales to El Salvador (PL 97‐113), Fiscal 1982 Department of Defense Appropriations (PL 97‐114), and the Social Security Act Amendments (PL 97‐123). Are we to conclude that two significant statutes were enacted in 1981, or six? Or some intermediate number? The justification for choosing any of these numbers is unclear. Are the Social Security Act Amendments important for having restored the minimum benefit eliminated by the Omnibus Budget Reconciliation Act and enabling the Old‐Age and Survivors Insurance fund to borrow from the Hospital Insurance and Disability Insurance trust funds? Is it important or unimportant that the Veterans' Health Care, Training, and Small Business Loan Act extended GI Bill eligibility for Vietnam veterans by two years? It is difficult to resolve such differences because the basis for these distinctions is unclear.            "
"13","A benefit of our statistical method is that since a principled adjudication between competing significance lists is difficult, we can remain agnostic and let the data determine the appropriate resolution. Relationships between raters determine the relative contribution of each rater to the composite significance estimate. Since we use raters who explicitly or implicitly identify significant legislation, the resulting list is likely to consist of “high‐stakes” legislation on “important,”“innovative,” or “consequential” policy. Despite this ambiguity, for purposes of exposition we refer to our estimates as measuring “significance.”13"
"14","The number of available raters and the differences evident in their ratings raise three additional questions that are largely avoided in the literature on measuring legislative significance. How should we interpret rater disagreement? How should such heterogeneity affect a measure of significance? And how can we compare the assessments of raters of different time periods?"
"15","There are three ways in which we can interpret rater heterogeneity. First, raters may differ because they use different criteria. For example, it may be that the American Presidency Series focuses on legislation related to presidential programs and the New American Nation series focuses on statutes that are retrospectively notable and “stand the test of time.” If this is the case, then a composite measure is problematic—the aggregate measure reflecting disparate concerns is less meaningful than the individual ratings. We consciously select raters to minimize this possibility: the raters we use explicitly seek to identify significant legislation or to identify the major legislative events of the time period. Furthermore, our statistical model can test whether rater assessments are based on different underlying dimensions.            "
"16","Second, raters may employ the same criteria, but different thresholds for designating statutes significant. For example, the American Political Science Review may be more likely to identify a statute as constituting an important policy change in its annual wrap‐up than a rater such as Sloan, who surveys the entire time period before making such an identification. In other words, two raters may agree as to the dimension of interest but differ on the threshold that defines significance. Contemporaneous assessments are most vulnerable to this possibility, since publishing annual reviews may result in inflated assessments during periods of relative inactivity.14 Finally, raters may make mistakes in their assessments. The process of culling through and assessing legislation is exhausting and time‐consuming. Raters may miss legislation that would have qualified as noteworthy according to their own standards.            "
"17","The literature takes two approaches in accounting for rater disagreement. First, some argue that one list is preferable to another (see, for example, Howell et al. 2000; Kelly 1993; Mayhew 1993). Although such comparisons raise important points, it is difficult to assess them objectively and conclusively in light of the difficulties already noted of determining the relationship between any measure and a statute's “true” significance. A second way in which competing lists are employed is to ignore the measurement debates and instead determine whether the results of interest depend on the list of significant legislation. In other words, researchers replicate their analyses using different measures (for example, Coleman 1999; Krehbiel 1998). Although pervasive, this approach fails to account for rater heterogeneity and examines only whether coefficients of interest (for example) depend on the measure used.            "
"18","Accounting for rater heterogeneity and unanimity is important because such an accounting conveys information about both the magnitude and certainty of our assessment of legislative significance. It makes little sense to treat the twelve statutes that receive unanimous mention by active raters equivalently to the 2,164 statutes mentioned by a single rater between 1877 and 1994. Rater agreement may indicate increased significance or increased certainty about the probability that the legislation is significant relative to the significance of a bill that experiences rater disagreement."
"19","Two additional concerns plague existing lists. First, the classification of landmark legislation is extremely coarse. It is hard to believe that the Voting Rights Act of 1982 and the Voting Rights Act of 1965 are equally significant. However, that is the conclusion suggested by the dichotomous ratings of Stathis (2003). Second, existing measures fail to quantify the precision of the measures. Rater disagreement suggests that our assessments of legislative significance are uncertain. Although we may be quite confident of the importance of the Civil Rights Act of 1964, which is mentioned by each of the 12 raters covering the period, we may be less certain of the significance of a statute mentioned by only two of the 12 raters. It is implausible that we are equally certain of the significance of the Civil Rights Act of 1964 and PL‐379, which passed the same year and established water resource research centers at land‐grant colleges and state universities.15"
"20","A final difficulty results from over‐time comparisons. Since not every rater evaluates every statute, it is difficult to know how to compare ratings from different eras. For example, Peterson (2001) attempts to extend Mayhew's (1991) Sweep 1 and Sweep 2 ratings to an earlier era. However, because Peterson and Mayhew use different sources and never rate a common set of statutes, it is impossible to determine whether they employ the same significance threshold and consequently how the two periods compare in terms of the number of significant enactments. It is also impossible to compare legislative productivity and test theories of lawmaking using legislative output both before and after World War II unless we restrict ourselves to one of the few lists that extend across time (for example, Stathis 2003).            "
"21","To account for the information contained in all of the various ratings and recover a more finely grained measure of legislative significance along with standard errors, we use an item‐response model. This provides a means of leveraging all available information, facilitating over‐time comparisons, and testing some underlying assumptions (for example, that all raters' assessments are determined by a common latent dimension). A statistical model also provides a means of integrating the rater data described in this section with statute characteristics potentially correlated with the statute's importance (for example, the amount of Congressional Record coverage, the number of substitute bills, the session in which it is passed, whether a conference committee was required, and whether the statute was an omnibus bill).            "
"22","The item‐response model was developed and is widely used in educational testing research. This is the statistical model we use to integrate the ratings discussed in the prior section. The model is commonly used in educational testing because it models how “items”—commonly questions on a test—discriminate between individuals on the basis of a latent trait such as ability, aptitude, or intelligence (see, for example, Baker's (1977) review, Patz and Junker's (1999) overview, or the textbook accounts provided by Hambleton, Swaminathan and Rogers (1991) and Johnson and Albert (1999). In other words, the item‐response model is a model of how observable responses reflect an underlying latent dimension. The model is specifically designed to address the complication that the parameters of interest are unobserved: the latent ability of the test takers, and the ability of the test questions to discriminate between test takers. Prior work in political science has recognized the similarities between students answering questions and legislators (or judges) casting votes in applying the models (e.g., Clinton, Jackman, and Rivers 2004; Jackman 2001; Martin and Quinn 2002). Poole and Rosenthal's (1997) seminal work on ideal point estimation uses a very similar model. In applying this model, we exploit a natural comparison between students being rated by examiners and statutes being assessed by congressional chroniclers.         "
"23","We assume that associated with all legislation is a true and unobservable value of legislative significance. For legislation t∈ 1 … T we denote the true latent significance as zt. We assume that raters i∈ 1 … N of legislative significance (for example, Mayhew's Sweep 1, Political Science Quarterly, New American Nation series) agree on what constitutes legislative significance and that zt entirely determines a statute's true significance relative to other legislation. If the true significance were observable and measurable, then all raters would agree on the relative legislative significance ranking even though they might employ different thresholds in determining the significance of a bill—no rater would think that statute i is more important than statute j if zj > zi. Although raters may differ in the methods they use to assess significance, they all fundamentally agree on the unobservable determinants of legislative significance.16 Each rater “votes” whether legislation t is significant (1) or insignificant (0) based on the latent trait zt. Recall that a “vote” in this context is a mention. Let Y be the T × N matrix of ratings, with element yti containing the dichotomous choice of rater n with respect to legislation t.17 For the period we examine (the 45th through 103rd Congresses), T = 37,766 and N = 20. Consistent with the observation that rater assessments may differ, we allow raters to imperfectly observe the true significance value z. Raters rely on the proximate measure x, where xti= zti+ɛti. In other words, for reasons such as the inherent difficulty of assessing legislative significance, differences in selection methodologies, and differences in effort level, the true significance of legislation is only imperfectly observed by raters. Although we assume that rater perceptions are unbiased (i.e., E[ɛ]= 0), we allow for the possibility that legislators differ in the precision of their perceptions—perhaps because of different degrees of ambiguity in raters' standards of determining significance. We denote the variance of ɛti for rater i by δi2.         "
"24","Denoting the distribution of ɛ by F(•), these assumptions imply that ɛti∼F(0, ɛti/δi). To model the significance of legislation in a statistical model we impose some structure on raters' decisions. Specifically, we assume that a rater's determination of whether a piece of legislation is significant depends only on whether the rater perceives the latent value of the legislation xti as exceeding the rater's threshold γi. Thus, yti= 1 if and only if xti > γi. In addition to allowing raters to differentially and imperfectly perceive the true significance of legislation, we also permit each rater to employ a different threshold when determining legislative significance.18"
"25","Given this rating rule, the probability of rater i mentioning statute t is the probability that the rater's observed trait for t exceeds her threshold. Given the assumption that ɛti∼ F(0, ɛti/δi), this implies that:            "
"26","Since not every rater evaluates every piece of legislation, we assume that the decision to not rate a piece of legislation is independent of both the significance of the legislation and rater qualities; a rater's failure to evaluate an enactment is uninformative about both the quality of the legislation and the rater. This assumption is unproblematic given that the missing data results from the fact that not all raters evaluate for the entire time period rather than a conscious choice of the raters. An important question concerns the extent to which ratings of early and recent statutes can be compared if the sources used to assess the statutes differs. The analogous problem in roll‐call analysis lies in comparing voting behavior across Congresses (e.g., DW‐NOMINATE) or chambers (e.g., Common Space scores; Poole 1988). The solution is to identify “bridging” observations that can be used to orient the two scores. Our bridging observations are the assessments of raters who overlap with nonoverlapping raters.19 For example, even though Mayhew (1991) and Peterson (2001) rely on different sources and rate different time periods, we use raters who overlap each such as Stathis (2003), Dell and Stathis (1982), and the American Presidency Series, to bridge their ratings. The intuition is that since Stathis and Mayhew rate legislation concurrently, we can relate their ratings to one another. We can similarly relate the ratings of Stathis and Peterson. Since the ratings of Mayhew and Peterson are each calibrated to Stathis's ratings, we can therefore relate the assessments of Mayhew and Peterson.         "
"27","Given this structure, the Bernoulli probability of yti is: Pr(yti= 1 | zt, βi,αi) = F(βi zt−αi)yti×[1 − F(βi zt−αi)](1‐yti). Assuming that the ratings are independent across raters conditional on the true latent quality of legislation zt and the rater parameters βi and αi implies that  . Further assuming that ratings are independent across legislation yields the likelihood            "
"28","Although the item‐response model represents a valuable way of incorporating information from several raters, it faces two limitations. First, there is additional nonrater information available which is plausibly correlated with the significance of statutes. Second, even employing 20 raters results in a relatively small percentage of enactments being rated (3,591 out of 37,766). Absent additional information we have no ability to distinguish between the significance of nonrated legislation."
"29","To address these concerns we use an integrated model that estimates a hierarchical prior for z. Instead of assuming that the prior distribution of legislation significance is identical and uninformative for all statutes (e.g., zt∼ N(0,1)), we assume that the prior distribution of z is N(μz, τ2), where the prior mean μz is a function of additional information. This provides a means of incorporating information plausibly correlated with legislative significance and determining how such characteristics relate to legislative significance. The importance of this is that it allows us to use the additional information as a means of “bridging” rated and unrated legislation. For example, if we believe that as the number of pages in the Congressional Record increases the more likely it is that the legislation is significant we can account for such possibilities. Let W denote the T × d matrix of covariates. If we assume an additive and linear relationship, than we assume that μz=Wκ+ς where κ is a d × 1 matrix of regression coefficients and ς is an iid error term. Note that this integrated model is almost identical to the exchangeable item‐response model discussed by Johnson and Albert (1999) with the important distinction that our model concerns the prior of z, not the item parameter priors.21"
"30","When we impose this linear regression structure and estimate an integrated model, three benefits arise. First, the estimator of z is able to “borrow strength” from the additional information contained in the covariate matrix W. Since legislation with identical characteristics is assumed to share the same prior mean (although the prior variance permits legislation with identical covariates to differ in significance), the integrated model can distinguish between identically rated legislation on the basis of their characteristics (assuming at least some characteristics covary with legislative significance). Second, the regression specification permits a way to leverage the relationship between the covariates and rated legislation to generate significance estimates for the unrated legislation. Since we observe the characteristics of all 37,766 statutes but only 3,591 statutes are mentioned by one of the 20 raters, the relationship between the covariates and the rated statutes essentially generates estimates for the unrated legislation. Third, if we are interested in the covariates of legislative significance, the integrated approach recovers estimates κ that account for the substantial uncertainty in estimates of z.            "
"31","To measure the amount of attention given to the legislation by Congress, we count the total number of pages—including debate and general bill activity (such as committee referral or discharge)—relating to the statute in the Congressional Record's History of Bills and Resolutions. Although imperfect, the page count measure is appealing because it attempts to assess the importance of legislative debate and rhetoric (Bessette 1994) and is available for the entire period.22 We also control for the number of conference committees required, the number of substitute bills associated with the public law, the session of Congress in which the legislation was introduced (Rudalevige 2002), and whether the bill was omnibus (Baumgartner and Jones 2004; Krutz 2001). The regression we estimate for μzi is given by:               "
"32","Since everything except for Y in equation 2 is unobserved, the scale and rotation of the parameter space are not identified (Rivers 2003). This means that z and −z yield equivalent values for the likelihood, as does z and A ×z where A is an arbitrary constant. Since we estimate the model using Bayesian methods and since we lack prior information about the discrimination and difficulty of the raters, we adopt uninformative priors for z, β, κ, τ, and α.23"
"33","We employ Bayesian methods because they provide a coherent means of integrating all available information while simultaneously propagating the error through the specification. The intuition underlying the method for the integrated method is as follows. First, generate significance scores for the 3,591 rated using some procedure (e.g., Poole's (2000) Optimal Classification). Second, regress the estimated significance scores on the covariates using equation 3. Third, use the recovered coefficient estimates and the covariate values for the unrated statutes to generate predicted values for the unrated legislation.24 Employing Bayesian methods provides a coherent and tractable means of simultaneously accomplishing these tasks while accounting for the error in each.25"
"34","Our method yields four sets of estimates: estimates about rater assessments; statute‐level estimates of significance; measures of legislative accomplishment resulting from the aggregation of the statute‐level estimates; and the regression coefficients of the relationship between legislative characteristics and statute significance. Although of less substantive interest than the statute‐level estimates and the resulting measures of legislative accomplishment, rater estimates can be used to assess several potential concerns with the statistical model."
"35","To examine whether raters' assessments can be interpreted as reflecting a common evaluative dimension we determine the ratings' dimensionality. For example, it could be that legislation mentioned in the American Presidency Series reflects both the legislation's importance and whether it was related to a president's legislative program. If so, legislation mentioned by this rater might include legislation that is insignificant but central to a president's program (unlikely but plausible), legislation that is significant but unrelated to a president's program, and legislation that is both. We investigate this possibility when we estimate a multidimensional measure of significance z and constrain the item parameters of the American Presidency Series and Mayhew's Sweep 1 and Sweep 2 to lie on different dimensions. Our findings suggest that a single dimension works well. Fitting a two‐dimensional model and estimating an additional 37,766 parameters (20 additional item parameters and 37,766 additional statute significance estimates) fails to noticeably improve the fit of the unidimensional model, which correctly predicts 98.6% of the mentions.            "
"36","Given the high naive classification rate and the very large standard errors for the two‐dimensional estimates, we also test whether there is sufficient evidence to conclude that two‐dimensional significance estimates do not lie on the 45‐degree line. Failure to reject the null hypothesis that the first‐ and second‐dimension estimates are equivalent suggests that there is only a single relevant dimension. The posterior indicates a nonzero difference in only 3% of the sample—a level below conventional significance levels.26"
"37","Having dismissed via empirical testing the possibility that the raters we use rely on different evaluative dimensions, we turn to the question of the consequences of different rater thresholds. We estimate two parameters for each rater: the extent to which each rater's determinations discriminate between legislation based on the latent significance z (βi= 1/σi) and the extent to which raters differ in their assessment of legislative significance holding constant the true value of legislative significance (αi=γi/σi). Table 2 denotes the estimated discrimination and difficulty parameters for each of the 20 raters used in the analysis and described in the previous section.            "
"38","Some retrospective raters (for example, the American Presidency Series) have comparatively low thresholds, and some contemporaneous raters (Mayhew Sweep 1, for instance) have high thresholds. More importantly, even though contemporaneous raters appear to employ lower thresholds, this is accounted for by the statistical model. A rater with a low threshold is comparatively less informative for distinguishing between significant legislation. The appropriate analogy is to an exam question testing for subject material knowledge: if it is so easy that every student answers it correctly, then it is comparatively less informative in determining student knowledge and distinguishing between student ability than a more difficult question. However, just as hard questions are useful for distinguishing between the smarter set of students, easier questions are useful for distinguishing between students who are less so. Rater heterogeneity is desirable precisely because it allows us to make these determinations.            "
"39","There is significant variation in the thresholds used by the various raters. Reassuringly, Sloan—who mentions only 16 statutes in his survey of 72 years of lawmaking—employs the highest threshold, and the “A to C” categorization of Howell and his colleagues (2000) employs the lowest threshold. Furthermore, it is not the case that all raters are equally responsive to the true underlying significance of legislation (z). The fact that Mayhew's Sweep 1 has a large estimate of β indicates that Mayhew's assessment is more likely to change in response to changes in the true underlying significance (z) than will the assessment of a rater with a lower discrimination parameter, such as the APSR.            "
"40","These differences can be illustrated by inspecting the item response curves implied by the parameter estimates reported in Table 2. Figure 1 plots the curves for selected raters. The disparity between the item discrimination parameters β is evident in the differences in the slopes. The flatter the line, the less responsive the rater is to the underlying latent significance z (plotted along the horizontal axis). The item difficulty parameter α determines the location of the curve in reference to the latent scale. The further to the right a curve is, the higher the threshold employed by the rater; for a given z, the rater is less likely to rate the statute as significant. In terms of the plotted raters, the measure of Howell and his colleagues (2000) is the least responsive to true significance, whereas Mayhew's Sweep 1 is the most responsive (steepest).27"
"41","                 Item Response Curves for Selected Raters                         "
"42","A related issue concerns inter‐rater comparability. For example, since the volumes of the New American Nation and American Presidency Series are written by different scholars, should they be treated as a single rater or as 20 and 11 raters, respectively? A consequence of employing an item‐response model is that this question is empirically resolvable. The question as to whether writers working within a multivolume series organized under specified goals are sufficiently similar can be answered by testing whether the item parameters of the various raters are statistically distinguishable. For example, we treat the Johnson volume of the American Presidency Series as a separate rater because it was clear in reading the work that its treatment of legislative accomplishment is systematically different from that of the other volumes. This is confirmed by the estimates reported in Table 2; the item parameters for the Johnson volume differ significantly from the parameters for the other volumes.            "
"43","Having established that the evaluations are based on a single evaluative dimension and illustrated the consequences of rater heterogeneity on the recovered estimates, we turn now to the statute estimates. Of most interest are the estimates and standard errors of legislative significance z for the 37,766 laws we analyze. We compare three estimates: the mean rating, the item‐response estimator described in an earlier 3, and the integrated estimator also described earlier. Figure 2 graphs the relationship between the recovered estimates. Recall that the scale is defined only relative to the identifying restrictions employed.            "
"44","                 Comparing Estimates of Legislative Significance                         "
"45"," Figure 2 illuminates several points. First, the relationship between the mean rating and the nonintegrated estimator in the top graph gives us reason to be suspicious of the assumption that significance is an additive function of the ratings: legislation with higher means are not always estimated to be more significant. This is a consequence of the fact that raters employ different thresholds: being mentioned by three raters with low thresholds may indicate less importance for a statute than being mentioned once by a rater with a very high threshold. Second, the change in estimated significance resulting from the first mention is more than the change resulting from the third mention (for example).            "
"46","The impact of employing an integrated estimator is made apparent in the bottom graph. The integrated estimator uses the regression structure to distinguish between legislative enactments with identical mean ratings. This is most apparent in the unmentioned legislation. Whereas the normal item‐response estimator locates all unmentioned statutes around 0, including statute characteristics distinguishes between the significance of unrated legislative enactments.28"
"47"," Table 3 provides an example of the power and face validity of our estimates for seven civil rights bills drawn from our list of public laws. Although examining the issue of civil rights is limiting in that most legislating took place from the 1950s onward, it is an illustrative example given its long and important history in our country and the fact that many are familiar with this legislation. Similar patterns are found in other policy areas.            "
"48","The highest score for a civil rights enactment, not surprisingly, is accorded to the Civil Rights Act of 1964. This bill massively expanded federal power over voting rights, outlawed discrimination in federally funded projects, and gave the attorney general new powers to prosecute state and local authorities who did not desegregate public accommodations. This bill was truly a landmark achievement, and we think it deserves a place atop our list of civil rights legislation. The second highest scoring civil rights bill on our list is the Voting Rights Act of 1965. Building on the 1964 act, this enactment made it illegal to use literacy tests and voter qualifications to screen out voters, brought in federal examiners to supervise registration in states where such requirements had existed, and established criminal penalties for those who violated the act. Below these two very influential landmark laws fall three important enactments passed in 1957, 1960, and 1982. The 1982 enactment, passed during the presidency of Ronald Reagan, was popularly called the Voting Rights Act Amendments of 1982. This law extended the key components of the Voting Rights Act of 1965 for 25 years and gave private parties standing in federal court to sue to overturn any law or procedure resulting in de facto discrimination. The Civil Rights Act of 1957, marshaled by then‐senator Lyndon B. Johnson, was a major enactment, but historical accounts tell us that the act that became law was very much watered down. Still, it was the first act of its kind in nearly a century, and therefore even a diluted enactment is quite important. Quite near the 1957 act in terms of significance is the 1960 Civil Rights Act. This act gave federal judges authority to assist people in voting and established criminal penalties for attempting to obstruct voting through violence."
"49","Two other enactments are less significant in comparison to these five enactments. Public Law 90–198, which passed in 1967, extended the life of the Civil Rights Commission by three years and made a nontrivial appropriation of $2.65 million to support it. Clearly this enactment, though important, is qualitatively different from major legislation such as the 1964 and 1965 acts. The second of these lesser enactments, Public Law 88–152, received a score well below the other laws in our table. This law provided relief for Mrs. Elizabeth Mason for the death of her husband, who died in combat in Belgium during World War II, and extended the Civil Rights Commission for one year. The law is a one‐sentence amendment that extended the Civil Rights Commission without an appropriation and is attached to what appears to be a private relief bill."
"50","These seven enactments provide strong face validity to our measure. The scores associated with these enactments are sensible and provide us with considerable information about the relative importance of the enactments. Our measures account for the fact that the 1964 and 1965 enactments differ from the acts passed in 1957, 1960, and 1982. In contrast, most existing lists treat these enactments as identically “notable” or “significant.”"
"51","Since we employ an integrated structure, we also recover an estimate of the extent to which observable covariates covary with legislative quality κ. Table 4 presents these estimated quantities. Recall that with the integrated model the regression parameter estimates κ account for the considerable uncertainty in the estimated significance of legislation z. To highlight the importance of accounting for the uncertainty present in the statute‐level estimates we present the results from running OLS on the posterior mean of the integrated statute estimates. Although the coefficient estimates are (as expected) almost identical, the OLS standard errors for the model ignoring uncertainty in the statute estimates are noticeably smaller.29"
"52","Although the regression structure used in the estimation does not exhaust the set of possible specifications, we can nonetheless draw several substantive conclusions. Consistent with expectations, legislative significance is increasing in the number of pages. Legislation whose page count differs by one standard deviation (55 pages) differs in predicted significance by 2.52. Important legislation is also more likely to require a conference committee to resolve House and Senate differences, to have several substitute bills, and be an omnibus bill. The purpose of the regression structure is not so much to suggest a causal explanation (although correlates of causal explanations could certainly be incorporated into the model), but rather to enable the estimating of the significance of unrated statutes using the plausible correlates of legislative significance.30 In terms of the relative impact on the estimated legislative significance of being mentioned by Mayhew's Sweep 1 (for example) and statute characteristics such as the length of legislation, note that a one‐standard deviation change in the logged page length results in a predicted significance change of .34. In contrast, since the implied threshold for Mayhew's Sweep 2 is 1.41, being mentioned in Sweep 2 implies a significance estimate of at least 1.41.31"
"53","Although useful for describing the scope of policymaking from 1877 to 1994, the true contribution of the statute significance measure is the opportunity to uncover the determinants of lawmaking. By measuring policy output, we enable investigations into the conditions under which lawmaking does and does not occur and assessments of the impact of institutional or preference changes. Although explanations of why institutional change occurs exists (for example, Schickler 2001), work assessing the impact on policy has been limited by the lack of measures comparable to the ones we offer.            "
"54","To measure legislative accomplishment we follow Mayhew (1991) and count the number of statutes passed each year. This productivity measure represents a descriptive, not normative, characterization. Although a year in which 15 significant public laws were passed was indeed more productive than a year in which three public laws were passed, the interpretation differs if the 15 statutes were passed in a year in which there were 40 opportunities for legislating and the three public laws represented the only opportunities for legislating change in the year they were passed. This is the “denominator” problem noted by Mayhew (1991).32"
"55","One difficulty raised by our measure is determining how to aggregate and summarize the statute‐level estimates. Existing dichotomous measures such as those of Mayhew (1991) and Stathis (2003) summarize productivity by counting the number of significant statutes enacted, treating every statute as being of equal significance. Since we estimate the significance for every public law, the appropriate measure for us is more ambiguous. Consequently, we follow Baumgartner and Jones (2002, 2004) and construct a measure focusing on statutes whose significance rank exceeds an exogenous threshold. Since the threshold is arbitrary—it is unclear whether analyzing the top 500 (of 37,766) enacted statutes provides a better measure of accomplishment than analyzing the top 2,000—we examine the consequences of several thresholds.            "
"56","The number of statutes passed is most similar to existing measures of accomplishment (for example, Baumgartner and Jones 2002, 2004; Mayhew 1991; Stathis 2003). Although it does capture differences in the quantity of legislation passed, this number cannot account for differences in quality. In counting the number of statutes passed that lie in the top 500 (for example), differences in the significance of enacted legislation in the top 500 are ignored and all legislation in the top set is treated equally. A second measure which arguably account for both quantity and quality considerations results if we sum the significance of every statute surpassing a given threshold. All else equal, Congresses that pass more legislation are judged to have accomplished more, and the higher the significance of the statutes passing the threshold, the higher the measure. Although in principle superior, the second measure correlates with the count measure at very high levels given the small significance differences among top‐rated statutes.            "
"57","One consequence of our statistical method is that our measure of accomplishment can account for the error in the statute‐level estimates. There are two sources of estimation error. First, since the statute‐level estimates being summed are measured with error, the summation will clearly contain error. The posterior mean is not perfectly measured, and a measure of accomplishment should reflect this imprecision. Second, because the significance of each statute is measured with error, the number (and identity) of statutes passing a given threshold during a particular Congress is subject to error. Each statute has a probability of lying in the top set that should be accounted for."
"58","A consequence of using a Bayesian estimator is that it is straightforward to calculate the posterior for any function of estimated parameters. Consequently, when summing the significance of the number of top statutes enacted, we account for both uncertainty in the probability that a statute lies in the top set as well as uncertainty in each statute's significance estimate. Figure 3 graphs the summed significance of the statutes passed by each Congress among the 3,500 and 500 most notable statutes passed from 1877 to 1994 and the 95% highest posterior density region for each.            "
"59","                 Congressional Accomplishment, 1887–1994                         "
"60","Regardless of the exogenous threshold used, the measure exhibits considerable similarity (the measure using the top 3,500 and top 500 statutes correlate at.87). Consequently, at least for nonnegligible thresholds, there is no evidence that the threshold used to define accomplishment matters. Reassuringly, the trend graphed in Figure 3 possesses strong face validity—the frenzied lawmaking of the “New Deal” and the “Great Society” are easily evident. For context, the shaded areas denote Congresses with unified party control of government. Although this measure, like all measures, is imperfect, the fact that it is responsive to both the quantity and quality of enacted legislation represents a notable advance over existing measures. Despite a healthy correlation with existing measures (for example, the correlations between the top 500 estimate plotted in Figure 3 and Mayhew's Sweep 1 and Sweep 2 are .94 and .94, respectively, and the top 3500 estimates correlate at .69 and .74, respectively), the ability to estimate statute‐level measures of significance can lead to important improvements in how we characterize legislative accomplishment. In addition to covering a longer time period than most ratings, our measure of accomplishment also accounts for statute‐level variation in the significance of enacted statutes.            "
"61","Studying policymaking—what we refer to as legislative accomplishment—is critical if we are to assess how well a political system is working. Unfortunately, theoretical progress in studying policymaking has not been matched by comparable empirical progress, and we believe that the lack of empirical progress can be attributed to the relative lack of attention paid to defining measures and deriving appropriate estimators."
"62","We present a new and more expansive measure of legislative significance that exploits existing and new data sources, including the assessments of legislative importance constructed by historians, policy experts, and the media and information on the characteristics of legislation. This measure uses recent statistical advances in item response modeling to address important limitations of existing measures. The end result is a significance score for every legislative enactment between 1877 and 1993—37,766 enactments in all as well as an assessment of the uncertainty of the legislative significance estimates. We also demonstrate how these scores can be aggregated to yield congressional (or yearly) legislative accomplishment scores and how these scores might be used to select important enactments."
"63","Although our larger project is oriented toward understanding lawmaking in the United States, it is important to reiterate the generality of the estimation method we present. An analogous procedure could be used to identify the relative importance of presidential executive orders, bureaucratic rule changes, and Supreme Court decisions. Furthermore, nothing restricts the method's application to policymaking in the United States; the accomplishments of any institution can, in principle, be assessed using the method we outline. All that is required is a set of assessments by chroniclers of the institution which are then analyzed using an item‐response model."
