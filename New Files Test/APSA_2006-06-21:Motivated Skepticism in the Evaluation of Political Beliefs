"","x"
"1","Our starting premise (following Kunda 1987, 1990) is that all reasoning is motivated. While citizens are always constrained in some degree to be accurate, they are typically unable to control their preconceptions, even when encouraged to be objective. This tension between the drives for accuracy and belief perseverance underlies all human reasoning. Keeping it simple and focusing on reasoning about things political, citizens are goal oriented (Chaiken and Trope 1999). Their motives fall into two broad categories: accuracy goals, which motivate them to seek out and carefully consider relevant evidence so as to reach a correct or otherwise best conclusion (Baumeister and Newman 1994; Fiske and Taylor 1991), and partisan goals, which motivate them to apply their reasoning powers in defense of a prior, specific conclusion (Kruglanski and Webster 1996). In our theory, partisan goals and subsequent selective information processing are driven by automatic affective processes that establish the direction and strength of biases (Lodge and Taber 2005; Taber, Lodge, and Glathar 2001). Sociopolitical concepts are “hot” for most people, so that associated attitudes come to mind automatically along with, indeed prior to, semantic information. One's likes or dislikes for Hillary Clinton, for example, are aroused even before conscious awareness of her identity and other semantic associations—that she is a Democratic senator, a woman, and a former first lady (Morris et al. 2003). These “hot cognitions,” in our view, motivate the partisan goals that drive normatively suspect selectivity in subsequent information processing.         "
"2","Surprisingly, given the widespread acceptance of selective attention, exposure, and judgment processes throughout the social sciences, the empirical evidence from social psychology is far more mixed and qualified than is often believed. The empirical status of selective attention and, in particular, selective exposure can best be characterized as uncertain (Abelson et al. 1968; Eagly and Chaiken 1993, 1998; Freedman and Sears 1965; Frey 1986; Greenwald et al. 2002; Kunda 1990; Lord 1992; Pomerantz, Chaiken, and Tordesillas 1995; Wicklund and Brehm 1976).         "
"3","Selective information processes are particularly important because of their impact on subsequent attitudes and behavior and because of their implications for the distribution of aggregate public opinion (Zaller 1992). Theoretically, we should expect attitude polarization: those holding strong prior attitudes become attitudinally more extreme on reading pro and con arguments because they assimilate congruent evidence uncritically but vigorously counterargue incongruent evidence (Ditto and Lopez 1992; Rucker and Petty 2004). Unfortunately, the empirical pedigree of this classic expectation is even more dubious than the various selectivity hypotheses. The most cited support for attitude polarization comes from the Lord, Ross, and Lepper (1979) study of attitudes toward the death penalty, but even this evidence is unconvincing because it is based on subjective rather than direct measures of polarization. Rather than comparing t1 and t2 measures of attitudes, Lord and his colleagues asked subjects to report subjectively whether their attitudes had become more extreme after evaluating pro and con evidence on the efficacy of capital punishment. Moreover, numerous attempts to replicate polarization using direct t1 and t2 measures of social and political attitudes have failed (e.g., Kuhn and Lao 1996; Miller et al. 1993; Pomerantz, Chaiken, and Tordesillas 1995).         "
"4","We believe that attitude polarization has been elusive in psychological research for at least two reasons. First, we suspect that the arguments and evidence used in many of these studies failed to arouse sufficient partisan motivation to induce much biased processing. Since most of the work in the cognitive dissonance tradition did not consider the strength of prior affect to be critical, little effort was made to create stimuli that would elicit strong affective responses. Some research, for example, relied on syllogistic arguments that are hard to understand (e.g., Oakhill and Johnson‐Laird 1985); other research used oversimplified policy statements comprised of a single stylized premise and conclusion (Edwards and Smith 1996). Selective biases and polarization, we believe, are triggered by an initial (and uncontrolled) affective response; by contrast, most of the work on selectivity and polarization in social psychology uses rather cold arguments and rests on theories of cold cognition (most commonly, dissonance theory).         "
"5","In our motivated reasoning experiments, we use statements and arguments taken directly from political interest groups, which are far more contentious and more in line with contemporary political discourse (Ailes 1995; Ansolabehere and Iyengar 1995); these arguments often generate strong affective responses (see Figure 2, below, for an example argument).         "
"6","                 The Primary Experimental Tasks (a) Information Board (b) Argument Strength Rating Box                      "
"7","The second and more difficult problem for those seeking to find attitude polarization is the weak measurement of attitude change and the severe scale constraints that ensue. Researchers have typically (e.g., Edwards and Smith 1996) relied on a single item, presented pre‐ and posttask, to measure attitude extremity and change. The problem, of course, in addition to the weak reliability of a single item, is that while the theory holds that those with the most extreme attitudes are the most prone to become even more extreme, detecting any such change is thwarted by the upper and lower bounds of the scale and by regression to the mean. We employ a six‐item additive scale to measure attitudes at t1 and t2, which improves measurement reliability and reduces the number of respondents at or near the scale limits at t1.         "
"8","Based on our theory of affect‐driven motivated reasoning, we posit three mechanisms of partisan or biased processing:"
"9","                        "
"10"," H1: a prior attitude effect, whereby people who feel strongly about an issue—even when encouraged to be objective and leave their preferences aside—will evaluate supportive arguments as stronger and more compelling than opposing arguments;                  "
"11"," H2: a disconfirmation bias, such that people will spend more time and cognitive resources denigrating and counterarguing attitudinally incongruent than congruent arguments; and                  "
"12"," H3: a confirmation bias, such that when free to choose what information they will expose themselves to people will seek out confirming over disconfirming arguments.                  "
"13","Because each of these mechanisms deposits more supporting than repudiating evidence in mind, we predict"
"14","                        "
"15"," H4: attitude polarization, whereby attitudes will become more extreme, even when people have been exposed to a balanced set of pro and con arguments.                  "
"16","Our theory, at first glance, might suggest we are arguing that people are closed‐minded, consciously deceiving themselves to preserve their prior beliefs. On the contrary, a key argument we make (Lodge and Taber 2005; Taber 2003) is that people are largely unaware of the power of their priors. It is not that they openly lie to themselves. Rather, they try hard to be fair‐minded or at least preserve the “illusion of objectivity” (Pyszczynski and Greenberg 1987), but they are frequently unable to do so. On the other hand, as the persuasion literature clearly shows (Petty and Wegener 1998) and as attested to in the study of voting behavior (Aldrich, Sullivan, and Borgida 1989; Rabinowitz and MacDonald 1989), even those committed to their positions can be persuaded by strong and credible counterevidence (Festinger 1957). But the research we report suggests that, once attitudes have become crystallized, persuasion is difficult. Asymmetrical skepticism—as would be reflected in the type of thoughts that come to mind as we read pro and con arguments—deposits in mind all the evidence needed to justify and bolster our priors with a clear conscience (Ditto et al. 1998).         "
"17","Being a motivated reasoner takes effort (Lavine, Borgida, and Sullivan 2000; Pomerantz, Chaiken, and Tordesillas 1995); hence we expect Hypotheses 1–4 to be conditional on the strength of one's prior attitude (motive) and on one's level of political sophistication (opportunity).         "
"18","                        "
"19"," H5: an attitude strength effect, such that those citizens voicing the strongest policy attitudes will be most prone to motivated skepticism; and                  "
"20"," H6: a sophistication effect, such that the politically knowledgeable, because they possess greater ammunition with which to counterargue incongruent facts, figures, and arguments, will be more susceptible to motivated bias than will unsophisticates.                  "
"21","Two experiments were carried out to test these six hypotheses.1 Participants (Ps) were recruited from introductory political science courses at Stony Brook University. Their participation, for which they received course credit, consisted of a single session lasting less than one hour (Study 1: N = 126, 59 male, 70 white, 64 Democrat, 34 Republican; Study 2: N = 136, 68 male, 64 white, 61 Democrat, 21 Republican). Since the two experiments share the same basic design, differing in but one manipulation, we will describe them together (Figure 1).         "
"22","                 Experimental Design                      "
"23","On entering the laboratory, Ps were seated individually at computers in separate experimental rooms and instructed that they would take part in a study of public opinion. Their first task was to evaluate a number of contemporary political issues, among them a battery of items tapping their attitudes on either affirmative action or gun control (with the sample split into two conditions by random assignment). These attitude measures included four items designed to measure attitude strength (recorded on 100 point‐sliding response scales) and six items that measure attitude position (9‐point agree/disagree Likert items; see http://www.stonybrook.edu/polsci/ctaber/taberlodgeajps05.pdf for the items). Additive scales were constructed for both variables and rescaled to [0,1] with responses below 0.5 indicating “weak” or “con,” respectively.2 In keeping with prior research (for an overview, see Petty and Krosnick 1995), strength and position are independent attitudinal dimensions such that some respondents took extreme positions on the issues without feeling strongly about those positions, and some moderates rode the fence with conviction.         "
"24","After completing the attitude battery for the first time, Ps practiced using an information board designed to track their search for pro or con information about affirmative action (or gun control in the other condition). They were instructed to view information in an evenhanded way so that they could explain the issue to other students (such instructions enhance accuracy motivation and work against partisan motivation). Our information board presented a matrix of 16 hidden policy arguments (rows and columns randomized), which Ps could only view by clicking on a button in the matrix (see Figure 2a). Rows of arguments were labeled with a known source, so that participants knew which hidden arguments would favor and which would oppose the issue; moreover, Ps were explicitly told each group's position on the issue as part of their instructions and were subsequently tested to make sure they understood. Ps viewed eight arguments with no time limit, but could not view the same argument a second time. The computer recorded the order and viewing time for each argument selected. This task provides our test for the confirmation bias—the prediction that people, especially those who feel the strongest and know the most, will seek out confirmatory evidence and avoid what they suspect might be disconfirming evidence. All Ps then completed the same attitude battery a second time (so as to measure t1→ t2 attitude change).         "
"25","A substantial set of demographic questions followed the information board task, including all the usual suspects: PID, ideological self‐placement, race, gender, etc., and most important for our purposes, a 17‐item general political knowledge scale (asking, e.g., “What proportion of Congress is needed to override a presidential veto?”). Our measure of political sophistication is the proportion of correct responses, which for many subsequent analyses we subject to a tertile split (so we may contrast the top and bottom thirds of the sample)."
"26","The second part of the experiments, testing for a disconfirmation bias, began with a third administration of the attitude battery as described above, but with the issues flipped across conditions, so that Ps who received affirmative action for the information board task now rated gun control, and vice versa. Ps were then asked to rate the strength of eight arguments, four pro and four con (presented sequentially in random order; see Figure 2b for a sample strength rating box). Again, Ps were instructed to be evenhanded and told that they would be asked to explain the controversy to other students (to maximize accuracy goals). This argument‐strength rating task was followed by the posttest attitude battery and a recognition memory test. In addition—this the only significant difference between Studies 1 and 2—Ps in Study 2 were asked to list their thoughts for two pro and two con affirmative action or gun control arguments.         "
"27","The arguments used in our experiments were drawn from print and online publications of real issue‐relevant interest groups (including the NRA, NAACP, Brady Anti‐Handgun Coalition, and the platforms of the Republican and Democratic parties). To control for such alternative explanations for processing bias as the “argument length = strength” or “complexity = strength” heuristics (Cobb and Kuklinski 1997; Petty and Cacioppo 1981), the arguments were edited such that they had similar complexities (length of sentence, average number of syllables, words per sentence, sentences per argument, reading level, and so forth) and were pretested on student samples (see the full set of arguments at http://www.stonybrook.edu/polsci/ctaber/taberlodgeajps05.pdf).         "
"28","Judgments of Argument Strength Our first hypothesis, the prior attitude effect, points to the difficulty people have in putting aside their prior feelings and prejudices when evaluating evidence, even when pro and con arguments have been presented to them in a balanced manner, and even when, as here, Ps are instructed repeatedly to “set their feelings aside,” to “rate the arguments fairly,” and to be as “objective as possible.”            "
"29","As an initial test of the prior attitude effect (Hypothesis 1), we compare the average strength ratings for pro‐attitudinal and counterattitudinal arguments, expecting Ps to rate the congruent stronger than the incongruent arguments. Arguments were rated on a [0,100] scale, with larger values denoting stronger ratings."
"30"," Figure 3 displays the results in sets of four bars, broken down by study, issue, sophistication, and strength of prior attitudes. Dark bars represent average strength ratings for pro arguments, light bars con arguments; the first pair of bars shows the responses of proponents of the issue, and the second pair shows responses of opponents. The prior attitude bias is indicated wherever we see higher ratings for congruent than incongruent arguments. Clearly, the prior belief effect is systematic and robust among sophisticates and those who feel the strongest, despite our best efforts to motivate evenhandedness (and despite the fact that across these samples and prior pretest samples, the eight arguments for each issue have statistically equivalent average strength ratings). By contrast with the most knowledgeable and most “crystallized” thirds of our sample, the least sophisticated respondents and those with the weakest prior attitudes on these issues show little or no prior belief effect.            "
"31","                 Argument Strength Ratings, by Sophistication and Strength of Prior                         "
"32"," Table 1 reports regression analyses of the impact of prior attitudes on argument strength ratings, with contrasts for the least and most sophisticated thirds of our samples and those with the weakest and strongest priors.3 Each P's overall rating of the strength of arguments (our dependent variable) was computed as the sum of ratings of the pro arguments minus the sum of ratings of the con arguments, recoded to [0,1]. To test for a prior attitude bias, we regressed these argument strength ratings on attitude extremity at time 1 (as measured by the six‐item scale described above, recoded to [0,1]). Significant, positive coefficients support the hypothesis: Ps who favor gun control or affirmative action rate congruent arguments as stronger than incongruent arguments, while those opposed see the con arguments as stronger. Table 1 shows a strong prior attitude effect in the predicted direction, with only nonsophisticates and those with weak priors failing to show the effect.            "
"33","A Disconfirmation Bias In addition to the prior belief effect, we predict a disconfirmation bias whereby people will too readily accept confirmatory arguments more or less at face value but actively counterargue attitudinally incongruent evidence (Hypothesis 2). Moreover, like the prior belief effect we expect this bias to vary with sophistication and strength of prior attitude. Our experimental design allows multiple tests for these predictions. If indeed people actively challenge attitudinally incongruent arguments, we would expect them to take more time processing counterattitudinal arguments than pro‐attitudinal arguments, and to spend the extra time denigrating, deprecating, and counterarguing the incongruent arguments.            "
"34","Unbeknownst to the Ps, as they read the eight arguments the computer kept track of the time that elapsed from when they clicked open an argument until they submitted their strength rating. This reading time variable provides an initial test of the disconfirmation bias. Because the pattern of results is the same for both affirmative action and gun control, we show both issues combined in Figure 4, broken down by study to underscore the robustness of the results. For simplicity, and because each study shows virtually the same pattern when taken separately, we report ANOVA analyses for both studies combined. As suggested in Figure 4, Ps in both studies across both issues did take longer to read and process attitudinally challenging arguments, F (1,107) = 3.39, p= .068. When averaging across all participants this difference was fairly small (on the order of 1–2 seconds), but the contrast becomes significantly greater for sophisticates and those with stronger prior attitudes (4–7 seconds, or a 25–50% increase in processing time for attitudinally incongruent arguments). Indeed, though there were no significant main effects on reading time for sophistication and attitude strength, the interactions of sophistication and strength with argument congruence were highly significant: sophistication * congruence, F (1,107) = 9.96, p= .002; attitude strength * congruence, F (1,107) = 4.41, p= .038. Finally, it is interesting to note that unsophisticated participants with weak prior attitudes actually spent longer processing congruent arguments, which suggests a confirmatory bias for those participants who lack the resources and motivation to disconfirm challenging arguments.            "
"35","                 Read Times for Argument Strength Ratings                         "
"36","What were the Ps doing with the extra time spent reading the contrary arguments? To explore this question, we asked participants in Study 2 to list their thoughts for four of the eight arguments they rated, two pro and two con.4 Our theoretical expectation is that whereas most Ps quickly (and relatively thoughtlessly) assimilate supporting arguments, they more actively process contrary arguments, generating thoughts that denigrate or counter these arguments and bolster their prior convictions. We carried out a direct test of this disconfirmation hypothesis by examining the content of the thoughts Ps listed in response to the two pro and two con arguments for each issue. We coded each thought into one of seven categories (following Edwards and Smith 1996) and then aggregated these codes into three basic response types: affect, including general affect for the argument, for the evidence, and for the conclusion; new information, including a new fact not present in the argument or a new argument; and comments about the evidence or about the source. And of course each thought was coded as denigrating or bolstering the presented argument.            "
"37"," Figure 5 depicts these data graphically for both issues combined, breaking down the mean number of thoughts by congruence and sophistication. On average, Ps made 2.5 comments per argument (for a total of 10 thoughts across the four arguments), but there were considerable differences across participants. Perhaps not surprisingly, sophisticated participants produced many more thoughts overall than did their less knowledgeable peers. More interesting, as predicted incongruent arguments elicited far more thoughts than did congruent ones, and these were almost entirely denigrating. Both sophisticated and unsophisticated participants showed this basic pattern of bolstering congruent arguments while denigrating incongruent ones, though sophisticates were clearly more biased. Finally, although we had asked Ps to leave their feelings aside and to concentrate on what made the arguments weak or strong, it is interesting that a goodly number of Ps made simple, content‐free affective statements (the darkest portion of each bar), to the effect “I like (don't like) this argument or conclusion” or simply said they liked or disliked the facts or figures supporting an argument. The more demanding types of responses were the introduction of a new fact or an original argument (medium gray) and a comment on the source or quality of the evidence (light gray). In both instances the new evidence brought to mind was overwhelmingly congruent with their priors. Overall, this pattern perfectly conforms to our expectations about disconfirmation.            "
"38","                 Mean Number of Thoughts for Congruent and Incongruent Arguments                         "
"39","We performed a mixed‐model ANOVA on the number of thoughts generated, with sophistication as a between subjects variable and argument type (congruent or not) and response type (bolster or denigrate) as within subjects variables. The results from this analysis strongly confirm the pattern reported above, with significant main effects for sophistication, F (1,89) = 6.37, p= .013, and argument congruency, F (1,88) = 4.57, p= .045. Moreover, there was a highly significant two‐way interaction between argument congruency and response type, F (1,88) = 10.05, p= .002, and a significant three‐way interaction between congruency, response type, and sophistication, F (1,88) = 4.07, p= .047, such that sophisticates even more than unsophisticates tend to denigrate incongruent arguments and bolster congruent ones.            "
"40","A Confirmation Bias In both experiments, we tested the hypothesis that when given a chance to pick and choose what information to look at—rather than when presented with pro and con arguments—people will actively seek out sympathetic, nonthreatening sources (Hypothesis 3). Both in the “real world” (where Volvo owners read Volvo ads) and in the lab using the information board, citizens can sometimes choose to selectively look or not look at information from the opposing side. It bears repeating that this selective exposure hypothesis has met with mixed empirical results in the psychological literature. We believe that this failure to clearly confirm one of the classic expectations of the cognitive dissonance tradition is at least partly due to the affectively tepid issues and arguments that have been used to test it (Edwards and Smith 1996). We expect to find evidence of the confirmation bias with the more contentious and challenging political issues and arguments found in real‐world politics.            "
"41","Recall that in part 1 of both experiments Ps were shown a computerized information board in which each row of a matrix of 16 policy arguments was labeled with a well‐known opinion source for the given issue (Figure 2a). As always, instructions were designed to maximize accuracy goals and minimize partisan bias. The most direct measure of bias in search is the proportion of pro‐attitudinal hits out of the eight arguments looked at. Figure 6 displays these data graphically by study, issue, and sophistication. For all groups examined, proponents of the issue sought out more supporting than opposing arguments, and this difference was quite substantial for sophisticates in both studies and for both issues. When given the chance, sophisticated respondents selected arguments from like‐minded groups 70–75% of the time. For example, on average sophisticated opponents of stricter gun control sought out six arguments of the NRA or the Republican Party and only two arguments from the opposition.            "
"42","                 Proportion of Pro‐Attitudinal Hits in Free Search                         "
"43"," Table 2 presents the results from a regression of this bias measure on t1 attitude extremity for both studies and both issues. The results are straightforward and confirm the pattern in Figure 6: Ps were more likely to read the argument of a sympathetic source than to expose themselves to an opposing point of view. Supporters of gun control or affirmative action were significantly more likely to search out the arguments of “their” issue groups (e.g., Citizens Against Handguns or the NAACP). As expected, these results are particularly pronounced for sophisticates, where, for example, every 10% increase in support for affirmative action in Study 1 led to a 7.78% increase in the proportion of pro‐affirmative action hits on the information board. By contrast, the results for strength of priors were mixed.5"
"44","As an interesting side note, we also recorded the reading times for Ps in the information board task, expecting a replication of our disconfirmation bias for Ps who did open counterattitudinal arguments. This is what we found. On average across both experiments, Ps spent about 2 seconds longer reading incongruent arguments, with sophisticates spending more than 5 seconds longer when considering an argument from the opposition."
"45","Attitude Polarization All of these mechanisms—the prior attitude effect, the disconfirmation bias, and the confirmation bias—should theoretically lead to attitude polarization because they deposit more supportive evidence and affect in memory (both in online evaluations and in the associated cognitions that may provide the grist for memory‐based processing). Our theory suggests that those on either side of the issues should become more attitudinally extreme in their positions, despite the fact that they were exposed to the same balanced stream of information. As we have already noted, concerted efforts by psychologists to find attitude polarization in bias studies have largely failed when they have used the appropriate direct measures of attitude change.            "
"46","To test the polarization hypothesis, we regressed t2 attitude extremity on t1 extremity. Coefficients significantly greater than 1 indicate polarization (that is, each unit movement on the t1 attitude scale corresponds to more than a unit increase on the t2 scale).6 As always, we report contrasts by sophistication and strength of prior attitude; we also consider contrasts of the top and bottom thirds of the sample in degree of bias in the given processing mechanisms. That is, we perform a tertile split on the variables that measure confirmation and disconfirmation biases—the proportion of pro‐attitudinal hits in the information board task and the average pro minus average con ratings in the argument strength task, respectively—and contrast the top and bottom thirds.            "
"47","Pooling the data from both studies (for statistical power), we find strong evidence of attitude polarization for sophisticated participants, those with strong priors, and (most importantly) those who were biased in their information processing. We find polarization across both tasks and both issues (indeed, only one of 12 expected cells in Table 3 fails to achieve significance—strong priors for gun control in the information board task).7 Looking at the most sophisticated third of the sample who rated affirmative action arguments, for example, the regression slope (1.268) indicates that those with positive priors had even more positive posteriors, while those with negative priors had even more negative posteriors (on average, 27% more extreme). By contrast, unsophisticates and those with weak priors did not polarize (unsophisticates who rated the strength of affirmative action arguments present the one exception to this pattern).            "
"48","Finally and most important, we find substantial polarization among participants who processed information in a biased manner, but not among those who were less biased. This finding directly and clearly links the processes of motivated skepticism to attitude polarization as our theory predicts, something that previous research has not been able to do. Those participants whose argument strength ratings were most skewed by disconfirmation biases had significantly more extreme attitudes on affirmative action and gun control after rating the arguments, while those whose ratings were more evenhanded showed no significant attitude polarization. Similarly, confirmation biases—seeking out attitudinally consistent arguments while avoiding inconsistent arguments in the information board—led to more extreme attitudes as compared to the least biased participants for both issues."
"49","In short, despite our best efforts to promote the evenhanded treatment of policy arguments in our studies, we find consistent evidence of directional partisan bias—the prior attitude effect, disconfirmation bias, and confirmation bias—with a substantial attitude polarization as the result. Our participants may have tried to be evenhanded, but they found it impossible to be fair‐minded."
"50","Our studies show that people are often unable to escape the pull of their prior attitudes and beliefs, which guide the processing of new information in predictable and sometimes insidious ways. But what does this mean for citizens in a democracy? From one perspective the average citizen would appear to be both cognitively and motivationally incapable of fulfilling the requirements of rational behavior in a democracy. Far from the rational calculator portrayed in enlightenment prose and spatial equations, homo politicus would seem to be a creature of simple likes and prejudices that are quite resistant to change. Can this possibly be rational? The normative question, it seems, turns on whether the processing of new information and the updating of one's attitude needs to be independent of one's priors.         "
"51","From one point of view with which we are sympathetic, it can be argued that the attitude strength effect and disconfirmation bias are rational responses to attitude‐relevant information; it is perfectly reasonable to give heavy weight to one's own carefully constructed attitudes. This perspective, which would substitute the word “skepticism” wherever “bias” appears in this article, suggests that beliefs and attitudes may be thought of metaphorically as possessions to be protected (Abelson and Prentice 1989). This belief, this feeling, is mine! Like other possessions we paid a purchasing price in terms of time and cognitive resources spent forming and updating our impressions. Many political attitudes, especially those linked to identity (Conover 1988), are worthy of such defense in their own right. To the extent one's attitude reflects considerable prior thought, it may well be more trustworthy than new information, especially if—as is so often the case in the political realm—that new information reflects the strategic behavior of political opponents. Simply put, if one thinks (more pointedly, feels) that the veracity of the evidence is dubious, the opposition is wrong, or the media hostile, then why pay them heed?         "
"52","From another perspective, with which we also have sympathy, Bayesian updating requires independence between priors and new evidence (Evans and Over 1996; Green and Shapiro 1994; but see Gerber and Green 1998). In the extreme, if one distorts new information so that it always supports one's priors, one cannot be rationally responsive to the environment; similarly, manipulating the information stream to avoid any threat to one's priors is no more rational than the proverbial ostrich.         "
"53","For many citizens, perhaps, the bias may be less extreme, but there are certainly ideologues and bigots who fit both of these descriptions. Luker (1984), for example, found that attitudes among abortion activists are so linked to their beliefs and feelings about sexuality, gender, religion, and family, that they have become completely incapable of entertaining points of view that challenge their own. Sears and Whitney (1973) have found similar stubborn adherence to prior attitudes among those watching a political debate. Our own evidence, presented above, presents a compelling case that motivated biases come to the fore in the processing of political arguments even for nonzealots.         "
"54","On the other hand and contrary to the intuitions of normative theory (but consistent with the predictions of cognitive psychology), we do find that those with weak and uninformed attitudes show less bias in processing political arguments. This finding may tempt the conclusion that objectivity and tolerance rest more on ignorance and apathy than on the elite skills of ideal citizens. Perhaps we have been looking for rational citizenship in all the wrong places, and it is the great unwashed who save democracy! Provocative though it may be, this interpretation does not stand up to normative, theoretical, or empirical scrutiny. First, we find no empirical evidence of principled moderation among the bottom or middle thirds of our sample, whose extremity scores were statistically indistinguishable from those of the most sophisticated participants. Second, our theory predicts less bias for unsophisticated and uncommitted respondents not because they possess a greater sense of evenhandedness, but rather because they lack the motivation and ability to engage in attitude defense. Finally, this same lack of motivation and knowledge undermines the ability to apply individual preferences to public policy that underlies a normatively secure democracy, so it would be a dysfunctional objectivity at best."
"55","If we push either side of the rationality argument too strongly we end up playing the clown. So how do we reconcile these positions? Skepticism is valuable and attitudes should have inertia. But skepticism becomes bias when it becomes unreasonably resistant to change and especially when it leads one to avoid information as with the confirmation bias. And polarization seems to us difficult to square with a normatively acceptable model (especially since the supporters and opponents in the policy debate will diverge after processing exactly the same information). Moreover, up to some tipping point for persuasion, our model predicts polarization even from unbalanced and counterattitudinal streams of information (see also Rahn, Aldrich, and Borgida 1993; Redlawsk 2001).         "
"56","How we determine the boundary line between rational skepticism and irrational bias is a critical normative question, but one that empirical research may not be able to address. Research can explore the conditions under which persuasion occurs (as social psychologists have for decades), but it cannot establish the conditions under which it should occur. It is, of course, the latter question that needs answering if we are to resolve the controversy over the rationality of motivated reasoning.         "
