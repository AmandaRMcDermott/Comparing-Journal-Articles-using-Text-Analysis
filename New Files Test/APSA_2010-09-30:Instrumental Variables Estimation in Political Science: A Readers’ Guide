"","x"
"1","Instrumental variables estimation is traditionally explicated using structural econometric models (Bowden and Turkington 1984; Theil 1971), with more recent textbooks using potential outcomes notation as well (Morgan and Winship 2007; Wooldridge 2002). The former has the virtue of simplicity, and so we start with it. The latter has the advantage of calling attention to several assumptions that are often implicit in or ignored by traditional treatments. This section provides a succinct overview of the logic underlying IV regression; for more detailed statistical exposition, see Murray (2006a), Gelman and Hill (2006), and Angrist and Pischke (2008).         "
"2","The traditional structural equation model posits a linear and additive relationship between a dependent variable (Yi), an endogenous regressor (Xi), a set of exogenous covariates (Q1i, Q2i. … QKi), and an unobserved disturbance term (ui), each indexed with the subscript i to refer to observations 1 through N. In this model            "
"3","A model of this form allows for consistent estimation of β1 via ordinary least squares (OLS) if . In other words, as the sample size approaches infinity, OLS will converge on the true parameter (β1) so long as the covariance between Xi and ui approaches zero. The motivation for instrumental variables estimation is that this requirement is violated when Xi is systematically related to unobserved causes of Yi. Violations of this sort commonly occur when factors related to Xi that predict outcomes are omitted from the regression model or when independent variables are measured with error (Wooldridge 2002, chap. 5). One need not believe that Yi is causing Xi in order to have good reason to use IV. Two‐way causation is not the only concern.         "
"4","The instrumental variables estimator is premised on a two‐equation model in which the endogenous regressor (Xi) is written as a linear function of an instrumental variable (Zi) and the covariates.1"
"5","The instrumental variables estimator in this case may be obtained by two‐stage least squares: regress Xi on Zi and the covariates; use the coefficients from this first‐stage regression to generate predicted values of Xi; and regress Yi on the predicted values of Xi as well as the covariates. This estimator presupposes that Zi is not an exact linear combination of the covariates in the first stage; if it were, the predicted values of Xi would be collinear with the covariates in the second stage, and the estimator would be undefined. Beyond this simple mechanical requirement, instrumental variables regression generates consistent estimates of β1 when two conditions are met. The first is that the covariance between Zi and ui goes to zero as N becomes infinite. When critics question the validity of an instrument, they are challenging whether Zi is truly unrelated to unobserved factors that affect Yi.         "
"6","The validity of an instrument may be challenged on various grounds, depending on the research design. In the context of experimental studies using a so‐called encouragement design, subjects may be randomly assigned (Zi) to receive a treatment (Xi). Well‐known examples of this type of design are randomly assigned encouragements of patients to get a flu vaccination (Hirano et al. 2000) or randomly assigned attempts by canvassers to mobilize voters on the eve of an election (Gerber and Green 2000). The fact that encouragements are randomly assigned means that Zi is independent of other preexisting causes of Yi, which makes Zi a potentially valid instrument. For Zi to be valid, however, it must transmit its influence on the outcome solely through the mediating variable Xi. In the case of the flu vaccine study, one could imagine a violation of this condition were it the case that encouragement to get a vaccine, rather than the vaccine itself, affected health outcomes. In the case of voter mobilization experiments, this assumption would be violated, for example, if another mobilization campaign learned of the experimental groups and directed its canvassers to contact the experimenter’s control group.3 In such cases, Zi affects Yi through some channel other than Xi.         "
"7","In nonexperimental research, the validity of this assumption is often unclear or controversial. As Dunning (2008, 288) points out, instrumental variables may be classified along a spectrum ranging from “plausibly random” to “less plausibly random.” In the category of plausibly random are IVs that are determined by forces that have little apparent connection to unmeasured causes of Yi. Researchers in recent years have generated a remarkable array of these kinds of studies. Duflo and Pande (2007) use land gradient as an instrument for dam construction in explaining poverty. Acemoglu, Johnson, and Robinson (2001) use the mortality of colonial settlers to estimate the effect of current institutional arrangements on economic performance. Kern and Hainmueller (2009) use whether an individual lives near Dresden as an instrument to determine the effect of West German television on political attitudes in East Germany. Whether these instruments qualify as “plausibly random” is a matter of opinion, but at least the authors advance reasoned arguments about why such instruments are independent of unobserved factors that affect the dependent variable. Less plausibly random IVs include variables such as demographic attributes in studies of political attitudes or higher‐order powers of the predictors in equation (1). These variables are dubbed instruments as a matter of stipulation, often without any accompanying argumentation. Whether such variables are truly unrelated to the unmeasured causes of Yi is uncertain and perhaps even doubtful.         "
"8","Even well‐reasoned IV specifications may involve modeling uncertainty (Bartels 1991), and this modeling uncertainty should be reflected in the standard errors associated with IV estimates. However, it is difficult to quantify this uncertainty, and current reporting conventions essentially ignore it (Gerber, Green, and Kaplan 2004). Reported standard errors, in other words, presuppose no modeling uncertainty at all. Thus, it is left to the reader of instrumental variables regression to form an opinion about the plausibility of the exclusion restrictions and to adjust the reported standard errors accordingly.         "
"9","Ideally, such opinions are guided by authors’ explanations for why the exclusion restrictions are plausible. Unfortunately, as documented below, explanations of this sort are frequently absent from political science publications using IV regression. It should be noted that the plausibility of the exclusion restriction hinges on argumentation; it cannot be established empirically. Occasionally, one observes political scientists arguing that an instrument is valid because it does not significantly predict Yi in an OLS regression of Yi on Xi, Zi, and covariates. This misguided regression does not provide reliable information about whether Zi is excludable.4"
"10","The second assumption is that the covariance of Zi and Xi (after partialling out the covariance that each variable shares with the covariates) converges to some nonzero quantity as N becomes infinite. Unlike the question of whether instrumental variables are valid, which is largely theoretical, the second assumption can be tested in finite samples based on the empirical relationship between Zi and Xi. If the partial correlation between Zi and Xi (controlling for Q) is low, the so‐called weak instruments problem can lead to substantial finite sample bias even when there is only a slight correlation between Xi and ui. Wooldridge (2009, 514) provides a useful heuristic discussion of the weak instruments problem in the simple case where equation (1) excludes covariates (i.e., all γk= 0). He notes that in this case the probability limit of the IV estimator may be expressed as , where rAB denotes the correlation between the variables A and B. This formula makes clear that although the correlation between the instrumental variable (Zi) and the disturbance term (ui) may be very slight in a given application, the amount of bias may be very large if the correlation between (Zi) and (Xi) is also very small. Fortunately, the problem of weak instruments is relatively easy to diagnose. Stock and Watson (2007) suggest conducting an F‐test that compares the sum of squared residuals from two nested models: equation (2) versus a restricted regression that excludes the instrumental variable(s). For a single instrumental variable, F statistics under 10 are thought to suggest a problem of weak instruments.5"
"11","To this point, we have considered a system of linear equations in which the effect of Xi is assumed to be constant across all observations. This assumption may fail to hold in a variety of applications. For example, suppose an interest group randomly assigns voters to receive calls designed to persuade them to vote for a particular candidate. It may be that targeted voters who are easy to reach by phone are more responsive to campaign appeals than voters who are hard to reach. Indeed, the campaign may target a particular group precisely because they are both easy to reach and especially responsive to the message. The problem is that IV regression estimates the so‐called local average treatment effect (LATE), that is, the average treatment effect among those who would be contacted if assigned to the treatment group but not contacted if assigned to the control group. This local average treatment effect may be different from the average effect in the entire population of voters.         "
"12","In order to highlight the assumptions that come into play when we allow for heterogeneous treatment effects, we apply the potential outcomes framework discussed by Angrist, Imbens, and Rubin (1996) to the application described by Albertson and Lawrence (2009) in their study of the effects of viewing a Fox News Special on voters’ support for a ballot proposition on affirmative action. In their experiment, which we discuss in more detail below, subjects who were randomly assigned to the treatment group were encouraged to view the program, and the outcome measure of interest is whether, in the context of a follow‐up survey, subjects reported supporting the ballot measure. For ease of exposition, we assume that assignment, treatment, and outcomes are each binary variables. We characterize the dependent variable as a pair of potential outcomes for subject i: yi1 denotes the subject’s voting behavior if exposed to the Fox News Special, and yi0 denotes the subject’s response if not exposed to this show. Thus, when classified according to their potential responses to the treatment, there are four possible types of subjects: those who oppose Proposition 209 regardless of whether they are treated (yi1= 0, yi0= 0), those who support Proposition 209 if treated and not otherwise (yi1= 1, yi0= 0), those who oppose Proposition 209 if treated and support it otherwise (yi1= 0, yi0= 1), and those who support Proposition 209 regardless of whether they are treated (yi1= 1, yi0= 1). Note that we will assume that a person’s response is solely a function of whether he or she personally is treated; assignments or treatments applied to others have no effect. This requirement is known as the Stable Unit Treatment Value Assumption, or SUTVA (Rubin 1978). We further assume what Angrist and Pischke (2008, 153) call the independence assumption: the potential outcomes (yi0, yi1) are independent of assigned treatment. In addition to independence, we assume that apart from increasing the probability of viewing, assignment to the treatment group has no effect on the outcome. This is simply a restatement of the exclusion restriction.         "
"13","Turning now to potential outcomes associated with receiving the treatment, we further distinguish among four potential responses to the experimental encouragement to view the show. Using Angrist, Imbens, and Rubin’s (1996) terminology, we call “Compliers” those who view the Fox News Special if and only if they are assigned to the treatment group. Those who watch the special program regardless of whether they are assigned to the treatment group are called “Always‐Takers.” Those who do not watch regardless of the experimental group to which they are assigned are called “Never‐Takers.” Finally, those who watch only if they are assigned to the control group are called “Defiers.”         "
"14","Based on this setup, there are 16 possible combinations of yi and xi, which is to say 16 possible kinds of subjects. Table 1 describes each of the possible voter types. Each type comprises a share πj of the total subject population, with . When we speak of the complier average causal effect (CACE), we refer to the causal effect of viewing the Fox News Special among those who are Compliers. From Table 1, we see that the complier average causal effect is            "
"15","Empirically, we are limited by the fact that we do not observe yi1 and yi0 for the same individuals. Instead, one outcome is observed, and the other remains counterfactual. In order to estimate the complier average causal effect, a researcher may conduct a randomized experiment. Suppose that the researcher randomly assigns subjects to the treatment group (Zi= 1) or the control group (Zi= 0). Among those assigned to the treatment group, some watch the Fox News Special (Zi= 1, Xi= 1) and others do not (Zi= 1, Xi= 0). Among those assigned to the control group, some watch the Fox News Special (Zi= 0, Xi= 1) and others do not (Zi= 0, Xi= 0).         "
"16","A randomized experiment provides estimates of several potentially useful quantities. We will observe the average outcome among those assigned to the treatment group, the average outcome among those assigned to the control group, and the proportion of each experimental group that is actually treated. As Angrist, Imbens, and Rubin (1996) point out, even this information is insufficient to identify the causal effect without further assumptions. In particular, we assume that the population contains no Defiers (i.e., π13=π14=π15=π16= 0). This stipulation is known as the monotonicity assumption (Angrist, Imbens, and Rubin 1996): no one watches the Fox News Special if and only if he or she is assigned to the control group. With these assumptions in place, the experimental design enables the researcher to identify the complier average causal effect, which is also the local average treatment effect.6"
"17","The mechanics of this identification result become apparent as one traces the groups depicted in Table 1 as a treatment is administered. The researcher observes the rate of Proposition 209 support in the assigned treatment group (Zi= 1) and in the assigned control group (Zi= 0). As the number of control group observations Nc→∞, the observed rate of support in the assigned control group () may be expressed as            "
"18","It should be stressed that the researcher will not know the identities of the Compliers. In the treatment group, Compliers look just like Always‐Takers, and in the control group, Compliers look just like Never‐Takers. Moreover, Compliers’ share of the population depends on the nature of the experimental encouragement. If the encouragement is weak, there will be relatively few Compliers. The broader point is that even very large experiments may generate different results depending on which sorts of people are induced to comply with the encouragement. This point is glossed over in most traditional presentations of instrumental variables estimation, which assume constant treatment effects. Once heterogeneous treatment effects are admitted as a possibility, caution must be exercised when extrapolating from an estimated LATE to other settings or populations. Even within a given sample, the average treatment effect among Compliers may not generalize to non‐Compliers."
"19","In political science, the quantity and quality of instrumental variables applications have evolved considerably over time. In this section, we describe trends in the use of instrumental variables in leading political science journals. We analyze articles appearing in the American Political Science Review, the American Journal of Political Science, and World Politics during the period 1985–2008. The APSR and AJPS were chosen because articles in these journals employ instrumental variables methods more often than do articles in other political science journals listed in JSTOR during the period of interest. We included World Politics as well to ensure that our sample was representative of literature in international relations and international political economy. Articles spanning the years 1985–2007 in the AJPS, 1985–2005 in the APSR, and 1985–2003 in World Politics were obtained through searches in JSTOR. For more recent articles, the journals were searched directly. In the case of World Politics, the Project Muse website was searched. Search terms included “instrumental variable,”“instrumental variables,”“2sls,”“3sls,” and “stage least squares.”7 A detailed listing of the articles retrieved in this search may be found in the supplementary appendix. Table 2 presents summary statistics of the 102 articles for which instrumental variables methods were mentioned in the body of the text. The articles were divided into four chronological groups: 1985–90, 1991–96, 1997–2002, and 2003–2008. Each article was further classified according to three criteria: the way in which exclusion restrictions are justified, whether the model is just‐identified or overidentified, and whether first‐stage results are presented.         "
"20","Our content analysis classified authors’ justifications for the choice of instruments into one of the following categories: “Experiment,”“Natural Experiment,”“Theory,”“Lag,”“Empirics,”“Reference,” or “None.” The “Experiment” category comprises instrumental variables that were formed through random assignment, regardless of whether a researcher or government agency conducted the randomization.8 In principle, instruments that were formed by random assignment satisfy Assumption 1, although any given application may suffer from problems that undermine random assignment, such as sample attrition that afflicts the treatment and control groups differently.         "
"21","The next category, “Natural Experiment,” includes instruments that were not formed using random assignment but can still be considered “plausibly random.” It turns out that this category includes just one article, as only Lassen (2004) employed a near‐random intervention as an instrumental variable. In order to estimate the effect of information on voter turnout, Lassen exploits a Copenhagen referendum on decentralization that was carried out in four of 15 city districts. The districts were created for the purpose of the experiment, and four districts, chosen to be representative of the city, introduced local administration for a four‐year period. The instrument seems “plausibly random” since it was created using near‐random assignment.         "
"22","The third category, “Theory,” includes articles in which authors provide a theoretical explanation for the validity of their exclusion restrictions. In other words, the authors presented some type of reasoned argument for why the chosen instrument should be uncorrelated with the error term. An example of a theoretical argument that falls into this category is Tsai (2007), which uses rural Chinese temple activity before 1949 to instrument for the current existence of a temple manager to explain public goods provision. Tsai argues that “because of the nearly complete eradication of community temples and collective temple activities and the radical social upheaval during the Maoist period … it is unlikely that a history of precommunist temple activity has influenced the current performance of village governments in any way except by making the current existence of temple groups more likely by providing a familiar template for newly organizing social groups” (2007, 366). Each article in this category contains justifications such as Tsai’s; however, the strength of argumentation about the validity of the exclusion restrictions varies widely. For example, many authors used variables such as age, gender, or education as instruments, arguing that these should be unrelated to the error term in their regression equation. Our content analysis took a permissive view of what constitutes a theoretical justification.         "
"23","The fourth category, “Lag,” includes IVs that were generated by lagging variables.9 In certain cases, one can make compelling theoretical arguments for using a lagged variable as an instrument. For example, Gerber (1998) presents a model estimating the effect of campaign spending on Senate election outcomes. To estimate incumbent vote percentage, the endogeneity of campaign spending must be dealt with. He instrumented for campaign spending using lagged spending by incumbents and challengers, arguing that “due to the staggered nature of Senate elections, the previous race and the current race rarely involve the same incumbent or challenger. The variable is therefore free from the criticism that might be applied to lagged spending by the same candidate, namely, that specific candidate attributes are correlated with both the regression error and past fundraising levels” (Gerber 1998, 405). Again, instrumental variables in this category must be viewed with caution, as their validity depends on the strength of the author’s argumentation.         "
"24","The fifth category, “Empirics,” includes IVs that were selected based on the results of an empirical test. For example, researchers regress Y on X and Z to show no correlation between Y and Z or regress X on Z to determine the most highly correlated instruments. Such empirical tests do not convincingly demonstrate the validity of the exclusion restrictions. The first regression is biased insofar as X is endogenous (suspicions about endogeneity are presumably what impelled the researcher to turn to IV regression); the second regression says nothing about whether Z is independent of the disturbance term."
"25","Our sixth category, “Reference,” contains articles in which the author explains the validity of his or her exclusion restrictions by citing another author’s work. For example, Lau and Pomper (2002) employ the same instruments as Gerber (1998) and merely cite Gerber’s work rather than providing a full justification for their selection.         "
"26","Finally, the category “None” includes all articles where no justification for the exclusion restrictions is provided. Two coders evaluated each article in order to confirm the lack of explanation."
"27"," Table 2 displays some encouraging trends. First, it is clear that the percentage of articles that provide some justification for the choice of instruments increased substantially over time. A growing proportion of articles fell into the “Experiment,”“Natural Experiment,”“Theory,”“Lag,” and “Reference” categories. Collectively, the articles in these categories increased from a low of 14% between 1991 and 1996 to 56% in the most recent period. During this period, the use of experiments and natural experiments emerged, growing from 0% in early periods to 6% most recently. Another encouraging sign is the rising percentage of just‐identified models. Apparently, the realization that valid instruments are hard to find and defend gradually led political scientists to become more discriminating in their choice of instruments.10 These numbers suggest a trend of increasing sophistication among political scientists in selection and implementation of instrumental variables methods. Reporting practices also became more transparent over time. The percentage of articles reporting the first‐stage relationship between Z and X increased from a low of 7% between 1991 and 1996 to 33% between 2003 and 2008.         "
"28","In absolute terms, however, there is still much room for improvement. Almost half of the articles published as late as 2003–2008 offered no argumentation or deficient argumentation. A minority of articles presented first‐stage results, and only a fraction of these assessed statistically whether instruments are weak or whether overidentifying restrictions are satisfied. Nevertheless, there are signs that scholars are becoming more sophisticated in terms of argumentation and presentation. We now turn to two noteworthy examples of especially creative uses of IV. The fact that both sets of authors have made their replication data available means that their use of IV can be evaluated in depth."
"29","In this section, we closely examine two illustrative applications. The first uses random assignment as an instrumental variable and illustrates the special considerations that arise with noncompliance and attrition. The second uses a near‐random intervention, change in rainfall, as an instrumental variable and illustrates the special considerations that arise when applying IV to nonexperimental data."
"30","Those who study the effects of media exposure outside the laboratory confront the problem of selective exposure: people decide whether to watch a TV program, and there may be important unmeasured differences between viewers and nonviewers. In an innovative attempt to address the selection problem, Albertson and Lawrence (2009) analyzed an experiment in which survey respondents were randomly encouraged to view a Fox News debate on affirmative action on the eve of the 1996 presidential election. Shortly after the election, these respondents were reinterviewed. The postelection questionnaire asked respondents whether they viewed the Fox News debate and whether they supported Proposition 209, which dealt with affirmative action. The authors report that 45.2% of the 259 people who were reinterviewed in the treatment group watched the half‐hour program, as compared to 4.4% of the 248 respondents who were reinterviewed in the control group. The F‐statistic implied by this first‐stage regression is 142.2, which allays any concerns about weak instruments.            "
"31","Albertson and Lawrence appropriately model the relationship between media exposure and support for Proposition 209 in a manner that does not presuppose that exposure is exogenous. Their two‐equation system is                "
"32","Several features of this study are noteworthy from the standpoint of statistical inference. First, the estimand is the local average treatment effect of viewing the program among Compliers. Here Compliers are those who potentially watch the program only if assigned to receive an interviewer’s encouragement, which included a follow‐up letter containing $2 and a reminder to watch in the form of a refrigerator magnet. It seems reasonable to suppose that these blandishments only increased respondents’ propensity to view the debate, which implies that we can safely assume monotonicity (i.e., no Defiers). It follows that Compliers constitute 45.2%− 4.4%= 40.8% of this sample.            "
"33","Second, the ignorability restriction stipulates that the treatment and control groups are identical except for the effects of the program. In defense of this assumption, one may argue that random assignment created groups that, in expectation, have identical potential outcomes. In addition, it seems reasonable to suppose that the follow‐up letter and accompanying payment had no direct effect on support for Proposition 209. On the other hand, the independence assumption is potentially threatened by attrition from the treatment and control groups. We do not know whether rates of attrition are similar in the two experimental groups or, more generally, whether the causes of attrition are similar. If attrition operates differently in the two groups and if attrition is related to support for Proposition 209, the IV estimates may be biased."
"34","To investigate whether attrition presents a problem for their research design, we use Albertson and Lawrence’s replication data to conduct a randomization check. Their data set only contains information for those who completed both the pretest and the posttest, and the question is whether attrition introduced noticeable imbalance among pretreatment covariates. A regression of treatment assignment on the demographic variables used in their study does not yield any significant predictors of treatment assignment. (The demographic variables in our regression include Party Identification, Interest in Politics, Watch National News, Read Newspapers, Education, Income, Gender, White, and dummy variables for missing values of control variables.) The nonsignificant F‐statistic, F(16,490) = 1.24, p = .23, is consistent with the null hypothesis that attrition is unrelated to pretreatment observables."
"35","A third concern involves the measurement of compliance. Respondents self‐report whether they viewed the Fox News debate, and the difference between the treatment and control group viewing rates forms the denominator of the IV estimator. A potential concern is that those in the treatment group may overreport whether they viewed the program in order to appear to comply with interviewers’ encouragement. This form of measurement error will cause researchers to overstate the proportion of Compliers and therefore to underestimate the local average treatment effect. As the authors note, researchers using this encouragement design in the future may wish to insert some specific recall measures to gauge the reliability of these self‐reports."
"36"," Miguel, Satyanath, and Sergenti (2004) present a natural experiment that has attracted a great deal of attention in political science due to its clever identification strategy. The authors use variation in rainfall (percentage change in rainfall from the previous year) to instrument for economic growth in order to estimate the impact of economic conditions on civil conflict. This approach attempts to overcome the problems of correlation between economic growth and unobserved causes of conflict, which has plagued other observational studies.            "
"37","The authors focus on the incidence of civil war in country i in year t using the PRIO/Uppsala database that covers 41 countries in 19 years. Current and lagged rainfall growth are used to instrument for per capita economic growth and lagged per capita economic growth controlling for other country characteristics such as religious fractionalization, mountainous terrain, and population. Country fixed effects and country‐specific time trends are also included in most specifications. Miguel, Satyanath, and Sergenti find a significant positive relationship between rainfall and GDP growth but acknowledge that change in rainfall falls short of passing the weak instruments test proposed by Stock and Watson (2007, 735) in all of the specifications they present.            "
"38","The second‐stage equation estimates the impact of GDP growth and lagged income growth on the incidence of violence. Their IV/2SLS estimates suggest that current and lagged economic growth significantly reduce the likelihood of civil conflict. This basic pattern of results holds up when the data are analyzed using maximum likelihood, suggesting that the weak instruments problem is fairly minor."
"39","It is instructive to review the assumptions on which this claim rests. First, consider the estimand. Unless one is prepared to assume that effects of a one‐unit change in economic growth are the same regardless of how economic growth comes about, the instrumental variables estimator may be said to gauge the local average treatment effect of rainfall‐induced growth. In his critique of Miguel, Satyanath, and Sergenti, Dunning (2008) argues that growth in different economic sectors may have different effects on conflict and that rainfall helps illuminate the growth‐induced effects of the agricultural sector. Relaxing the assumption of homogeneous treatment effects forces more cautious extrapolations from the results. The results may tell us not about the effects of economic growth but of a particular type of economic growth.            "
"40","A second assumption is that rainfall is a near‐random source of variation in economic growth. In a natural experiment, “it is assumed that some variable or event satisfies the criterion of ‘randomness,’ the event or variable is orthogonal to the unobservable and unmalleable factors that could affect the outcomes under study” (Rosenzweig and Wolpin 2000, 827). In this case, the exogeneity of rainfall is uncertain. If variation in rainfall growth were truly random, it should be unpredictable. One can examine whether rainfall’s associations with other observable variables are consistent with the hypothesis of random assignment. Using the replication dataset that Miguel, Satyanath, and Sergenti provide with their article, we find that factors such as population, mountainous terrain, and lagged GDP significantly predict rainfall growth or lagged rainfall growth, although these relationships are not particularly strong and the predictors as a group tend to fall short of joint significance.13 Suppose for the sake of argument that these covariates were found to be systematically related to rainfall growth. Rainfall could still be assumed random conditional on the covariates in the model. However, the reason using rainfall as an instrument is intuitively appealing is that we think of rainfall as patternless. If rainfall growth is systematically related to other variables, we have to assume that our regression model includes just the right covariates in order to isolate the random component of rainfall.            "
"41","A further estimation concern is that rainfall in one country may have consequences for the economic growth in another country, creating potential SUTVA violations. For example, drought in one country could make another country’s products more scarce and therefore more valuable. These possible SUTVA violations can produce biased estimates, which, importantly, could be biased in either direction.14"
"42","In sum, these two applications illustrate the kinds of issues that frequently arise in the context of experimental and nonexperimental analysis. When reading experiments that involve noncompliance, one must consider whether the random assignment might influence the outcome for reasons other than the treatment itself. When evaluating experiments more generally, one must be alert to problems such as attrition, which threaten to undermine the comparability of the treatment and control groups. When reading nonexperimental applications, special critical attention must be paid to the assumption that the instrument is unrelated to the disturbance term. Even when the IV is deemed exogenous, the reader should reflect on whether the instrumental variable may transmit its influence on the outcome through causal pathways not specified by the model. Instrumental variables estimation embodies a series of arguments, and the reader must be prepared to critically evaluate these arguments."
"43","Having reviewed the assumptions underlying instrumental variables regression, both in general and with regard to specific applications, we conclude with a checklist (summarized in Table 3) for readers to consider as they evaluate argumentation and evidence.         "
"44","                        "
"45","What is the estimand? A basic conceptual question is whether treatment effects are homogenous. Instrumental variables regression identifies the local average treatment effect, that is, the average effect among Compliers. If homogenous treatment effects are assumed, then the LATE is the same as the average treatment effect for the sample as a whole. When drawing inferences from IV results, the reader should consider the question of whether results for the Compliers in this particular study are generalizable. For example, do rainfall‐induced shocks to economic growth have the same effect on ethnic violence as technology‐induced growth? The issue of heterogeneous treatment effects is best addressed through replication. Do different instruments generate similar results? Extrapolation becomes increasingly plausible when estimated effects are found to be similar across different groups of Compliers. Replication may be more than one can reasonably expect from a single study, but, where possible, researchers should guide readers’ intuitions about heterogeneous effects by describing how other IV approaches have played out in the literature."
"46","Is the instrumental variable independent of the potential outcomes? When evaluating the independence assumption, the reader should take note of whether it is justified empirically, procedurally, or theoretically. Empirical justifications that take the form of a statistical test should be read with caution; auxiliary regressions do not provide a direct test of this assumption. One should be especially skeptical when Zi is proposed as an instrument based on preliminary regressions showing that Zi has no influence on Yi controlling for Xi. When authors justify the exclusion restriction based on randomization or a near‐random procedure, they should provide some evidence that, consistent with the hypothesis of random assignment, the instrumental variable is weakly predicted by other covariates. If attrition occurs, the researcher should assess whether the loss of treatment and control observations undermines the comparability of these groups. When instrumental variables are proposed on theoretical grounds, readers should reflect on whether the instrument bears a systematic relationship to the disturbance term. For example, McCleary and Barro (2006) use distance from the equator as an instrument by which to identify the effect of per capita GDP on religiosity. Might latitude be correlated with other unmeasured causes of religiosity?                  "
"47","Suppose an instrumental variable is deemed exogenous because it is random or near random. Are the exclusion restrictions valid? This assumption implies that the instrument can have no effect on the outcome except through the treatment. In the case of the Fox News experiment, could it be that opinion change is induced when a person is invited to watch the TV special, regardless of whether he or she in fact watches?"
"48","Are the instruments weak?“Weak instruments” are instrumental variables whose incremental contribution to R‐squared (over and above the contribution of other covariates) in the first‐stage equation is so low that the risk of bias is severe. Although the precise criteria by which to evaluate the weakness of an instrument are subject to debate, the usual rule of thumb is that a single instrumental variable should have an F‐statistic of at least 10 in order to avoid appreciable weak instruments bias. In the case of a single instrumental variable, this criterion means that the first‐stage t‐ratio must be greater than 3.16. When instruments fall short of this threshold, researchers are encouraged to check the robustness of their results using other estimators. See Stock and Watson (2007).                  "
"49","Does the instrumental variable have a monotonic effect on the treatment? The assumption of monotonicity states that there are no units that receive the treatment if and only if assigned to the control group, ruling out the existence of Defiers. This assumption is satisfied by design in certain experiments where the treatment is only available to the treatment group. However, in other experimental and observational research designs, this assumption is more uncertain. For example, in the Miguel, Satyanath, and Sergenti (2004) study, increased rainfall may not necessarily lead to higher economic growth; more rain could actually impede growth in very wet regions. If so, the assumption of monotonicity would be violated, leading to potentially biased estimates of the local average treatment effect.                  "
"50","Are the observations subject to spillover effects? Violations of the Stable Unit Treatment Value Assumption, or SUTVA, occur when outcomes for one unit depend on whether other units receive the treatment. SUTVA violations occur when one observation is affected by another observation’s Zi or Xi. SUTVA violations may lead to biased estimates. The sign and magnitude of the bias depend on the way in which treatment effects spill over across observations.                  "
"51","These six checklist items, while important, do not exhaust the list of concerns, and one could easily expand the checklist to include complications arising from limited dependent variables (Maddala 1985) or clustered assignment to treatment (Wooldridge 2003). But even consulting our abbreviated list of evaluative criteria, the reader in political science currently confronts a basic challenge: most publications that use instrumental variables regression fail to provide the arguments or evidence that readers need in order to evaluate the statistical claims. If authors could be encouraged to consider the abbreviated checklist presented above, the quality of exposition—and, one hopes, estimation—might improve substantially.         "
"52","The use of instrumental variables regression is likely to grow dramatically in years to come, and with good reason. IV is a valuable method for addressing problems of selection bias and unobserved heterogeneity. By providing a checklist for readers to consider as they critically evaluate applications, we in no way wish to imply that IV is inferior to other estimation approaches. On the contrary, instrumental variables regression is extraordinarily useful both as an estimation approach and as a framework for research design. The reason to read instrumental variables applications with care is that this type of identification‐oriented research deserves special attention."
