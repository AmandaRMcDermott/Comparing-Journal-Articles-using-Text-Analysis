"","x"
"1","The goal of a single‐shot causal inference approach is to estimate the effect of a single action on an outcome at a single point in time.1 With the example of campaigns, we might be interested in the effect of a Democratic candidate running a negative campaign or a positive one on his or her share of the two‐party vote. There are many situations in political science, including campaigns, where actions evolve over time and react to the current state of affairs. In this case, a campaign can “go negative” at multiple points over the course of the campaign. Perhaps a candidate attacks early, before her opponent has a footing, or perhaps she runs negative ads late, responding to smear tactics. These two situations, as far apart as they are, would both register as “going negative” in a single‐shot model since they ignore time and implicitly assume that all actions occur at once. This is an acceptable framework for many problems because actions really do occur once. When actions unfold over time, however, the incorporation of time and its implications become necessary.         "
"2","Dynamic causal inference, in contrast, allows the actions to vary over time. In this framework, we investigate the effect of an action sequence on the outcome of interest. In this framework, we have sequences such as , where a candidate stays positive in the first part of the campaign and then goes negative later. We might ask how this differs from initiating negativity earlier in the race: . This framework has two primary advantages over single‐shot methods in dynamic situations. First, the comparison of action sequences naturally handles a richer set of causal questions, which include both the presence and timing of actions. As Pierson (2000) points out, when an action occurs is often as important as if it occurs at all. Second, and more important, this framework clarifies and resolves certain dilemmas posed by single‐shot methods.            "
"3","In order to separate a causal effect from a mere association, we must be confident that the observed correlations are not due to some other variable. In political science, we call this assumption no omitted variables, and it is made, implicitly or explicitly, in almost all empirical research in political science. It states that we have measured and appropriately controlled for any variable that could potentially cause bias in our causal estimates. We call this bias confounding and the variables that cause it confounders. For instance, if we were to run a regression of the Democratic vote share in Senate elections on a measure of Democratic negativity, we would also want to control for variables that might cause a correlation between negativity and vote shares. In this case, the incumbency status of the Democrat would be a confounder because incumbents are less likely to go negative and also more likely to win an election. Figure 1a shows a graphical representation of the causal relationship between confounders, actions, and the outcome. We would want to include confounders like these in our analysis, be it using a linear model, a generalized linear model, or a matching estimator.            "
"4","                Directed Acyclic Graphs Showing Single‐Shot and Dynamic Causal Inference Frameworks"
"5","Note: Each arrow represents a causal relationship.                        "
"6","How do we choose which of our variables are confounders? A common definition is this: a confounder is any variable that (a) is correlated with the outcome, (b) causes, or shares a common cause with, the action, and (c) is not affected by the action. Thus, in any regression or matching estimation of a causal effect, we would want to control for or match on any preaction variables in the sense that they are causally prior to the action of interest. In negative advertising, these variables would either affect or be correlated with the decision to go negative, but never be affected by the decision to go negative. We avoid controlling for postaction variables because doing so can induce bias in estimating the causal effect. This is known in the causal inference literature as posttreatment bias (Ho et al. 2006).            "
"7","There are two related sources of posttreatment bias. First, conditioning on postaction variables can “block” part of the action’s overall effect. For instance, suppose a researcher controlled for polling results from the day of the election when attempting to estimate the effect of incumbency. This will understate the effect of incumbency since most of the effect flows through the standing of candidates late in the race. Second, conditioning on a postaction variable can induce selection bias even when no bias exists absent the conditioning. For instance, suppose at the start of a campaign we randomly assigned high and low budgets to different Democratic candidates for Senate. If we condition on the polls sometime during the campaign, we can seriously bias our estimates of the effect of campaign budgets. Those leading Democrats who had high budgets are likely to differ strongly from leaders with small budgets. For example, if higher budgets help a candidate, then those low‐budget leaders are actually much stronger candidates than the high‐budget leaders, since they were able to lead in the polls without the additional funding. Thus, comparing high‐ and low‐budget leaders would give a misleading estimate of the causal effect of campaign finance, even though it was randomly assigned."
"8","When we force an inherently dynamic situation into a single‐shot framework, the above discussion of confounders and posttreatment bias becomes muddled. Take negative advertising, for example: how should we treat polling data from over the course of the campaign? It is surely preaction in the sense that polling affects the decision to go negative, and it is correlated with the outcome, the election results. At the same time, polling is postaction since it is affected by negativity earlier in the race. Polling is an example of a time‐varying confounder, which is a confounder that both affects future treatment and is affected by past treatment.            "
"9","The single‐shot advice to include preaction confounders and exclude postaction variables appears to recommend both courses of action in this situation, leaving a researcher without a palatable solution. In fact, both of these approaches will bias causal estimates, albeit in different ways. In the above hypothetical regression of Democratic vote share on Democratic negativity, we could omit polling data from the regression on the grounds that it is posttreatment, yet this would lead to omitted variable bias. Note in Figure 1b that polling in period 2 affects negativity in period 2, perhaps because candidates who are trailing are more likely to go negative. If we exclude polling from our regression (or matching analysis), it might seem that negativity is a bad strategy even though this is wholly due to candidates going negative when they are in trouble. Thus, we must include polling in our analyses. Doing so, however, also biases our estimates, since the polls in period 2 are partially a result of negativity in period 1. For instance, a candidate who stays positive early and whose polls decline might have done better if she had gone negative early. If we control for polling in period 2, we block that part of the effect in our analysis and introduce posttreatment bias into our estimates. Either approach, ignoring or including polling, will lead to some form of bias. These problems with time‐varying confounders cannot be solved by single‐shot methods even if we assume, as I do below, no omitted variables in each time period. They are fundamental to situations where actions unfold over time. The assumptions and methods presented here represent a solution to this dilemma under the weakest possible assumptions on the causal structure of the data.2"
"10","A key characteristic of single‐shot methods, such as regression and matching, is that they provide no way of removing omitted variable bias due to time‐varying confounders without inducing posttreatment bias. These estimators divide up the data into comparable subsets and estimate causal effects within these subsets. The overall effect is simply a combination of these stratum‐specific effects. This broad approach is called stratification, and it breaks down in dynamic settings as described above: stratifying removes omitted variable bias but induces posttreatment bias for time‐varying confounders.            "
"11","An alternative to stratification estimators are inverse probability of treatment weighting (iptw) estimators, which reweight the data to alleviate the omitted variable bias.3 To see how these weights work, note that, in negative campaigning, certain strategies are used more often than others: candidates tend to go negative when they are trailing and stay positive when they are leading. In Figure 1b, we represent this in the arrows from polling to negativity. This, of course, causes confounding. To remove this time‐varying confounding, we can give less weight to common strategies so that, in the reweighted data, all strategies have the same weight: as many trailers go negative as stay positive. Thus, in the reweighted data, the action sequences are balanced across time‐varying confounders, and there is no omitted variable bias. Crucially, Robins (1999) shows that iptw estimators do not introduce posttreatment bias because they avoid stratifying the outcome by time‐varying confounders.            "
"12","Alternatives to iptw estimators for dynamic causal inference include structural nested models, structural equation modeling, synthetic control methods, and principal stratification, but each of these methods has a disadvantage when compared to the weighting approach. The iptw estimator described below is far more general than the latter three approaches, while being less model dependent than structural nested models. Robins (2000) points out that while these structural nested models can estimate more flexible causal quantities of interest than iptw, they also require models for each time‐varying confounder in the data.4 While this weighting approach is less flexible than structural nested models, it is much more flexible than other related methods. Structural equation modeling requires a constant effects assumption in order to estimate dynamic causal effects.5 Synthetic control methods for comparative case studies, for example, focus on a single intervention for each unit and thus limit the number of possible estimable quantities (Abadie, Diamond, and Hainmueller 2010). Principal stratification (Frangakis and Rubin 2002) can recover causal‐effect estimates when a posttreatment variable defines the available sample, such as censoring by death. Frangakis and Rubin (2002) note, however, that this approach is more appropriate for nonmanipulable posttreatment variables. When the relevant posttreatment variable is manipulable and truly part of the treatment, as is the case here, principal stratification needlessly restricts the quantities of interest under investigation.            "
"13","To show how iptw can estimate causal effects in a dynamic setting, it is useful to extend the single‐shot causal‐inference framework to explicitly include time.6 Suppose i indexes the campaign, with i= 1, …, N. Let t denote the week of the campaign, taking possible values 1, …, T, where T is the final week before Election Day. We refer to t= 1 as the “baseline” time period; it is the time period before the campaign begins, assumed to be the first week after the primary. In each period, campaigns can either go negative, denoted Ait= 1, or remain positive, Ait= 0.         "
"14","Campaigns face a rapidly evolving environment. To account for this, let Xit represent the characteristics of the campaign in week t that affect the Democrat’s decision to go negative in week t. This would include recent polling or Republican negativity in the previous weeks. This definition assumes that the decision to go negative occurs “after” the variables in Xit, so that they are preaction for week t.7 Instead of containing all variables occurring at time t, the set of covariates describes the information setting for the action decision at time t. Simply put, Xit is the most recent set of variables that could possibly affect Ait.8 The baseline covariates, Xi1, include background information that remains static over the course of the study. For campaigns, these could be perceived competitiveness of the election, number of ads shown in the primary, incumbency status, or challenger quality. The choice of relevant covariates of course depends on the outcome, Y, which in this case is the Democratic percent of the two‐party vote.         "
"15","Dynamic settings require references to the history of a variable. A history is the set of all instances of that variable up to some point in time. In this example, it may be the sequence of campaign tone or poll results in each week. Underlines indicate the history of a variable, so that  would be the negativity up through time t: . The covariate history, , is defined similarly. One possible realization of  is , where each at can take the values 0 or 1. Furthermore, let  be the sequence of negativity over the course of the entire campaign. Let  be a representative campaign tone history and  as the set of all possible values of ; that is, all the possible ways a candidate could go negative over the course of the campaign. Let , , and  be defined similarly for the covariate history.         "
"16","Each possible negativity sequence, , has an associated potential electoral outcome. Let  be the Democratic percent of the two‐party vote if we forced candidate i to implement the campaign . Note that there are 2T possible sequences . As before, any individual candidate can experience at most one of these potential outcomes, which is the one associated with her observed action history. The rest of the potential outcomes will be counterfactual; they are what would have happened if the unit had followed a different sequence. Suppose campaigns only lasted two weeks. In this world, Yi(0, 1) would be the Democratic vote share if candidate i were to remain positive in week one and go negative in week two. To complete the definition of the potential outcomes, we connect them to the observed outcomes, Yi. When some unit is observed to have followed action sequence , then we observe the potential outcome for that sequence, or  when .9"
"17","We say that  contains a time‐varying confounder if it (1) affects the election outcome, (2) affects future negativity, and (3) is affected by past negativity. In estimating the effect of Democrats going negative, the advertising tone of the Republican would be a time‐dependent confounder. Democrats are more likely to go negative if their opponent has gone negative, and their opponent’s actions are likely related to the outcome. Note that Xt could include past values of Y, in which case the lagged dependent variable would be a time‐dependent confounder.         "
"18","The goal of dynamic causal inference is to estimate the means of the potential outcomes under various action sequences. These are population‐based quantities of interest: what would happen if every Democrat remained positive? In the sample, however, the candidates who actually went negative always might be different from those who did not. Thus, the sample of units who followed the strategy would be an unrepresentative sample of the potential outcome under that strategy. In order to rid our analysis of the above selection problems, we must be able to identify and measure all possible confounders.            "
"19","For any action sequences , covariate history , and time t, if, then .               "
"20","Here, B⊥⊥C|D means that B is independent of C, conditional on D, and notation for units has been suppressed. The assumption of sequential ignorability extends the conditional ignorability assumption to time‐varying actions. It states that action decision at time t is independent of the potential outcomes, conditional on the covariate and action histories up to that point. That is, conditional on the past, those who go negative are similar to those who stay positive. Figure 2a shows a causal directed acyclic graph (dag) in which sequential ignorability holds, while Figure 2b shows a situation where the assumption fails to hold due to an omitted variable U. If decisions are made by a coin flip, then clearly this assumption will hold. If units act based on the covariate history, however, then it will fail to hold unless the analyst can observe all of those covariates. For instance, the assumption would be violated if campaigns made the decision to go negative based on polling data, but the analyst did not have access to that polling data. The goal for researchers, then, is to collect all the covariates that might influence the decision to go negative in some week. While this is a daunting task in an observational study, it is no harder than satisfying conditional ignorability in the single‐shot case, and the sixth section shows how to relax the assumption in a sensitivity analysis.               "
"21","                Directed Acyclic Graphs Representing Different Assumptions about Sequential Ignorability, Where U Is an Unobserved Variable"
"22","Finally, in order to compare the various action sequences, each must have some positive probability of occurring. It is nonsensical to estimate the effect of a sequence that could never occur."
"23","For any sequences and , and time t, if , then .               "
"24","This assumption outlines the types of strategies we can study. Positivity can break down when some sequences fail to occur in the actual data even though they are theoretically possible. In negative advertising, for instance, candidates with extremely safe seats never go negative, even though nothing is stopping them from doing so. Unfortunately, we will be unable to estimate the effect of going negative for these candidates. These empirical violations of positivity are closely related to the assumption of common support often invoked in the matching literature. The sixth section discusses these practical problems with positivity and how to restrict the analysis to the common support.               "
"25","In the single‐shot approach, estimating a causal effect only involves two quantities, one corresponding to each action: E [Yi(1)] and E [Yi(0)]. In dynamic causal inference, there is one potential outcome for each action sequence. A key consequence is that even with a small number of time periods, there will be an overwhelming number of possible action sequences. With two potential outcomes, we can nonparametrically estimate the mean outcome in the treated and control groups by taking sample means. With just 10 periods, however, there would be 1,024 possible action sequences, making it unlikely that there will be even one unit following any particular sequence. Thus, the nonparametric approach of single‐shot methods will be useless here.            "
"26","To overcome this curse of dimensionality, we can use a parametric model to relate the action sequences to the potential outcomes. That is, we will suppose that “similar” action sequences should have “similar” potential outcomes. Imposing this structure on the problem reduces the dimensionality of the problem at the expense of possible model misspecification. Robins, Hernán, and Brumback (2000) introduced a parsimonious class of semiparametric models for this problem called marginal structural models (msm). In this class of models, we assume a parametric form for the mean of the potential outcome               "
"27","The function g defines our assumptions about which action sequences should have similar potential outcomes. We may have, for instance,               "
"28","Supposing that Equation (2) was the correct model for the potential outcomes, we want to estimate its causal parameters. One approach would be to estimate               "
"29","One might think that the two traditional estimation procedures would at least provide bounds on the true causal effect, with β1 falling between γ1 and δ1. When the omitted variable bias and the posttreatment bias have the same sign, however, this bounding will fail to hold. This can occur, for instance, when strategic actors attempt to compensate poor performance with beneficial actions. Suppose that there is a strong, positive effect of negative advertising and that trailing campaigns use it to bolster their positions. The omission of polling in a model would lead to an understatement of the negativity effect, since candidates tend to be trailing when they go negative. Positive campaigns would appear stronger than negative campaigns, even though negativity boosts performance. The inclusion of polling in a model would also lead to an understatement of the effect, since it washes away the increase in polls from past negativity. Thus, the true effect of negativity would be higher than either of the traditional methods would predict. Robins (1997) gives a numerical example that has these features.            "
"30","As shown above, the usual single‐shot approaches break down when the actions can vary over time. Fortunately, inverse probability of treatment weighting (iptw) can recover unbiased estimates of causal effects, even in dynamic settings. To see how iptw works, note that, due to the omitted variables, the distribution of the potential outcomes differs from the distribution of the observed outcomes (). Regression and matching attempt to avoid this problem by finding subsets of the data where those distributions are the same and making comparisons within these subsets. This conditioning removes the omitted variable bias, but it can induce posttreatment bias. Methods that rely on weighting, such as iptw, avoid these by never explicitly conditioning on the confounders in the outcome model.10"
"31","Robins, Hernán, and Brumback (2000) show that under the above assumptions, a reweighted version of the observed outcomes will have the same distribution as the potential outcomes. In the campaigns context, the reweighted outcomes for always‐positive campaigns will look like the outcomes if we forced all Democrats to remain positive. The weights in a given week are defined as            "
"32","In words, the denominator of Wit is the probability of observing the action that unit i actually took in that week, conditional on the past. To generate an overall weight for each race, we simply take the product of the weekly weights over time:            "
"33","A simple example helps to explain the construction of the weights. Suppose that there were only two weeks in a campaign, with a poll update in between the weeks. A candidate decides to go negative or stay positive in the first week, sees the outcome of the poll, decides to go negative in the second week, and then observes the election results. A candidate who stays positive in week one, trails in the polls, and then goes negative in week two would have the following weight:             "
"34","The weights in iptw remove any confounding by ensuring that the distribution of action sequences is the same in each level of the confounder. In the reweighted data, the action decisions are unrelated to the measured confounders, and, thus, they cannot account for any remaining differences between action sequences. It is instructive to see how this works in the single‐shot case. Let  be the reweighted probability of observing a negative candidate, conditional on trailing in the polls. We can find this probability by multiplying the original probability by the weight for this type of observation and divide by a normalizing constant:               "
"35","Intuitively, this weighting breaks the links between the action decision and the factors that affect the action decision. Candidates who are pursuing common strategies, where  is closer to 1, will have lower weights than those candidates with less common strategies. This weighting corrects the deviations from the ideal experiment we would have liked to run. The sequential ignorability assumption is crucial here because we cannot correct for deviations we do not observe. Since there is no connection between the action sequence and the confounders in the reweighted data, we can simply run whatever model we wanted to run in the first place, without conditioning on time‐varying confounders. And because we never condition on these variables, we never introduce posttreatment bias as with single‐shot approaches.            "
"36","Of course, without randomization, the probability of going negative will be unknown, leaving Equation (5) to be estimated. To do so, we must model the decision to go negative in each week, conditional on the past. Since the decision is dichotomous, a common approach is to estimate the probability of going negative with a logit model:               "
"37","An estimate of the weights requires an estimate of the parameter vector α from this model. We can obtain these estimates, , from a pooled logistic regression, treating each campaign‐week as a separate unit. These estimates form the basis for the estimated weights,               "
"38","Each observation i is then weighted by  in a weighted generalized linear model for the outcome, with form  from Equation (2).12Robins (2000) shows this estimation procedure is consistent for the causal parameters, β, under sequential ignorability, positivity, and the correct model for the weights. The most straightforward way to estimate standard errors and confidence intervals is to bootstrap the entire estimation procedure, including the weights (Robins, Hernán, and Brumback 2000). For negative campaigning, this means resampling the set of campaigns (not the set of campaign‐weeks), reestimating the weights, and running the weighted outcome model on the resampled data.            "
"39","If campaigns have vastly different likelihoods of going negative, then the estimated weights from Equation (11) can have extreme variability, which results in low efficiency. We can use a slightly different version of the weights, called the stabilized weights, to decrease this variability and increase efficiency. The stabilized weights take advantage of an interesting fact: the numerator of the weights does not change the consistency of the estimation procedure.13 While it was natural to use the value 1 as the numerator, we can replace it with other functions of the action history that increase efficiency. The usual choice used in the literature (Robins, Hernán, and Brumback 2000) is               "
"40","Of course, the numerator of SWi is unknown, leaving us with the task of estimating δ. All this requires is an additional logit model for the numerator to estimate the probability of going negative without conditioning on the time‐varying covariates. If the outcome model will include interactions with baseline covariates, then both the numerator and the denominator should include those variables. To construct these weights, one simply needs to obtain predicted probabilities from each model for every unit‐period. Then, for each unit, take the product of those probabilities across time periods and divide to obtain the estimates .            "
"41","Pundits and theorists often bemoan the growth in negative campaign advertising in recent decades. Less often do they discuss its effectiveness. An implicit assumption in the air of political discourse is “Of course it works, politicians do it.” The prospect of dirtying the waters with such cheap and tawdry tactics is bad enough, and being useless would only add insult to injury. A contingent of political scientists has investigated just how useful negativity is for candidates, without reaching a consensus. In a comprehensive review, Lau, Sigelman, and Rovner describe the state of the literature: “All told, the research literature does not bear out the idea that negative campaigning is an effective means of winning votes” (2007, 1176)."
"42","The usual approach to estimating the effectiveness of negative advertising (see Lau and Pomper [2002, 2004] for examples) is to regress election outcomes on a summary measure of the degree of negativity in a campaign along with controls for various static attributes of the race. A crucial problem for these investigations is that campaign tone is a dynamic process, changing from week to week. Furthermore, there are strong time‐varying confounders. For instance, poll numbers affect the decision to go negative, but going negative also affects poll numbers. Thus, polling is both pre‐ and postaction: a classic time‐varying confounder. As shown above, ignoring the polls and conditioning on the polls will both result in biased estimates. We can estimate the effect of time‐varying actions, though, using marginal structural models and inverse probability of treatment weighting.         "
"43","The goal of this application is to estimate the effect of going negative for Democratic candidates in state wide elections. I use data on campaigns for Senate and gubernatorial seats in the cycles of 2000, 2002, 2004, and 2006. For each campaign, I code the advertising tone using data from the University of Wisconsin Advertising Project (Goldstein and Rivlin 2007). To ensure consistency across years, I use a simple measure of negative or contrast ads: does the ad mention the opposing candidate?14 I use this coding to construct a measure of whether a candidate has “gone negative” in a given week of the campaign based on what percentage of ads is negative.15 The WiscAds data also provide a proxy for weekly campaign spending: the total number of ads aired in a week. In addition to advertising data, I also collected weekly polling data from various sources,16 along with baseline covariates, such as predicted competitiveness of the race (as measured by the Congressional Quarterly score), incumbency status, number of ads run by each candidate in their primaries, the length in weeks of the campaign, measures of challenger quality and incumbent weakness, and the number of congressional districts in the state. Much of these data come from Lau and Pomper (2004) with additional data collection. In this example, baseline is the day after the final primary.         "
"44","In order to estimate the causal parameters from an msm, we must construct the weights from the previous section. In order to satisfy the assumption of sequential ignorability, we must gather as many covariates as possible that might influence the decision to go negative in a given week and are correlated with the election outcome. This is, of course, a difficult task, but we can often leverage substantive knowledge to guide our models. The dynamic reasons for a candidate to go negative might be numerous, but it is likely that the state of the race, as summarized by the polls in a given week, is at worst a proxy for these factors and at best the most important factor. Indeed, we might think that the candidates doing the worst in the polls are the most likely to go negative. This is why it is crucial to include both precampaign measures of competitiveness and dynamic measures of campaign performance in the form of polling data. Without these data, it would be impossible to differentiate between the effect of negative advertising on the one hand and negative advertising simply indicating weak candidates on the other. Previous literature on the effectiveness of negative advertising has not had access to the kind of polling data available in more recent elections, hampering its ability to address these dynamic‐selection issues.            "
"45","To address these concerns, I include the following time‐varying covariates in the weighting model: the Democratic share of the polls in the last week, the share of undecided voters in the last week, past negativity of both Democrats and Republicans, the amount of advertising by both candidates in the last week, and the week of the campaign. It may be the case that these variables do not encompass or proxy all of the factors that influence candidates, which is why it is crucial to assess any inferences using sensitivity analysis, as I do in the next section. With these covariates, I ran two separate pooled‐logistic models for the decision to go negative: a separate numerator and denominator model.17"
"46","These models largely fit with the intuition and theory of campaigns, with high advertising and already negative races being more likely to be negative. Figure 3 shows that there is a strong relationship between polling and the decision to go negative: nonincumbent Democrats in safe seats rarely go negative, but those who are trailing often do. To construct the weights, I combine predicted probabilities from these models according to Equation (12).18 Due to empirical violations of positivity, I restricted the analysis to common support on baseline covariates, which mostly involved removing extremely uncompetitive race.19"
"47","                The Marginal Relationship between Lagged Polling Numbers and Going Negative for Democratic Nonincumbent Candidates"
"48","Note: All other variables from the model are held at their mean, or median, depending on the type of variable. The shaded region is a 95% confidence band. Intuitively, trailing Democrats are more likely to go negative than leading Democrats.                        "
"49","The effect of negative advertising is unlikely to be constant across time. Ads closer to Election Day should have a stronger impact than those earlier in the campaign, and marginal structural models allow us to estimate these time‐varying effects. I break up the effect into an early campaign effect (the primary through September) and a late campaign effect (October and November). Vote shares are continuous, so a linear msm is appropriate for the potential outcomes:               "
"50","It is instructive to compare estimates from this model with two competing approaches. First, the naïve estimator simply ignores all time‐varying covariates and fits Equation (13) to the observed data without weights. Second, the control estimator attempts to control for the covariates by including them as additional regressors in Equation (13).20 These represent the two single‐shot methods used by applied researchers: the naïve estimator to guard against posttreatment bias and the control estimator to guard against omitted variable bias.            "
"51","Table 1 shows the estimated effects of late campaign negativity from all three models broken out by incumbent status.21 The msm finds that Democratic incumbents are hurt by going negative, while nonincumbents are helped. Nonincumbents see a 0.64 percentage point increase in the Democratic percent of the two‐party vote for every additional week of negative advertising in the last five weeks. Incumbents, on the other hand, drop 0.57 percentage points for the same change. As Figure 4 shows, there is no evidence of a direct effect of earlier negativity on the final vote in either group. Note that these results control for polls taken at the beginning of the campaign. It is surprising, then, to see effects that are even this large since these baseline polls are highly predictive of the outcome in Senate and gubernatorial elections.            "
"52","                Inverse Probability of Treatment Weighting Estimates of the Time‐Varying Effects of Negative Campaigning with Bootstrapped 95% Confidence Intervals"
"53","Note: Negative ads are more potent later in the campaign (October and November) than earlier in the campaign, but the direction of the effect is negative for incumbents and positive for nonincumbents.                        "
"54","When we compare the three estimators, we find that using a dynamic causal inference approach leads to substantively different conclusions about negative advertising. For nonincumbents, for instance, the two single‐shot methods recover what the previous literature has found: no significant effect of negativity (Lau and Pomper 2004; Lau, Sigelman, and Rovner 2007). With the msm, however, we find that negativity does have a large, statistically significant, and positive effect. Interestingly, the msm‐estimated effect is well outside of the bounds set by the naïve and control estimators. For these nonincumbents, the iptw estimate is over 18% larger in magnitude than either of the other methods. Thus, “trying it both ways” would be an unsuccessful strategy in this case. For incumbents, we find additional divergence from the literature. Similar to the effects of negativity for incumbents estimated by Lau and Pomper (2004), the naïve estimator finds a large and harmful effect of negativity for incumbents. But this is likely driven by midcampaign confounding, and once I account for this using an msm, I find no significant effect of negativity for incumbents. Overall, a dynamic causal inference approach leads to different conclusions about the effectiveness of negative advertising for U.S. statewide election than the previous literature had found.            "
"55","With single‐shot causal inference methods such as matching, balance checks are crucial diagnostics (Ho et al. 2006). These checks ensure that the treated and control groups are similar on their background covariates. Usually this takes the form of simple comparisons of covariate means in the treated and control group, though more sophisticated techniques exist. Unfortunately, this simple approach is ill‐suited to the dynamic setting since it is unclear what groups to compare. At a given week of the campaign, negative and positive campaigns might differ on a time‐varying confounder, but these differences might be due to past negativity.         "
"56","Under the above assumptions of the iptw estimator, the decision to go negative is unconfounded in the weighted data, conditional on past negativity. We should expect, then, that the observed actions will be independent of time‐varying covariates once we weight by SWi. This independence is, however, conditional on a unit’s action history. For instance, suppose we had two campaigns that had remained positive until week t. Then the decision to go negative in week t+ 1 for these two campaigns should not depend on time‐varying covariates, such as polling, in the weighted data. We can assess balance in the weighted data, then, by checking for associations between the action decision and the time‐varying covariates that affect that decision, conditional on the action history. If, after reweighting the data and conditioning on past negativity, the decision to go negative is still predictive of past polling, then there is likely residual confounding of the relationship between the outcome and negativity.         "
"57","Figure 5 shows how the weights reduce this history‐adjusted imbalance in the campaign‐advertising example. It shows the change in the standardized history‐adjusted imbalance from the unweighted to the weighted data.22 In the unweighted data, for instance, Democrats were much more likely to go negative after an attack by Republicans (R Negt−1). Once we apply the weights, however, the differences move much closer to zero because iptw gives relatively more weight to races that went negative without Republican negativity in the last week.         "
"58","                The Change in History‐Adjusted Balance between the Weighted and Unweighted Data as Measured by Standardized Differences between Those Campaign‐Weeks That Went Negative versus Those That Remained Positive, Conditional on Baseline Covariates"
"59","Note: The differences are, all told, closer to zero in the weighted model. “R Neg” is whether the Republican went negative, “Ads” are the number of ads run by the candidates, “R Neg Total” is the total number of Republican negative weeks in the campaign, and “Polls” is the averaged polling numbers for Democrats.                     "
"60","One stark observation from the diagnostic plot is that confounding exists for incumbents even after weighting for the time‐varying confounders. This makes sense for two reasons. First, data‐quality issues plague incumbents since their safer races attract less polling. Second, incumbents have stronger positivity problems with extremely safe seats rarely going negative. Furthermore, incumbent campaign‐weeks with high total ad volumes almost always feature negativity. These issues prevent the weights from fully eliminating the confounding in the data and should give us pause when interpreting the estimates for incumbents."
"61","Cole and Hernán (2008) propose a series of model checks based on the distribution of the weights, SWi. They note that the confounding of time‐varying covariates is what pushes weights away from 1. A mean weight far below 1 indicates that there are relatively few surprise actions—those that are unlikely given the covariate history. This lack of surprises indicates that the probability of going negative is close to 0 or 1 in some parts of the covariate space, which is a violation of positivity. In some sense, there are very few comparable cases for these units with high weights. In the matching literature, this is called a lack of common support. A good check for these issues in the weight model is to check the distribution of stabilized weights in each period to ensure that (1) the means at each point in time are close to 1, and (2) the minimum and maximum values are reasonably close to 1. The final distributions of the weights by week are in Figure 6. Their means are all very close to 1, and the upper bounds are fairly low, indicating well‐behaved weights.         "
"62","                Stabilized Weights Over the Course of the Campaigns"
"63","Note: The black lines are the weekly means, the gray rectangles are the weekly inter‐quartile ranges, and the thin gray lines denote the range of the weights. Note that campaigns begin at various times so that there are very few campaigns at 30 weeks out, but very many at five weeks out. These weights appear well behaved as their means are close to 1.                     "
"64","Causal estimates from an msm have excellent properties when the assumptions of positivity and sequential ignorability hold. Of these, sequential ignorability is the trickiest, as it requires that, conditional on the covariate and action histories, the action decision is unrelated to the potential outcome. Any residual differences in potential outcomes between treated and control groups we call unmeasured confounding or omitted variable bias. Unless we conduct an experiment and randomize the action, this assumption must be justified through substantive knowledge. Since it is impossible to test this assumption, it is vital to include as much information as possible and to conduct a sensitivity analysis of any estimated results.            "
"65","Robins (1999) proposes a method to investigate the sensitivity of estimates to the presence of unmeasured confounding. Robins quantifies the amount of confounding as               "
"66","The above iptw estimation procedure assumes that α= 0, yet Robins (1999) shows that we can estimate the parameters under any assumption about α. Thus, by setting α to various levels, we can estimate the causal effect under different assumptions about the degree of omitted variable bias. To do so, we have to replace the outcome with a bias‐adjusted outcome,               "
"67","Figure 7 shows how the estimated effect of late‐campaign negativity varies across different assumptions about the omitted variable bias, encoded in the parameter α, which runs along the x‐axis. The magnitude of α describes how much stronger or weaker the negative campaigns are, on average, in terms of their potential outcomes. This figure also charts the change in the confidence intervals under the various assumptions about bias, with those that cross zero shaded lighter.            "
"68","                Sensitivity of the Results to Deviations from the Sequential Ignorability Assumption"
"69","Note: The parameter α indexes assumptions about confounding, where negative values indicate that the observed negative campaigns are inherently weaker than predicted by the observed variables. Positive values assume that those negative campaigns are stronger than predicted.                        "
"70","When negative campaigns are even 0.5 percentage points stronger than positive campaigns on average, our 95% confidence intervals would overlap with zero for nonincumbents. This might occur if campaigns were attacking their opponents for (unmeasured) behavior such as a scandal or an unpopular vote. Note that these imbalances would have to occur within levels of the covariate history and thus exist after conditioning on polls. If the negative campaigns are instead weaker, perhaps because campaigns go negative when they are in trouble, then results only grow stronger for nonincumbents. The results for incumbents show the reverse pattern. The results are fairly sensitive to the degree of confounding. Note, though, that this confounding would have to be above and beyond any information contained in polls and precampaign measures of competitiveness."
"71","It is clear that there is some sensitivity to the sequential ignorability assumption, and we could attempt to gather more data (quantitative and qualitative) to justify which direction this confounding is likely to lean. Notably, we could measure a larger set of dynamic campaign features such as scandals and endorsements. It would also help to draw on additional electoral cycles, such as 2008, when incumbents faced strong challengers to overcome the overlap and ignorability issues."
"72","Political actions do not happen all at once. There are sequences of events that unfold over time. As we have seen, this poses strong problems for extant single‐shot causal inference methods. This article brings to bear a framework that explicitly models the dynamic sequences and builds methods to test their effects. The original application of msms was to epidemiological data. Robins (1997) develops a set of methods called structural nested models with an application to HIV‐treatment studies. In that context, the units are patients and doctors change the treatment over time if the patient status worsens. The analogy to politics is suggestive: campaign managers and candidates as doctors, working to save their patient, the election. Of course, candidates face human opposed to viral opponents, yet this changes only the types of variables needed to satisfy sequential ignorability.         "
"73","The structural nested model of Robins (1997) provides an alternative approach to dynamic causal inference. These techniques center on modeling the effect of going negative at every possible history, which allows effects that interact with time‐varying covariates. The estimation methods resemble backwards induction in game theory. Unfortunately, these structural nested models require models for entire sets of time‐varying covariates and complicated computation to estimate while researchers can easily use off‐the‐shelf software to implement an msm.         "
"74","The focus of this article has been the effect of action sequences, yet in many political science situations, actors follow dynamic strategies—updating their actions based on changing conditions. It is likely that the optimal action is actually a strategy, since being able to respond to the current state of affairs is more effective than following a predefined sequence of actions. Hernán et al. (2006) demonstrates that marginal structural models and inverse probability weighting can estimate the effectiveness of strategies with a simple form such as “go negative when polls drop below x%.” In addition, structural nested models can estimate the effect of arbitrary strategies. As might be expected, precisely estimating these effects requires larger sample sizes than the effects of simple action sequences.         "
"75","A crucial path for future research is model development. In this article, I used a fairly simple model to estimate different effects for early and late in the campaign. This is a crude division of the data, and more fine‐grained modeling might help to smooth effects over time. Indeed, we would expect that the effect of negativity in week 5 should be quite similar to the effect of negativity in week 6. Better msms should be able to handle this type of structure.         "
"76","Dynamic causal inference is a problem for more than just campaigns. Each subfield of political science analyzes actions that occur over time and have multiple decision points: foreign aid, interest rates, budget allocations, state policies, and even democracy. Indeed, many of the assumptions in this article (or variations thereof) are implicit in time‐series cross‐sectional models, where the counterfactual framework is rarely discussed in explicit terms. Thus, there is a great opportunity for future work that identifies areas with dynamic causal inference problems and attempts to clarify or improve existing results."
