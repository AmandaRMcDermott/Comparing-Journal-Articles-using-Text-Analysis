"","x"
"1","Almost from the day Justice O'Connor announced her retirement from the U.S. Supreme Court, pressure mounted on President George W. Bush to nominate a woman. Various news sources reported that elites on the left and right thought the seat should be “reserved” for a female, and the public concurred. Even the first lady ventured an opinion, saying that she “would really like [the President] to name another woman to the Supreme Court.”"
"2","Whether Bush acceded to this pressure with his (unsuccessful) nomination of Harriet Miers is a matter of some debate. But the entire episode raises the question of why the pressure was there in the first place: why did elites and the public alike support appointing a woman to replace O'Connor? One answer centers on “social legitimacy,” or the belief that “democratic institutions in heterogeneous societies ought to reflect the make‐up of society” (Cameron and Cummings 2003, 28). On this account, elected officials should work to ensure the commensurate representation of women on the nation's highest court in part because they now constitute over one‐half of the U.S. population and nearly one‐third of all lawyers in the country.3"
"3","Another set of responses centers less on the sheer presence of female judges and more on “their participation and their perspective” (Sherry 1986); that is, on whether males and females behave differently (individual effects) and whether females influence their male colleagues (panel effects). Falling into this set, as we show in Table 1, are different voice, representational, informational, and organizational accounts of sex‐based judging. Note that while three of the four posit differences in the behavior of male and female judges, their underlying mechanisms and, ultimately, their empirical implications, are distinct.         "
"4","In light of the prominence of these accounts—one or more appears in virtually every study of gendered judging (see, e.g., Baldez, Epstein, and Martin 2006; Brudney, Schiavoni, and Merrit 1999; Clark 2004; Farhang and Wawro 2004; Martin, Reynolds, and Keith 2002; Peresie 2005; Sherry 1986; Sullivan 2002)—they require little elaboration. Briefly, the first, the different voice approach, follows from Gilligan's (1982) seminal work.4 This account stresses divergencies between males and females—primarily that they develop distinct worldviews and see themselves as differentially connected to society. As a result, we would not expect much in the way of panel effects; given their differences, male and female judges are unlikely to influence one another. Individual effects, however, should be quite extensive, emerging across virtually all areas of the law. Indeed, if Gilligan's work has any implications for judging, it is that female judges bring a “feminine perspective” to the bench—one that “encompasses all aspects of society, whether or not they affect men and women differently,” and not only “the political agenda associated with feminism” (Sherry 1986, 160; see also Davis 1992; Steffensmeier and Herbert 1999).         "
"5","For representational accounts, that “political agenda” moves to the fore. The idea here, tracing to Pitkin's (1967) work, is that female judges serve as representatives of their class and work toward its protection in litigation of direct interest—or, as Cook famously put it, “the organized campaign to place more women on the bench rest[ed] on the hope that women judges will seize decision‐making opportunities to liberate other women” (1981, 216; see also, e.g., Allen and Wall 1993; Martin and Pyle 2005; Tobias 1990).5 Consequently, this account too posits individual effects, but they should manifest themselves in a smaller set of cases—only those involving issues “where the policy consequences are likely to have immediate and direct impact on significantly larger numbers of women than men” (Carroll 1984, 308). Common examples of such “women's issues” in the law include abortion, affirmative action, sex discrimination in employment, and sexual harassment.6"
"6","To the extent that informational accounts suggest the emergence of individual effects in a few legal areas, they converge with representational theories. But the similarities end there. The logic behind informational or expertise approaches is not that women represent a particular class but rather that they possess unique and valuable information emanating from shared professional experiences (Cameron and Cummings 2003; Gryski, Main, and Dixon 1986; Peresie 2005). Accordingly, sex‐based effects are likely to manifest themselves in an even more circumscribed set of cases—primarily sex discrimination in the employment context.7 But the effects themselves are likely to be broader, not only increasing the odds of a pro‐plaintiff decision by female judges in employment litigation but also by the male judges with whom they sit. The reason is straightforward enough: because, under this approach, female judges possess information that their male colleagues perceive “as more credible and persuasive” than their own knowledge about sex discrimination, females can directly or even indirectly alter the choices made by males (i.e., induce them to decide sex discrimination cases differently than they otherwise would; Peresie 2005, 1783; see also, e.g., Baldez, Epstein, and Martin 2006; Cameron and Cummings 2003; Ostberg and Wetstein 2007; Sullivan 2002).8"
"7","Finally, we turn to approaches that emphasize the commonalities between male and female judges, or what some call organizational accounts (e.g., Steffensmeier and Herbert 1999). While not necessarily denigrating the importance of diversity for, say, promoting social legitimacy, these analysts suggest that we are unlikely to observe any sex‐based effects in the courts. After all, they argue, male and female judges undergo identical professional training, obtain their jobs through the same procedures, and confront similar constraints once on the bench (see, e.g., Kritzer and Uhlman 1977; Sisk, Heise, and Morriss 1998). These commonalities should be sufficient “to overcome any biological, psychological, or experienced‐based differences between the sexes” (Steffensmeier and Herbert 1999, 1165).         "
"8","However different these accounts (and however distinct their empirical implications), scholars have devised remarkably similar designs and employed nearly identical methods to explore them. Virtually all quantitative work in this area:"
"9","                        "
"10","asks the same research questions: Does gender cause judges to behave differently (individual effects)? And, more recently, does the presence of a female judge cause male judges to act differently (panel effects)?;                  "
"11","makes use of a dichotomous regression model (typically logit or probit), with the judge's vote (e.g., for or against the plaintiff in sex discrimination cases) serving as the dependent variable;"
"12","captures the effect of sex in the same way, as a dummy variable for the sex of the judge (for individual effects) or a series of dummy variables for the sex of panel members (for panel effects); and"
"13","attends to (approximately) the same covariates (i.e., confounding factors), chiefly attributes of the judge (e.g., ideology, age, judicial experience, race) and characteristics of the case (e.g., direction of lower court decision, year of decisions)."
"14","Despite the similarities in approach, the resulting research findings have been somewhat mixed. By our count, social scientists and legal academics have produced over 30 systematic, multivariate analyses of the extent to which female judges make decisions distinct from their male colleagues (individual effects) or cause male judges to behave differently than they otherwise would (panel effects).9 Of these, roughly one‐third purport to demonstrate clear panel or individual effects, a third report mixed results, and the final third find no sex‐based differences whatsoever.         "
"15","Why the mixed findings is of less immediate interest to us than the question of how best to isolate sex effects, if in fact they exist. In what follows, we undertake this challenge, not by offering a critique of the existing approaches, but rather by returning to first principles—theoretical and methodological approaches to drawing causal inferences."
"16","Of interest to us and many others working in this area is whether and in what ways gender leads judges to behave differently. For a panel of judges hearing a case on an intermediate appellate court, for example, we aspire to estimate the extent to which the presence of a female judge causes male judges to vote in a particular direction when they otherwise would not.10"
"17","Estimating this causal effect demands counterfactual analysis (see, generally, Epstein et al. 2005; Epstein and King 2002; King, Keohane, and Verba 1994). We want to learn how a male judge would vote on a panel with a female judge but for the presence of the female judge. Undertaking it requires us to determine the effect of a female judge for any given panel composition, along with any other relevant (i.e., confounding) case and judge factors (such as the sex of the litigant and the ideology of the judge).            "
"18","This task would be straightforward enough in a research environment lacking constraints. We would create an all‐male panel and ask it to decide a sex discrimination case; then we would rerun history, holding everything constant except the absence of a female judge, and ask the panel to decide the same case. If we observed the men voting against the plaintiff when serving on the all‐male panel but supporting the plaintiff when serving with a woman, then we might conclude that the female had an effect on the panel and that the effect was in the direction anticipated by at least one theoretical account of sex difference."
"19","For a more formal accounting of this type of analysis, we adopt the potential outcomes framework posited by Neyman (1935) and Rubin (1973, 1974), thoroughly reviewed in Holland (1986), and recently applied in political science by Imai (2005) and Epstein et al. (2005). Under this framework, let the unit of analysis for our panel‐effect example be the judge‐vote cast by a male judge, and i = 1, …, N index each observation. Further, let Yi denote an outcome variable; say, whether the judge voted for (Yi = 1) or against (Yi = 0) the plaintiff in a discrimination suit. Finally, each judge‐vote takes place under one of two treatment conditions: the control group, denoted Ti = 0, includes the panels where the other two judges are male (an all‐male panel); the treatment group, denoted Ti = 1, consists of those panels with at least one female judge (a mixed‐sex panel).11 Note that this notation is in terms of potential outcomes: the case potentially could have been decided by an all‐male or mixed‐sex panel, and the panel could have decided it for or against the plaintiff.            "
"20","Under this framework and consistent with the Neyman‐Rubin model, we can now formally define the causal effect for each observation (τ subscripted by i) as the difference between the two potential outcomes:               "
"21","The difficulty, of course, is that in the real world of research we cannot rerun history to estimate the counterfactual and obtain τi and its summary . This is known as the fundamental problem of causal inference (Holland 1986, 947). It simply means that, for any given observational unit, we will never observe the outcome under both the treatment (a mixed‐sex panel) and the control (an all‐male panel). Instead, we see the judge‐vote either when it takes place under the control Yi(Ti = 0) or the treatment Yi(Ti = 1). To put it another way, we can only observe the factual (e.g., if the panel was, in fact, all male, then we observe an all‐male panel) and not the counterfactual (e.g., observing a mixed‐sex panel, if the panel was in fact composed of all males). Consequently, and depending on the research setting, we must make certain assumptions to estimate τi.            "
"22","Consider, first, the experimental setting. Were we able to randomly select judges and in turn assign them, again randomly, to treatment and control groups, we would assume that assignment is independent of all other observed pretreated covariates (denoted Xi). And then—with the assumption of independent assignment met—as the sample size grows, all observed and unobserved covariates will be balanced across the treatment and control groups due solely to the presence of randomization. Present also is the “stable unit treatment value assumption” (SUTVA; Rubin 1974), which states that the potential outcome of one unit does not depend on the treatment assignment of another unit.12"
"23","Because most experimental settings easily meet SUTVA and the assumption of independent assignment to treatment, researchers can estimate the average treatment effect by doing nothing more complicated than computing the differences of means:                "
"24","Unfortunately, of course, in most studies of judging—including ours—executing an experiment of this sort is nearly as impossible as rerunning history. While it is true that the U.S. appellate courts use a “wheel” to assign judges to panels, logic and practice counsels against deeming it a mechanism for true random selection.13 As a result, judicial specialists, again us included, must work with observational data, which substantially complicate the inferential task. One obstacle is that the assumption of independent assignment to treatment rarely, if ever, holds. This is not insurmountable, however, if we can condition on our observed covariates (Xi) and if the assumption of conditional ignorability holds. Should we have the appropriate pretreatment covariates—for a study of panel effects, judge‐specific and case‐specific covariates that precede panel assignment14—we can then assume that conditional on them, assignment to treatment is unconfounded; that is, after controlling for the covariates, the probability of being assigned to the treatment group is not correlated with the outcome variable.            "
"25","With this obstacle hurdled, and the additional assumptions of SUTVA and strong ignorability met,15 we can proceed to estimate the ATE :               "
"26","But how ought we estimate this effect? This question has been the subject of virtually no debate within public law and gender politics circles. Instead, a single approach has long dominated efforts in these fields to perform causal inference with observational data—including efforts to study gendered judging: linear regression models (or their variants for dichotomous dependent variables, such as logit or probit). The typical approach, as we mentioned earlier, is to regress an outcome variable of interest (usually the judge's vote, either for or against the sex‐discrimination plaintiff) on a dichotomous sex variable and a handful of controls, including additional information about the judges (e.g., their ideology) and the cases (e.g., direction of lower court decision)."
"27","To be sure, linear regression provides analysts with a particular type of statistical control, and, if certain assumptions are met, the model will provide reliable inferences about causal effects. But equally as apparent are several very serious limitations—not the least of which is that linear regression assumes the presence of a precise functional form for the relationship between the treatment and outcome, measured covariates and the treatment, and measured covariates and the outcome.16 In an experimental setting, where treatment assignment is randomized, this assumption is easily met. For observational data, however, we cannot depend on random assignment to ensure that our covariates are systematically unrelated to our treatment variable. As a result, imbalances frequently emerge. Since performing causal inference requires researchers to limit their analyses to the range of values for which they have data in the treatment and the control groups,17 the presence of imbalances can undermine the integrity of regression results. Without accounting for these imbalances in the covariates, analysts wind up comparing the equivalent of apples and oranges.            "
"28","Because the regression model too readily extrapolates beyond the range of the observed data, this may well be a rather frequent occurrence in analyses of legal decisions—and perhaps especially in work on gendered judging. To see why, consider that in virtually all studies of this sort the researcher takes into account, in addition to the judges' sex, their ideology. This is a sensible choice: we know that ideology is an important determinant of judicial decisions. But since female judges are, on average, far more liberal than their male colleagues, it is also a problematic choice. Figure 1 nicely illustrates the point. Looking at U.S. Court of Appeals judges who voted in disputes over sex discrimination in employment (Title VII) or the Americans with Disabilities Act (ADA) and using their Judicial Common Space scores (Epstein et al. 2007; Giles, Hettinger, and Peppers 2001) to measure ideology, we can see that the men are rather evenly dispersed between liberal and conservative groupings. Women, in contrast, noticeably skew to the left.            "
"29","                 The Ideology of U.S. Court of Appeals Judges Who Voted in Title VII Sex Discrimination and Americans with Disabilities Act (ADA) Cases                         "
"30","Each panel displays a kernel density plot that depicts the marginal distribution of ideology (measured using the Judicial Common Space), from most liberal to most conservative, of the participating U.S. Court of Appeals judges. The black line represents male judges and the grey line represents female judges. Case data come from Sunstein et al. (2006) and ideology, from Epstein et al. (2007).                        "
"31","Data of this sort are so imbalanced that regression analysis could produce profoundly misleading results. In concrete terms, because the range or distribution of ideology is, at least for now, sufficiently different between male and female judges serving on the federal courts, a linear regression model of their votes on their sex and ideology might well estimate a significant and negative treatment effect (men are more likely to cast left‐of‐center votes), when, in reality, the treatment effect is positive!18 Under such circumstances, the only way to ensure a reliable estimate of the average treatment effect is to obtain balance on the covariates; i.e., to compare apples and apples.19"
"32","In the simple example depicted in Figure 1 it is easy to spot the imbalance, but when we incorporate more covariates, as we typically do, that task becomes essentially impossible. More generally, while regression can be a useful and appropriate tool in some settings, it often makes assumptions that are unjustified in the study of judging (Epstein et al. 2005).            "
"33","If naively using linear regression can lead to misleading inference, especially when we expect imbalance in and nonoverlap of the covariates, what are the viable alternatives? The most promising is semiparametric matching, where the idea is to estimate equation (4) only when units are matched on all covariates. The intuition behind this approach is easy to grasp: while we can neither rerun history to see if male judges would decide the same case differently on an all‐male versus mixed‐sex panel nor run an experiment to test the same, we can match cases and judges that are as similar as possible (except of course on the key causal variable, the presence or absence of a female judge) to make the same causal inference. In other words, once we have conditioned on all the relevant confounding factors (i.e., pretreatment covariates; see note 14), we can attribute any remaining differences in the proportion of votes cast for or against plaintiffs to the presence of a female judge.            "
"34","While matching methods are only beginning to make headway in political science (see, e.g., Epstein et al. 2005; Imai 2005), they have gained considerable traction in statistics and other related fields. And, actually, one form of matching—exact matching—has even found its way into the literature on gendered judging (see, e.g., Segal 2000; Walker and Barrow 1985). With exact matching, the idea is to estimate equation (4) only when units are matched on all covariates.            "
"35","Exact matching has the benefit of increasing the plausibility of the assumption of strong ignorability. But it introduces other problems, primarily the “curse of dimensionality”: as the number of covariates increases, exact matching itself can become increasingly implausible.20 To see the problem, suppose we began with the first sex discrimination case decided by an appellate court panel in 1995. Further suppose that the suit was decided in favor of the female plaintiff by a mixed‐sex panel on which the men had fairly conservative ideological scores. Finally, assume that the panel's male judges were confirmed to the bench in 1950 and 1966 and the female judge was confirmed in 1979. To find an exact match for this case we would need to identify a dispute and a panel that had the same values on all the potentially confounding variables—in this example, a suit resolved in 1995 by a panel with two relatively right‐of‐center men with these precise confirmation years—but on which a female judge, and not three males, sat. Because such an exact match may not exist in our database, we would be forced to discard this dispute, and likely countless others, from our analysis. And the problem—the curse really—only grows exponentially as we add more covariates, such as additional judge attributes and the direction of the lower court decision.            "
"36","To avoid unnecessarily wasting data, we create matches that are not exact but are as close to exact as possible. The approach we take is to match on a one‐dimensional summary of the pretreatment covariates known as the propensity score (Rosenbaum and Rubin, 1983, 1984). By calculating the predicted values from a logistic regression of the treatment indicator Ti on only the pretreatment covariates Xi, the idea is to obtain a single variable—the estimated propensity score—that serves as a summary of the covariates on the treatment and control groups. With the propensity scores in hand, we can utilize them to match observations (using a variety of strategies discussed below) without making any of the strong parametric assumptions necessitated by linear regression.            "
"37","Estimating propensity scores and executing matching are tasks that require the researcher to make a series of choices, and momentarily we explain ours. But first we must deal with a final conceptual complication—one that implicates the specific research questions we ask and the precise inferences we can draw. Simply put, a crucial and by now obvious feature of the potential outcomes framework is that for a treatment to be a cause there should be “potential (regardless of whether it can be achieved in practice or not) for exposing or not exposing each unit to the action of a cause” (Holland 1986, 946). In practice, this means that attributes, such as a judge's sex, cannot be viewed as causes. As Cox tells us, in most cases, sex “is not a causal variable but rather an intrinsic property of the individual” (1992, 296). Drawing inferences about sex, race, and other immutable characteristics is methodologically quite challenging and is only now starting to receive attention in the literature on causal inference (see, e.g., Greiner and Rubin 2009; Imai and Yamamoto 2010).            "
"38","Where does this leave us with the two research questions of interest? The second question—does the presence of a female judge on a panel cause male judges to behave differently?—lends itself to causal analysis. In principle, a case could have been heard by a panel with only men or a panel with one or more women. As a result, panel composition is (experimentally speaking) subject to manipulation, and with suitable pretreatment covariates, it is possible to estimate the average treatment effect. To put it another way, because the values of our observed covariates are determined before the panel is assigned, we can assess the extent to which the presence of a female judge causes male judges to behave differently.            "
"39","Our first research question (and the one that predominates in the existing literature)—do male and female judges decide cases differently?—presents two problems. First, because the treatment is the sex of the judge, most would say that it fails to meet the “no causation without manipulation” standard. Second, the other covariates relevant to this question—whether centering on the judge's attributes (e.g., ideology and age) or the case's details (e.g., direction of the lower court decision)—occur after the sex of the judge is determined. With only posttreatment covariates, we cannot estimate a causal effect.            "
"40","The conclusion is thus inescapable: the question of whether sex causes judges to behave differently is ill posed. Instead, our data can only be informative on the descriptive—though nonetheless interesting—matter of whether male and female judges decide cases differently. This does not imply, we hasten to note, a return to regression analysis without first balancing the database. Quite the opposite: to perform better descriptive inference, we still should harness the power of matching methods. As Rubin himself observed,            "
"41","                              "
"42","[E]ven though it may not make sense to talk about the ‘causal’ effect of a person being a white student versus being a black student, it can be interesting to compare whites and blacks with similar background characteristics to see if there are differences in academic achievement, and creating matched black‐white pairs is an intuitive way to implement this comparison. (2006, 3)"
"43","With that important caveat now noted, we turn to the implementation of propensity score matching—a task performed in four steps: selecting appropriate factors on which to match cases and judges, amassing the data necessary to assess the various accounts of gendered judging (see Table 1), estimating the propensity scores, and matching observations. Once we have semiparametrically processed the dataset in this way, we can summarize the difference in judging for the first question and estimate the causal effect for the second (Ho et al. 2007).         "
"44","Beginning with the first step, choosing covariates, we took cues from the large and well‐established literature on judging in the U.S. Courts of Appeals (e.g., Cross 2007; Hettinger, Lindquist, and Martinek 2004; Scherer 2005) and incorporated both judge‐based attributes (e.g., ideology and age) and case‐specific factors (e.g., year of decision and the direction of the lower court decision).21"
"45","Our data on the votes cast by judges come from the Sunstein et al. (2006) project on the federal appellate courts. To determine whether Democratic judges reach more liberal decisions than Republicans, and whether the partisan composition of a panel affects votes as well, the Sunstein team developed a database containing the decisions of federal appellate court judges in 13 areas: abortion, affirmative action, disability law (ADA cases), campaign finance, capital punishment, the Contract Clause, environmental protection (EPA cases), federalism, piercing the corporate veil, sex discrimination in employment (Title VII), sexual harassment, the Takings Clause, and race discrimination (Title VII).22 Not only are these data of an extremely high quality in terms of their accuracy, detail, and thoroughness, but, also, fortunately, given the range of areas covered, they are extremely well suited to assessing the various theoretical accounts of sex‐based judging. Under differences accounts, to reiterate, we anticipate individual effects across most of, if not all, 13 areas. For representational approaches, we also expect individual differences, but they should be largely cabined to abortion, affirmative action, sex discrimination, and sexual harassment cases. If informational accounts are afoot, we ought to observe both individual and panel effects but in an even more circumscribed category of cases, sex discrimination in employment.23"
"46","With the data in hand, we complete our final steps: estimating propensity scores for each judge‐vote in the cases (for individual and panel effects) and matching the observations (again, for individual and panel effects). For both the individual and panel effects analyses, we used a logistic regression of the treatment indicator on a number of covariates to estimate the propensity score. The right‐hand panels of Figure 2 depict the distribution of the propensity scores prior to matching for the Title VII sex discrimination and Americans with Disabilities Act (ADA) cases (see note 22).24 For the sex discrimination scores, note the lack of common support: we observe no female judges in a broad propensity score area (roughly beyond −4). A similar, if not as severe, issue exists for the ADA propensity scores. The problem for both, and the other 11 datasets as well, is a lack of balance on many covariates, as Table 2 indicates. Note, though, that the matching procedure was successful in remedying the imbalances. A visual inspection of the left‐hand panels of Figure 2 suggests as much, and Table 1 confirms what our eyes tell us. The percent reduction statistics and the eQQ medians both show that for nearly all covariates, matching greatly improved balance.25"
"47","                 Kernel Density Plots of the Estimated Propensity Score for the ADA and Title VII Sex Discrimination Individual Effects Analyses                      "
"48","The black lines depict the density for all‐male panels (control); the grey lines for mixed‐sex panels (treatment). Each left‐hand panel represents the full datasets while the right‐hand panels display the propensity scores for only the matched data."
"49","Turning to panel effects, at first blush the left‐hand panels of Figure 3 seem to indicate that common support for the ADA and Title VII sex discrimination cases is not much of an issue.26 On further inspection, though, the range of the propensity scores are more evenly spread for male judges (the black line) than for the females (grey line)—a fact that Table 3 confirms (note the presence of imbalances in the scores and other covariates). Matching markedly improves balance, as the percent reductions and eQQ medians in Table 3 and the right‐hand panels of Figure 3 indicate.27 In other words, after matching, the distribution of the propensity scores for the treatment and control groups in each dataset appears quite similar, suggesting that balance has been achieved.         "
"50","                 Kernel Density Plots of the Estimated Propensity Score for the ADA and Title VII Sex Discrimination Panel Effects Analyses                      "
"51","The black lines depict the density for all‐male panels (control); the grey lines for mixed‐sex panels (treatment). Each left‐hand panel represents the full datasets while the right‐hand panel displays the propensity scores for only the matched data."
"52","Performing inference required one final step: matching observations. For this task, we used “nearest‐neighbor” matching with replacement; that is, for each “mixed‐sex” observation (or female judge, for the individual analysis), the “all‐male” observation (or male judge) that has the closest propensity score is selected.28 We implemented this approach by matching observations from the control group (e.g., male judges on all‐male panels) multiple times (“with replacement”).29"
"53","With the balanced datasets in hand (along with weights necessary for subsequent analyses), we turned to the task of assessing the impact of the variables of interest. In terms of implementing it, scholars are of two minds. Some suggest that researchers can estimate the causal effect with little more than a difference of proportions test (e.g., Smith 1997) because the data are now balanced. Others recommend proceeding in the typical fashion by parametrically processing the now balanced database (e.g., Ho et al. 2007). We do both with the hope of unearthing consistent results, and, as it turns out, this is (almost) precisely what obtains.         "
"54","We begin our analysis with the question of whether male and female judges differ in their decisions over cases in the 13 issue areas. Returning briefly to Table 1, the four accounts of gendered judging present relatively diverse empirical expectations with respect to individual effects: for “different voice,” we should see effects across most, if not all, of the issue areas; for representational, effects should be limited to abortion, affirmative action, Title VII sex discrimination, and sexual harassment; for informational, we expect only Title VII sex discrimination cases to produce effects (but see note 23); and for organizational, no effects at all are anticipated.            "
"55","To assess these accounts, we estimated four different models for each of the 13 datasets. The first two are the conventional tests in this literature: logistic regressions using the full unbalanced dataset—specifically a bivariate, with the sex of the judge as the only covariate (the equivalent of a difference of proportions test); and a fully specified model incorporating the judges' political ideology.30"
"56","We plot the resulting individual effects ATEs for all 13 issue areas in Figure 4.31 For each, we constructed the top two models using the full, unmatched data and the bottom two models, from the matched data.32 Note that almost without exception, female and male judges do not reach different decisions. To be sure, for the ADA and capital punishment cases, the results of the naive, unmatched analyses seem to indicate that female judges are more liberal. But this turns out to be an artifact of imbalances in the data; for both the naive and multivariate models, the matched data analyses reveal no significant effects. Note too (and in contrast to some existing empirical results), the matched data findings show that the judges' sex has no bearing on the direction of their votes in sexual harassment, affirmative action, or abortion litigation. These findings might give pause to proponents of representational and, especially, “different voice” accounts of gendered judging.            "
"57","                 Dotplots of Average Treatment Effects (ATEs) for Individual Effects Across 13 Issue Areas                         "
"58","The lines represent 95% confidence intervals for the average treatment effect. For every issue area, the first two models are logistic regression models fit to each full, unbalanced dataset. The naive model includes only the judge's sex as a covariate. The other model includes the judge's sex and a number of controls, including ideology. The next two models show the ATE after nearest‐neighbor matching with replacement on the estimated propensity score. The first is for a difference of proportions analysis. The second is for a logistic regression model with the judge's sex and a number of controls including ideology."
"59","One exception to this general finding of “no difference” emerges, however, and it tends to support informational approaches while discounting organizational theories: female and male judges differ significantly in their treatment of Title VII sex discrimination suits. On average, the probability of female judges voting in favor of the plaintiff in a sex discrimination case is around 0.10 higher than it is for male judges—a difference with meaning, as Figure 5 indicates.            "
"60","                 Predicted Probabilities of Pro‐Plaintiff Votes in Title VII Sex Discrimination Cases as a Function of the Judicial Common Space (Ideology) and the Gender of the Majority Opinion Writer for Male and Female Judges, Individual Effects                         "
"61","The Judicial Common Space runs from most liberal (here, −0.6) to most conservative (0.6). These estimates are from the weighted logistic regression model on matched data. All continuous variables are held at their sample means; other variables are at their sample modes. The vertical grey lines denote 95% confidence intervals."
"62","There we depict the predicted probabilities of men and women casting liberal (pro‐plaintiff) votes in sex discrimination cases as a function of their ideology and the gender of the majority opinion's author. Note that the estimated probability of a female judge voting in favor of the plaintiff (when a female judge is the majority opinion writer) is over 0.61 at the highest levels of liberalism; for even the most left‐of‐center male, that figure is closer to 0.50. When the case has a male majority opinion writer, the likelihood of a liberal male judge voting in favor of sex discrimination plaintiffs is less than 0.38."
"63","What is especially interesting about these results, we believe, is that they may have gone undetected had we employed the standard procedure (i.e., estimating a logit model with unbalanced data). Note that in the full, unmatched sex discrimination data displayed in Figure 4, at a 0.05 level of statistical significance, no difference emerges between male and female judges.33 Only via matching and balancing were we able to unearth what amounts to a fairly important sex‐based distinction.            "
"64","Turning to panel effects, recall that accounts of sex‐based judging are nearly of one mind. Of the four, only informational accounts suggest that a female may influence her male colleagues and then only in sex discrimination cases. As it turns out, our results are consistent with this one account; they also parallel the findings for individual effects (see Figure 4).34"
"65","As Figure 6 indicates, for most types of disputes male judges serving on mixed‐sex panels do not vote differently than male judges serving on all‐male panels. As was the case for individual effects, the naive, unbalanced ADA and capital punishment analyses indicate statistical significance but yet again the matched data analyses do not support the conclusion of a genuine difference based on panel composition. More importantly, our analyses identify no significant differences in several areas (e.g., sex harassment and affirmative action) where others previously reported them (e.g., Cameron and Cummings 2003; Peresie 2005).            "
"66","                 Dotplots of Average Treatment Effects (ATEs) for Panel Effects across 13 Issue Areas                         "
"67","The lines represent 95% confidence intervals for the average treatment effect. For every issue area, the first two models are logistic regression models fit to each full, unbalanced dataset. The naive model includes only the treatment as a covariate. The other model includes the treatment and a number of controls, including ideology. The next two models show the ATE after nearest‐neighbor matching with replacement on the estimated propensity score. The first is for a difference of proportions analysis. The second is for a logistic regression model with the treatment and a number of controls including ideology. See also note 34."
"68","Where strong and systematic panel effects emerge is in precisely the same area we observed them in the individual effects analyses: sex discrimination. Consistent with informational accounts, for not one sex discrimination model displayed in Figure 6 does the 95% confidence interval come near the zero line (indicating no difference between male judges serving on all‐male and mixed‐sex panels). Rather, we observe causal effects ranging from 0.12 to 0.14—meaning that the likelihood of a male judge ruling in favor of the plaintiff increases by 12% to 14% when a female sits on the panel.35"
"69","Not only is this a fairly large difference but, at least from the perspective of litigants, it is also quite consequential, as Figure 7 shows. Notice that for all‐male panels the probability of supporting the plaintiff in a sex discrimination dispute never exceeds 0.20—not even for the most liberal of male judges. But for mixed‐sex panels, the probability never falls below 0.20 for even the most conservative males. For males at relatively average levels of ideology, the likelihood of a liberal, pro‐plaintiff vote increases by almost 85% when sitting with a female judge.            "
"70","                 Predicted Probabilities of Pro‐Plaintiff Votes in Title VII Sex Discrimination Cases as a Function of the Judicial Common Space (Ideology) for All‐Male (Control) and Mixed‐Sex (Treatment) Panels                         "
"71","The Judicial Common Space runs from most liberal (here, −0.6) to most conservative (0.6). These estimates are from the weighted logistic regression model on the matched data. All continuous variables are held at their sample means; other variables are at their sample modes. The vertical grey lines denote 95% confidence intervals."
"72","Seen in this way, the results for sex discrimination panel effects mirror our findings for individual effects: for both, we find evidence of statistical significance and substantive importance. In fact, the only difference of note between the two sets of results centers on matters of methodology. In the case of individual effects we observe disparate results between the traditional regression‐based analyses on the unmatched data and the analyses on the matched data; for panel effects, no such differences emerge."
"73","Why? The most plausible answer, as we hinted earlier, is that random assignment to panels, while an imperfect selection mechanism, produces data that reasonably meet the assumption of independent assignment to treatment. This implies, in turn, that panel data will be close to balanced, or, at the least, more balanced than under the complete absence of randomization.36 But it does not imply, to reiterate, that balancing via matching is per se unnecessary for panel data. Quite the opposite. The danger of assuming a balanced dataset is far greater than the perils of semiparametric balancing; the former can easily lead to severe errors of inference, while the latter cannot (see, e.g., Ho et al. 2007; Greiner 2006). Scholars should be no more willing to deploy regression‐based tools to analyze nonexperimentally generated data than they would be to use, say, linear regression to estimate a model with a binary dependent variable (regardless of whether it yields results no different than a probit model). Best practice, of course, demands that we always use the most appropriate tool at our disposal. For even if the most and least suitable methods supply the same answer for a set of analyses of a particular set of data—as was the case here for panel effects—this will not always or even usually hold.            "
"74","Ever since the campaign to place women on the federal bench began in earnest, supporters have emphasized both the symbolic and the practical implications of appointing female judges. While the first is primarily a matter for normative theorists, the second is susceptible to empirical scrutiny. And that is what we have attempted to give it here. Drawing on empirical expectations from four accounts (different voice, representational, informational, and organizational), we proceeded from a formal framework for causal inference to answer questions that have long dominated scholarly and policy discourse over the role of sex in judging."
"75","The results of this exercise are now reasonably clear: the presence of women in the federal appellate judiciary rarely has an appreciable empirical effect on judicial outcomes. Rarely, though, is not never. Based on an account that isolates the analysis to judge‐vote observations with a nearest‐neighbor match, we observe consistent and statistically significant individual and panel effects in sex discrimination disputes: not only do males and females bring distinct approaches to these cases, but the presence of a female on a panel actually causes male judges to vote in a way they otherwise would not—in favor of plaintiffs. Characterized in this way, our results are consistent with an informational account of gendered judging; they also serve to reinforce other studies that identified gender effects in the employment area. Finally, our results may provide empirical fodder for a class of normative claims supportive of diversity on the bench; namely, “the greater the diversity of participation by [judges] of different backgrounds and experiences, the greater the range of ideas and information contributed to the institutional process,” and the higher the likelihood of altered deliberations in response (Epstein et al. 2003, 944; see also Cameron and Cummings 2003).         "
"76","While we hope our study goes some distance toward answering important questions in the literature, we also think that the very questions we addressed here continue to deserve a prominent place on the scholarly agenda. It seems entirely worthwhile, for example, to consider the extent to which our findings transport to other collegial courts, both here and abroad, and to other stages in the litigation process. We also can imagine extending the analyses to cover other attributes, including race, religion, and age."
"77","We certainly commend these challenges to scholars working in the fields of public law, gender politics, and race and ethnicity. Going forward, we also encourage the use of the general framework and methods deployed here—as do a growing number of other political scientists who too now call for a reconsideration of the field's traditional and dominant approach to inference (e.g., Epstein et al. 2005; Greiner 2008; Ho et al. 2007). To them, reliance on regression analyses of unmatched data far too often leads to unreliable and misleading results. In light of the findings here, along with promising developments in the statistical sciences aimed at improving the conclusions we can draw from observational data, their message seems especially timely.         "
"78","This is almost certainly true for the burgeoning scholarship on the extent to which female legislators better represent women's interests compared to their male counterparts (e.g., Dodson 2008; Reingold 2000; Swers 2002)—an area in which the same sort of imbalances we identified may well be present. But it also may hold for research outside the gender (or race) realm. In one of the few previous studies on judicial behavior that adopted a potential‐outcomes framework—Epstein and colleagues' (2005) analysis of the effect of war on Supreme Court decisions— the authors found imbalance on the key causal variable: liberal courts, relative to conservative courts, were more likely to decide cases during war times. Had Epstein et al. failed to correct for this imbalance via propensity score matching, they would have reached the highly misleading conclusion that the Court was more likely to protect individual rights in the middle of a war. Of course, the extent to which imbalance plagues other research on judging or legislating is an empirical question that researchers must evaluate for their particular projects. At the very least, though, our study, in line with the few others in this area, counsels in favor of such evaluations.         "
