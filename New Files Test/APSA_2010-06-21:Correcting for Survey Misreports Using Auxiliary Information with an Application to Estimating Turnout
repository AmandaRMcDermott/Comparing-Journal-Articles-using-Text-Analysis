"","x"
"1","Let  be a dichotomous (dummy) variable, and denote by  a vector of individual characteristics of interest. We want to estimate the conditional distribution of  given . However, instead of observing the “true” dependent variable , assume we observe the self‐reported indicator . Most studies use the observed  as the dependent variable, typically running either a probit or logit model to estimate .            "
"2","In order to know whether this substitution can lead to incorrect inferences, we need to know the relationship between  and . We can always write               "
"3","Standard methods for estimating binary choice models generally assume that the conditional distribution of the dependent variable given  is known up to a parameter vector β. However, unless , estimating the conditional probability  rather than  will generally lead to biased estimates of β and inaccurate standard errors, with even small probabilities of misreporting potentially leading to significant amounts of bias (Hausman, Abrevaya, and Scott‐Morton 1998; Neuhaus 1999). In addition, the marginal effect of covariate x on the observed response  and on the true response  will differ by               "
"4","As a result, inferences drawn on the relationship between the covariates of interest and the response variable may change substantially when estimated based on the likelihood function defined by  rather than on the true model , depending on the distribution of  and the covariate vector , on the prevalence of misclassification and on the relationship between the probabilities of misreporting and the covariates in  (Bernstein, Chadha, and Montjoy 2001; Hausman, Abrevaya, and Scott‐Morton 1998; Neuhaus 1999).            "
"5","Different parametric models have been proposed to correct for misclassification of the dependent variable in binary choice models (Carroll, Ruppert, and Stefanski 1995; Hausman, Abrevaya, and Scott‐Morton 1998; Paulino, Soares, and Neuhaus 2003; Prescott and Garthwaite 2002, 2005).8 In particular, Hausman, Abrevaya, and Scott‐Morton (1998) proposed a modified maximum likelihood estimator that requires the “monotonicity” condition  to achieve identification. Using Monte Carlo simulations, they showed that their model consistently estimates the extent of misclassification and the parameter vector β, at least in large samples. More recently, however, Christin and Hug (2004) replicated the work of Hausman, Abrevaya, and Scott‐Morton (1998) for different sample sizes and found that the modified maximum likelihood estimator performed consistently better than simple probit models ignoring misclassification only in samples of 5,000 or more observations. As noted by Gu (2006), the failure of Hausman, Abrevaya, and Scott‐Morton's (1998) estimator in small samples is likely due to the insufficiency of the monotonicity condition to ensure model identification. For such sample sizes typically available in political science, even moderate rates of misclassification may hinder model identification, so different assumptions may be required to put bounds on the misclassification rates and the regression coefficients. In addition, Hausman, Abrevaya, and Scott‐Morton (1998) and, in fact, most empirical applications of models proposed to correct for misreporting, assume constant misclassification rates, failing to account for the potential influence of the covariates of interest on  and .9"
"6","Relevant prior information on the misreport patterns is often available from auxiliary data sources, such as internal or external validation studies, small sample pilots, or administrative registers, which can be used to impose restrictions on the misreport probabilities and regression coefficients to aid in identification and improve inferences on the relationship between  and  (Molinari 2003). In order to incorporate this information, we propose a simple Bayesian approach based on Markov Chain Monte Carlo (MCMC) methods that can be easily implemented by practitioners and applied researchers using flexible and freely available software for Bayesian analysis, such as WinBUGS or JAGS (Plummer 2009; Spiegelhalter, Thomas, and Best 2003).            "
"7","We are interested in accurately estimating the effect of relevant individual characteristics on the conditional distribution of the true response. Hence, the focus of our analysis lies in the marginal posterior distribution of β, while the model for the conditional probabilities  and  can be regarded as “instrumental.”            "
"8","Since the observed response variable is dichotomous, we can start by assuming that, conditional on some set of individual characteristics, the observations are independently and identically distributed according to a Bernoulli distribution—as in Hausman, Abrevaya, and Scott‐Morton (1998). The probability of the sample can therefore be written as               "
"9","Suppose that both the true and the self‐reported dependent variables are recorded for all respondents in a validation study of size M. Comparing  to  for every , we can estimate the misreport probabilities for the validated sample. Let  and  denote sets of regressors that are useful in predicting the conditional probabilities  and , where the notation allows for the fact that we may use different regressors to predict the two types of misreporting.  and  may include some or all of the variables in , as well as other variables not affecting the true response. Again, we assume probit link functions and specify the conditional probabilities of misreporting as  and . Letting  denote the data from the validation study, the likelihood from  is:               "
"10","The posterior distributions  or  could then be used to specify the priors for , and  in the model fit to the sample of interest by repeated application of Bayes' theorem. However, since these posteriors cannot be expressed as tractable distributions, there is no straightforward way of transferring the relevant information from the validation study to the analysis of the main sample (Prescott and Garthwaite 2005). In addition, unless the validation study is a random subsample of the main study, heterogeneity between the two samples might in some circumstances lead to misleading conclusions if inference on β is based on the pooled datasets (Dunson and Tindall 2000). Hence, we consider both samples simultaneously, combining the likelihoods in equations (5) and (7) with vague independent priors , and  and weighting the likelihood from the validated sample by a “tunning” parameter δ that controls how much influence the validated data have relative to the main sample (Ibrahim and Chen 2000). The joint posterior density of the unknown parameters thus becomes:               "
"11","Consequently, we only need to have validated data from a previous sample or for a subsample of the respondents in order to correct for misreporting in the model for the main study. In case several validation studies are available, they can be easily integrated into our analysis by adapting the method proposed in Ibrahim and Chen (2000) to incorporate historical data in binary choice models, substituting  in equation (8) by:               "
"12","Even if we did not have access to a validation sample, several other sources of information, such as administrative records or even aggregate data, could be used to impose informative constraints on the misclassification rates and improve the parameter estimates. For example, in the analysis of voter turnout, we may observe turnout rates in small geographic areas, such as counties or congressional districts, that could be used to specify the misreport probabilities for all individuals in the sample belonging to a given area. Hierarchical beta priors can then be used to summarize auxiliary information available on misreporting patterns by location or relevant sociodemographic characteristics following the approach in Dunson and Tindall (2000). A Bayesian hierarchical model would also allow combining aggregate and individual data on misreport patterns if available (Congdon 2002). Finally, if no auxiliary data are available to predict misreporting, constraints on the misreport probabilities could be imposed via elicitation of experts' opinions. Our model would then be virtually identical to Paulino, Soares, and Neuhaus (2003).            "
"13","Despite the advantages of our approach, it is worth mentioning that, like all parametric estimators, our model might be quite sensitive to distributional and modeling assumptions. Although semiparametric methods have been used to estimate discrete choice models with misclassified dependent variables (Abrevaya and Hausman 1999; Hausman, Abrevaya, and Scott‐Morton 1998), they are also subject to potential misspecification (Molinari 2003). A different approach would be to adapt and implement nonparametric methods based on Horowitz and Manski (1995) and Molinari (2003).13 In particular, the “direct misclassification approach” proposed by the latter allows incorporating prior information on the misreporting pattern to obtain interval identification of parameters of interest and can be easily applied to the case in which misclassification depends on observed covariates with relatively little computational cost. However, as is well known, nonparametric methods are subject to the curse of dimensionality, which can pose a problem in applications where the misreporting probabilities might depend on a relatively large set of covariates, and is uncertain whether point identification can be achieved in this setting (Hu 2008). To the best of our knowledge, there is very little research comparing the performance of parametric versus nonparametric methods to correct for covariate‐dependent misclassification and evaluating the relative weaknesses and advantages of both approaches in applied work.            "
"14","Besides measurement errors, survey data are often plagued with large proportions of missing outcome and covariate values due to nonresponse or loss of data. As is well known, unless the data are missing completely at random (MCAR), using list‐wise deletion and restricting the analysis only to those respondents who are completely observed can lead to biased parameter estimates (Little and Rubin 2002).14 Furthermore, even if the data are MCAR, complete‐case analyses may lead to discarding a large proportion of observations and can be therefore quite inefficient (Ibrahim et al. 2005).            "
"15","While several alternative procedures have been proposed to accommodate missing data, fully Bayesian methods such as the one presented in this article are especially appealing when dealing with small sample sizes and when the fraction of missing values is considerable and can be easily implemented without requiring new techniques or additional steps for inference (Ibrahim, Chen, and Lipsitz 2002; Ibrahim et al. 2005).15 There is no distinction between missing data and parameters within the Bayesian framework, and thus inference in this setting essentially requires defining a prior for the missing values and sampling from the joint posterior distribution of the parameters and missing values, incorporating just an “extra‐layer” in the Gibbs sampling algorithm compared to the complete‐case analysis (Ibrahim et al. 2005). Hence, our model can be immediately extended to deal with missing responses and covariate values, including cases with missing responses alone, with missing covariates alone, and with missing covariates and responses. This allows us to accommodate item and unit nonresponse in both the main and the validation studies.16"
"16","Let , denote a  vector of covariates included in , and , and denote the marginal density of  by , where α parameterizes the joint distribution of the covariates. If some of the covariates are missing, we can write , where  is the  vector of missing components of , and  is the observed portion of . Similarly, we use  if the self‐reported outcome  is missing, and  otherwise. Assuming that the missing data mechanism is ignorable (Little and Rubin 2002), the observed‐data likelihood for the main study reduces to:               "
"17","As suggested by Ibrahim, Chen, and Lipsitz (2002), it is often convenient to model the joint distribution  as a series of one‐dimensional conditional distributions:               "
"18","Information on the misreport patterns and on all the parameters of interest can be incorporated from the validation study in an essentially identical way as in the case with no missing data. A joint prior for  could be specified as:               "
"19","In principle, it is possible to extend this approach to the case of nonignorably missing values. However, there is usually little information on the missing data mechanism, and the parameters of the missing data model are often quite difficult to estimate (Ibrahim et al. 2005). The plausibility of the assumption that the data are missing at random (MAR) can be enhanced by including additional individual and contextual variables in the model specification (Gelman, King, and Liu 1998).            "
"20","In this section, we conduct a series of simulation analyses aimed at assessing the sensitivity of our method to misspecification of the model of misreporting. This is a particularly relevant issue, since misspecification of the misreport model may lead to inconsistent estimates of β and affect inferences on the covariates of interest (Abrevaya and Hausman 1999; Hausman, Abrevaya, and Scott‐Morton 1998). Drawing on research analyzing a somewhat similar problem, namely, the sensitivity of the estimated treatment effects to the specifications of the propensity score model (Zhao 2008), we examine the influence on the estimated covariate effects of misspecifying the disturbance distribution and the linear predictor of the misreport model. For reasons of space, we only present a brief overview of the results from the Monte Carlo simulations. A detailed analysis is presented in Katz and Katz (2009).18"
"21","Based on the Monte Carlo design in Neuhaus (1999), we simulated 2,000 observations for two covariates: x1 is drawn from a standard normal distribution, and x2 is a dummy variable equal to one with probability 1/2. The true response  was generated as:            "
"22"," Figure 1 reports the estimates of the marginal covariate effects when x1 is omitted from the linear predictor of the misreport model (Specification 1) for different values of  and average symmetric misreport rates of 5%, 10%, and 20%.20 The estimates of the marginal effect of x1 worsen as the average misclassification rates increase and as the correlation between the covariate and the misreport probabilities increase. However, for all values of , the estimates from our model are closer to the true marginal effects than those from a model ignoring misreporting. The estimates for x2, on the other hand, are virtually unaffected by the omission of x1 from the model of misreporting and are again between 6 and 23 percentage points closer to the true effects than those from a standard probit model.         "
"23","                 Marginal Covariate Effects When x1 Is Omitted from the Misreport Model                      "
"24","The graph plots the marginal effects of x1 and x2 estimated under our method when x1 is omitted from the linear predictor of the misreport model, for different values of  and . Results are compared to those obtained ignoring misclassification. The center dots correspond to the posterior means, the vertical lines to the central 95% credible intervals, and the horizontal lines represent the average effects (dashed) and 95% intervals (dotted) estimated using  as the response.                     "
"25"," Table 1 complements the information from the figure, illustrating the influence of the other forms of misspecification considered for different values of , and . Adding irrelevant covariates and unnecessary nonlinear terms to the linear predictor of the misreport model has relatively little influence on the estimated marginal effects, and the same holds for the case of misspecified disturbance distributions. In all cases, the true average covariate effects lie within the central 95% credible intervals from our model, and the point estimates are betwen 4 and 18 percentage points closer to the true values than those obtained ignoring misreporting. It is worth mentioning that, as illustrated in Katz and Katz (2009), the estimates of  and  can be far away from the true coefficients when the model of misreporting is misspecified, particularly when the error terms are bimodal or heteroskedastic (Horowitz 1993; Zhao 2008). Nonetheless, the estimated covariate effects seem to be quite robust to the specification of the misreport model and much more accurate than those from standard parametric models when misclassificaton is nonnegligible.         "
"26","We also conducted additional simulations assuming slightly different misreport processes for the validated and the main samples. Specifically, the values of  and  in the main sample were obtained by adding uniformly distributed errors to the corresponding parameters from the validation study. The amount of misclassification and the direction of the relationship between the covariates and the misreport probabilities was preserved, but we changed the magnitude of the effect of x1 and x2 on  and . Again, as illustrated in Table 1, the marginal effects estimated from our model are quite close to the true covariate effects. In contrast, the model ignoring misclassification systematically underestimates  and overestimates . We must note, though, that these results are based on limited simulation analyses and may not be true in general.         "
"27","Next, we illustrate the potential consequences of misreporting in the context of estimating the determinants of voter turnout and provide three different applications of our methodology using data from all the validated ANES surveys between 1978 and 1990.21 This dataset comprises three midterm (1978, 1986, 1990) and three presidential elections (1980, 1984, 1988) and has the obvious advantage of allowing us to directly compare the estimates from our model to a known benchmark, i.e., the same model estimated directly on the validated vote. We assume the validated vote to be the “gold‐standard” measure of turnout, although there is considerable disagreement on this point (Burden 2000). The concern is that the validation studies are far from perfect. As stated at the outset, vote validation is expensive and difficult. The ANES is conducted in two parts, a pre‐ and postelection survey. In the studies from 1978, 1980, 1984, 1986, 1988, and 1990, there were in total 11,632 completed postelection surveys. Unfortunately, of these completed surveys, the ANES was unable to validate 2,189 respondents, about 19.8% of the usable sample.22 The majority of these failures were caused either because no registration records were found or because the local election office refused to cooperate with the ANES. If we are willing to maintain the assumption that these errors are essentially random (in the sense of being independent of the characteristics of interest), then there is no real harm done. The measurement error will merely result in less efficient estimates of the misreporting model and a corresponding reduction in efficiency of the corrected turnout model. However, if there is systematic error, then we are just substituting one form of measurement error for another.         "
"28","In the next section, we estimate a simple model of the determinants of the turnout decision using both self‐reported and validated turnout as the dependent variable in order to assess the consequences of ignoring misreporting. We reestimate the turnout model with self‐reported vote but apply our proposed solution to correct for misreporting, using a random sample of each survey as a validation substudy. We then apply our correction for misreporting under an external validation design, using information from previous ANES studies to correct for misreporting in the main sample. Both applications are based on a complete‐case analysis. We deal with the problem of incomplete data later, where we account for item and unit nonresponse using the approach described above.         "
"29","As mentioned in the introduction, it has long been established in the political science literature that survey respondents often report having voted when they did not actually do so (Bernstein, Chadha, and Montjoy 2001; Katosh and Traugott 1981; Sigelman 1982). Figure 2 illustrates the differences between turnout rates computed from self‐reported and validated vote in the six ANES studies under analysis. Validated turnout is systematically lower than reported turnout, and while both rates tend to follow similar trends, differences vary considerably across years, ranging from 7 percentage points in 1990 to more than 15 percentage points in 1980. Responding affirmatively to the turnout question were 17.3% of the survey respondents who claimed to have voted but did not do so according to the validated data, and more than 28% of those who did not vote according to the official records. In contrast, only 84 respondents in the 1978–90 ANES studies reported not voting when the official record suggested they did, representing 0.7% of the sample. Additional descriptive statistics on vote misreporting in the 1978–90 validated ANES can be found in Table 2.            "
"30","                 Self‐Reported vs. Validated Turnout, 1978–1990                         "
"31","The graph shows the self‐reported and validated turnout from the 1978–90 ANES only in years for which there were vote validation studies. Reported turnout rates are systematically larger than the validated ones."
"32","In order to examine whether such high rates of overreporting affect inferences on the determinants of the turnout decision, we fit two hierarchical probit models allowing for election year and regional effects with both self‐reported  and validated turnout  as the response variable:               "
"33","The regressors included in  are indicators for demographic and socioeconomic conditions and political attitudes: Age, Church Attendance, Education, Female, Home owner, Income, Nonwhite, Party Identification, and Partisan Strength. A description of the coding used for each of the variables may be found in the appendix. We should note that, while this specification includes some of the variables most commonly used in models of voter turnout found in the literature (Bernstein, Chadha, and Montjoy 2001; Highton 2004; Wolfinger and Rosenstone 1980), it does not examine the effect of other factors we might plausibly believe could alter turnout, such as political information (Alvarez 1997) or differences in state‐level ballot laws (Wolfinger and Rosenstone 1980). The sample used in the analysis consists of 6,411 observations for the six elections under study and was constructed so that they are identical for both models. Only the respondents with no missing response or covariate values are included in the analysis. The remaining observations were dropped using list‐wise deletion.            "
"34"," Figure 3 presents the main results from both models.23 The left panel summarizes the posterior distribution of the model's coefficients using self‐reported vote as the dependent variable, and the right panel redoes the analysis with the ANES validated vote. Most of the parameter estimates are quite similar in both models, and inferences on the role of these predictors on the probability of voting agree with common expectations. For example, for both sets of estimates, older, wealthier, and more educated respondents are more likely to turn out to vote. Also, strong partisans are on average 15 percentage points more likely to vote than independents, while respondents who attend church every week are on average 12 percentage points more likely to turn out to vote than those who never attend. Respondents are much more likely to turn out to vote in presidential than in midterm elections and are less likely to vote if they live in the South. These results are similar using either reported or validated vote as the dependent variable. However, there are some interesting differences between the two sets of results regarding the role of some sociodemographic variables such as gender and race. In particular, the mean posterior of the coefficient for the race indicator is more than twice as large (in absolute value) using validated vote than using self‐reported vote as the dependent variable.            "
"35","                 Coefficients of the Probit Models for Self‐Reported vs. Validated Turnout                         "
"36","The graph summarizes the posterior distribution of the coefficients of the turnout model, using self‐reported and validated vote as the response variable. The center dots correspond to the posterior means, the thicker lines to the 50% credible intervals, and the thinner lines to the 95% credible intervals."
"37","These differences in the parameter estimates can affect inferences drawn from both models regarding the impact of the covariates on the turnout decision. In order to illustrate this fact, Figure 4 plots the marginal effect of race on the probability of voting using reported and validated vote for the elections under analysis. As seen in the figure, the negative effect of being Nonwhite on turnout is higher when validated vote is used as the response variable for each of the surveys considered. The average marginal effects (posterior means) are more than 6 percentage points higher than if we look only at the reported vote, with differences ranging from about 3 percentage points in the 1984 and 1986 elections to almost 11 points in the 1978 and 1988 elections. While a researcher using reported turnout would conclude that race had no significant effect on the probability of voting in the 1978 and 1988 elections at the usual confidence levels, the results obtained using validated data indicate otherwise.24 Fitting a model of turnout using reported vote as the dependent variable will therefore tend to overpredict the probability of voting among nonwhite respondents and might in some cases affect substantive conclusions about the effect of race on turnout.            "
"38","                 Marginal Effect of Race on Turnout                         "
"39","The graph shows the marginal effect of the race indicator on the likelihood of voting for each election year under study, using both reported and validated vote. The center dots correspond to the point estimates (posterior means), the thicker lines to the 50% credible intervals, and the thinner lines to the 95% credible intervals."
"40","Finally, we examine whether overreporting varies systematically with individuals' characteristics, fitting a probit model for . As with the turnout model, the misreport model is fairly simple. The predictors include five variables that have been shown to be strongly correlated with overreporting in previous studies: Age, Church Attendance, Education, Nonwhite, and Partisan Strength (Bernstein, Chadha, and Montjoy 2001; Cassel 2003). In addition, we also include three additional covariates aimed at capturing some of the conditions of the interview. The first is an indicator of whether the interview was conducted while the respondent was alone. According to the “social pressures” argument (Loftus 1975), a respondent should be more likely to lie about voting if others will learn of the statement. The other two variables are the interviewers' assessments of the respondents' cooperation and sincerity during the interview.25 Point and interval summaries of the posterior distribution of the parameters are presented in Figure 5.            "
"41","                 Determinants of Misreporting                         "
"42","The graph shows the parameter estimates for the model of overreporting. The center dots correspond to the point estimates (posterior means), the thicker lines to the 50% credible intervals, and the thinner lines to the 95% credible intervals."
"43","In line with previous analyses, we find that overreporters tend to be more educated, older, more partisan, and more likely to be regular church attendees. Also, consistent with the results reported in Figures 3 and 4, being nonwhite has a positive effect on the probability of misreporting vote status: nonwhites are on average 0.05 more likely to misreport than their white counterparts, and this effect is significant at the 0.1 level. Several scholars have argued that African Americans and Latinos feel pressured to appear to have voted due to the struggles and sacrifices needed to gain voting rights for their racial or ethnic group (Abramson and Claggett 1986), although recent research has suggested that the relationship between race and overreporting is much more complex than previously thought and depends on the demographic and geographical context (Bernstein, Chadha, and Montjoy 2001).26 None of the other variables has a statistically significant effect on misreporting at the usual confidence levels. In particular, the interviewers seem unable to pick up a “feeling” that is not otherwise captured by the characteristics observable from the survey. This is probably caused by the fact that very few of the interviewers were willing to rank a respondent as uncooperative and/or insincere.27"
"44","Hence, the results from these simple models indicate that the probability of misreporting varies systematically with characteristics we might be interested in, and that failing to account for misreporting may affect parameter estimates and inferences about the determinants of voter turnout drawn from nonvalidated survey data. Unfortunately, as previously mentioned, the ANES has stopped conducting validation studies due to the cost and difficulty in collecting the data as well as to the fact that few researchers used the validated data. The next three sections allow us to evaluate the performance of our proposed method to correct for misreporting and improve estimates and inference obtained from self‐reported turnout. Although our model accounts for the possibility of two types of misreporting, we saw before that virtually no one reports not voting when they did, and thus  would be poorly estimated (Prescott and Garthwaite 2005). Therefore, in the applications below we will assume that , and we therefore only need to account for .            "
"45","We first apply our method assuming an internal validation design. As in the simulation exercise in the second section, we randomly assign half of the respondents in each of the 1978–90 surveys to be the validation substudy and ignore the validated data for the remaining respondents. We then used the information from the validated subsample to correct for overreporting in the main sample, equally weighting both datasets. For illustrative purposes, we fit the same turnout and misreport models described before for all the ANES studies considered. Nonetheless, as indicated above, the probability of voting is considerably higher in presidential than in midterm elections, and it is likely that different factors affect turnout in different election years. More importantly, the patterns of overreporting have also been shown to differ substantially across types of races and election years (Cassel 2003). As a result, the misreport model does not predict overreporting very well: the mean error rate of the misreport model across election studies is 36%, while a null model that simply predicts that no respondent overreports has an error rate of 31%. The model correctly classifies 64% of the survey respondents in cases, and the mean predicted probability of misreporting averaged across simulations is 0.45; ideally this would be near zero or one for the entire sample. Therefore, while the simulation results from the second section suggest that our approach is quite robust to misspecification of the model of misreporting, we note that the performance of our proposed method would benefit from better modeling of the misreport process.            "
"46"," Figure 6 summarizes the posterior distribution of the coefficients of selected regressors estimated using validated, self‐reported vote, and corrected self‐reports for the two ANES studies with the lowest (1978) and largest (1984) percentage of overreporters (see Table 2). Assuming that the parameters estimated using validated vote are the “correct” ones, the point estimates (posterior means) from our model for the two elections are between 32% and 92% closer to the “true” values of each of the parameters than the estimates ignoring overreporting. In addition, like the “true” estimate, the estimate of  under our approach is significantly negative at the 0.05 level for the 1978 ANES. Figure 7, in turn, plots the marginal effect of race on the probability of voting estimated using our approach to correct for misreporting. A comparison of the results in the left panel of the figure with those presented in Figure 4 above shows that, after correcting for misreporting, the impact of race in the 1978 and 1988 elections is now statistically significant at the usual confidence levels. Moreover, as seen in the right panel of Figure 7, the point estimates from our model are closer to the “true” effects than those obtained from the model using self‐reported vote for all the ANES studies, with differences ranging between 1 and 9 percentage points. Therefore, the evidence presented in this section indicates that, even with the simple model of misreporting estimated here, the improvements in the accuracy of the parameter estimates obtained using our method are important and can eventually change the substantive conclusions drawn regarding the effect of relevant covariates on the turnout decision.            "
"47","                 Posterior Summaries for Selected Parameters under an Internal Validation Design                         "
"48","The figure plots point and interval summaries of the posterior distributions of selected coefficients for the 1978 and 1984 ANES presidential elections, using corrected, self‐reported, and validated vote. The center dots correspond to the posterior means, the thick horizontal lines to the central 50% credible intervals, and the thin lines to the central 95% credible intervals from the three different models."
"49","                 Marginal Effect of Race on Turnout Estimated under Our Proposed Method                         "
"50","The left panel of the graph plots the point and interval (50% and 95%) estimates of the marginal effect of race on the probability of voting obtained using our method to correct for misreporting. The right panel compares the point estimates from our model and the model ignoring misreporting with the estimates obtained using the validated data."
"51","We also apply our correction for misreporting assuming an external validation design, ignoring the validated vote for the sample under analysis and incorporating information on the misreport probabilities and regression parameters from other ANES studies. Figure 8 illustrates the results of this exercise, plotting the marginal posterior distribution of selected coefficients for the 1988 and 1992 presidential elections obtained by updating the corresponding posteriors from previous validated ANES surveys.            "
"52","                 Posterior Densities of β under an External Validation Design                         "
"53","The figure compares the posterior densities of selected coefficients for the 1988 and 1992 presidential elections. The solid lines plot the posterior distributions of the parameters estimated from the validated vote, the dotted lines represent the estimates obtained using self‐reported vote, and the dashed lines represent the ones obtained adjusting for misreporting."
"54","The upper panel compares the posterior distributions of , and  for the 1988 ANES, the last presidential election for which vote validation is available, using validated, self‐reported, and corrected vote. In order to implement our correction for misreporting, we used auxiliary data from the two previous presidential elections for which validated turnout data were collected (1980 and 1984). As seen in the figure, the marginal posterior means and modes from the model accounting for overreporting are in all cases closer to “true” values than those obtained from the unadjusted self‐reports. Again, as the “correct” estimate, the estimate of  under our model is significantly negative at the 0.05 level. In the case of the 1992 ANES, for which there is no validated data, we implemented our correction for misreporting using information from the previous presidential elections for which vote validation was conducted (1980, 1984, and 1988) and compared the estimates from our model with those from a model using self‐reported vote. As seen in the lower panel of Figure 8, the posterior distributions of some of the parameters— and —remain essentially unchanged when applying the correction for misreporting. However, using auxiliary information does affect the posterior distribution of the coefficients of Income and Nonwhite. In particular, accounting for misreporting substantially affects the marginal posterior distribution of . The mean posterior is more than twice as large (in absolute value) when using the corrected self‐reports, and the effect of Nonwhite on the probability of turning out to vote is significantly negative at the 0.05 level, while it is not significant even at the 0.2 level when estimated using self‐reported vote. Similar results hold when applying our model to correct for misreporting in the 1994 ANES—for which, again, vote validation was not conducted—using validated turnout data from previous midterm elections.            "
"55","We also conducted a series of sensitivity analyses aimed at assessing the robustness of the parameter estimates to changes in the composition of the auxiliary data used to correct for misreporting and in the weight assigned to the validated vis‐à‐vis the main sample. Figure 9 summarizes some of the results for the 1988 and 1992 ANES. The left panel plots point and interval summaries for  from our model for the 1988 ANES using two different sets of values for the weighting parameters  in equation (9): a point mass prior  with probability , and uniform  priors , where . In the first case, the validated and main samples are pooled together, and the estimates of β for the main sample are obtained by updating the posteriors from the previous ANES surveys via Bayes' theorem. In the second case, we allow for different a posteriori weights for each of the validated samples, accounting for heterogeneity between the previous ANES studies. The right panel, in turn, compares the estimates from our model for the 1992 survey for the cases in which only validated data from the immediate previous (1988) or from all the previous (1980, 1984, 1988) presidential elections are used to adjust for misreporting.28 For both election years, the estimates from our model are compared to those from the unadjusted self‐reports.            "
"56","                 Sensitivity Analysis for the External Validation Design                         "
"57","The graph summarizes the posterior distribution of  from our model for the 1988 and 1992 elections, using alternative strategies to incorporate information from previous validated ANES studies. The estimates are compared to those obtained using self‐reported vote. The center dots correspond to the posterior means, the thicker lines to the 50% credible intervals, and the thinner lines to the 95% credible intervals.                        "
"58","As illustrated in the figure, the posterior standard deviations of β tend to decrease with the amount of auxiliary data used to correct for misreporting in the main sample, but the point estimates (posterior means) and the main substantive conclusions about β seem to be quite robust to changes in the values of δ and in the size and heterogeneity of the auxiliary data. In particular, correcting for overreporting using information from previous validated studies leads to stronger negative effects of  being Nonwhite on the probability of voting than using self‐reported vote, with differences of approximately 4 and 9 percentage points for the 1988 and 1992 ANES, respectively.            "
"59","Both applications of our methodology in the previous sections have been based on a complete‐case analysis, including in the sample only those respondents for whom both the response to the turnout question and all the relevant covariates are completely observed. When respondents with missing covariates differ systematically from those with complete data with respect to the outcome of interest, this approach may lead to significantly biased estimates and inference (Little and Rubin 2002). In our sample from the 1978–90 ANES studies, 14.5% of whites and 20.9% of nonwhites have missing covariate values (other than race), and the percentage of missingness for the self‐reported vote is almost two times larger for the latter. Since the evidence above indicates that voting patterns vary systematically with race, inferences from a complete‐case analysis may be quite misleading in this setting (Ibrahim et al. 2005). In addition, list‐wise deletion due to missing values in the response variable and/or the predictors leads to discarding more than 40% of the respondents in the 1978–92 ANES, so that complete‐case analyses are extremely wasteful and potentially inefficient. Table 3 reports the rates of item nonresponse for all the variables included in the turnout models estimated in earlier sections.            "
"60","In order to accommodate item and unit nonresponse, we implement the approach described in the first section, fitting a separate model for each of the ANES studies.29 Based on equation (11), we specified probit regression models for all the dichotomous covariates in the model—Female, Nonwhite, Home owner, and Alone—while the remaining categorical covariates were assigned conditional normal distributions and discrete values were afterwards imputed for the missing responses (Gelman, King, and Liu 1998).30 In all cases, we assigned vague independent normal priors for the components of α. Figure 10 illustrates the results for the 1978 and 1992 ANES. For the former, 31% of the survey respondents have at least one missing covariate value, and 0.5% of the respondents failed to answer the turnout question. The corresponding rates for the latter are 47% and 9%, respectively. A complete‐case analysis would keep 77% of our sample for the 1978 ANES and only 42% for the 1992 ANES. The left panel of the figure summarizes the marginal posterior distribution of  for the 1978 ANES using reported, validated, and corrected vote. As in an earlier section, our correction for misreporting was implemented based on auxiliary information from a random subsample of the ANES survey. The right panel, in turn, plots the estimates for the 1992 ANES, for which we use validated turnout data from the 1988 ANES. In both cases, estimates obtained using Bayesian imputation are compared to those from the complete‐case analyses.            "
"61","                 Posterior Summaries for                                                      with List‐Wise Deletion versus Bayesian Imputation                         "
"62","The graph plots point and interval summaries for  for the 1978 and 1992 ANES, using list‐wise deletion and fully Bayesian imputation. The center dots correspond to the point estimates (posterior means), and the horizontal bars indicate the 90% and 50% credible intervals for the models with imputed missing values.                        "
"63","Two interesting facts emerge from the figure. First, for both election studies, the marginal posterior distribution for  estimated using our Bayesian imputation model is not statistically different from that obtained using list‐wise deletion, at least at the 0.05 level. However, the standard errors tend to be lower when missing values are imputed than under list‐wise deletion. This result holds in fact for most of the election years under analysis, suggesting that by omitting the cases with missing values, much information is lost on the variables that are completely or almost completely observed, thus leading to less efficient parameter estimates (Ibrahim, Chen, and Lipsitz 2002; Ibrahim et al. 2005). This is likely to be an important concern in the election studies examined here, given that there is substantial variation in the rates of item nonresponse, with most of the variables exhibiting a relatively low percentage of missing values while a few others show very high rates of nonresponse (see Table 3). Second, imputing missing values does not change the substantive findings reported above regarding the performance of our methodology. The results for the 1978 ANES show that the estimated effects from our model correcting for misreporting are again closer to the benchmark case—using validated vote—than the effects estimated using recalled vote. This result holds for the other ANES validated studies as well. For the 1992 election, the marginal effect of race obtained from the corrected turnout model is also higher than in the uncorrected model, as was in the complete‐case analysis. For both elections, once again, the main substantive conclusions regarding the effect of being nonwhite on the probability of voting drawn from the model correcting for misreporting differ from those obtained using recalled vote.            "
"64","Survey data are usually subject to measurement errors, generally referred to as classification errors when affecting discrete variables. In the political science literature, misclassification of binary dependent variables has received considerable attention in the context of estimating the determinants of voter turnout. High rates of overreporting have been documented in survey instruments commonly used to study turnout in the United States, such as the American National Election Study (ANES) and the Current Population Survey (CPS), and most previous research has found that misreporting varies systematically with some of the relevant characteristics affecting the turnout decision."
"65","In the presence of misreporting, standard binary choice models will generally yield biased parameter estimates and inaccurate standard errors and may lead to erroneous substantive conclusions. This article develops a simple Bayesian method to correct for misreporting using information on the misreport mechanism from auxiliary data sources. Our model does not require full validation studies to be conducted every time a researcher is concerned about potential misreporting. As long as enough data exist to reasonably estimate the misreporting probabilities, our approach can be applied for drawing inferences from the nonvalidated samples, improving the accuracy of the parameter estimates and inferences regarding the effect of covariates of interest on the true response vis‐à‐vis standard models ignoring misclassification and methods assuming constant misreport rates. This is clearly important, since obtaining “gold‐standard” data is usually quite expensive and time consuming, and thus restricting the analysis only to validated studies will generally lead to discarding large amounts of useful information, as in the case of the ANES."
"66","The proposed model is fully general and modular, can be easily implemented using freely available software, and can be readily applied in the case of missing data in the response and/or covariates. While we illustrate our technique using turnout data from the ANES, it could be applied in general to account for potential misclassification of a binary dependent variable in many other situations in which auxiliary data on the misreport structure are available. Extensions to more general discrete choice models are also straightforward. Potential avenues for future research would be to use semi‐ or nonparametric methods to estimate both the misreporting and turnout models, simultaneously account for response and covariate measurement errors within our model, and explore the possibility of incorporating semi‐parametric approaches for inference with missing data."
"67","While the primary focus of the article has been on estimation techniques as opposed to substantive findings, the empirical application of our model to the analysis of the determinants of voter turnout has clear implications for researchers interested in race. Our results confirm that race does have a clear negative impact on turnout and suggest that the null previous findings have been probably due to problems of misreporting, as had been argued by Abramson and Claggett (1986). With the correction for misreporting developed in this article, researchers could now better estimate the effect of race over the length of the ANES datasets and not just for the few years with validated turnout data. In addition, researchers might wish to revisit Wolfinger and Rosenstone's (1980) findings of the effect of registration laws to see if properly correcting misreporting reinforces or diminishes their findings.         "
