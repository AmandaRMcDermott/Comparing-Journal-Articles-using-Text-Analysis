"","x"
"1","Race differences in political knowledge  Table 1 summarizes the distribution of responses to each of the seven political knowledge questions. The questions are arrayed from the easiest to the hardest, based on the percentage of correct answers offered by the African American respondents. For all but one question, “correct” and “wrong” answers comprised the majority of answers. Only on the “Who is William Rehnquist” question were most of the answers either “don't know” or “refused.” On the whole, the patterns of answers do not differ much between African American and white respondents, though on five items a larger percentage of whites answered correctly, and on two items (minimum voting age, which party holds a majority in the state legislature) a larger percentage African Americans answered correctly.            "
"2","On average (Table 2), African American respondents answered 3.05 questions correctly, while white respondents answered 3.83 correctly, a statistically significant difference (p < .001). Although there is a strong gradient in the number of correct answers by educational level of the respondents, the race differences cannot be accounted for by differences in the educational attainments of whites and African Americans.1"
"3","Blacks and whites did not differ in the tendency to “refuse” to answer the questions (p= .738). They did differ significantly, however, in the number of correct answers, wrong answers, and don't know answers that they offered (Table 2).            "
"4","Race of the interviewers Half of the black respondents were interviewed by persons whom they identified as black (see top panel of Table 3), compared to only one‐fourth of the white respondents. About 15 percent of black respondents did not identify the interviewers as either black or white, compared to 34 percent of the white respondents. The larger percentage among white respondents may reflect sensitivity on the race issue. When we examine the interviewers' own racial self‐identification (bottom panel of Table 3), we find far larger percentages who identify as black or white than the respondents reported.            "
"5","For purposes of testing the effects of race of the interviewers on the political knowledge scores of the respondents, it is tempting to rely on the interviewer's self‐identification as likely to be more accurate. However, race of the interviewer effects are more likely to be filtered through the respondents' perceptions of the interviewer. Also, if stereotype threat underlies the pattern of correct responses that we find among African American respondents, then the “threat” is likely to be induced by the perception that the interviewers are white, not directly by whether the interviewers are actually white (by their self‐description). Furthermore, since the focus of this research is on the black respondents, it is important that for most black respondents the race of the interviewer was not ambiguous—only 15 percent of black respondents answered “other,”“don't know,” or “refuse” when asked to report the race of the interviewer.            "
"6","Race of the interviewer and political knowledge Among white respondents, the mean number of correct answers is not associated with either the respondent's perceived race of the interviewer or the interviewer's self‐identified race (Table 4, panel A). The differences in the number of correct answers by perceived race of interviewer are small and not statistically significant (p= .485). Nor does the number of correct answers given by white respondents differ significantly by the self‐identified race of the interviewers (p= .922).            "
"7","In contrast, among black respondents, the perceived race of the interviewer matters a great deal. When interviewed by a black interviewer (perceived), black respondents answer an average of 3.42 political knowledge questions correctly. When interviewed by a white interviewer (perceived), black respondents answer an average of 2.80 questions correctly. When interviewed by an interviewer whose race is not perceived as either black or white (DK, Refuse, or Other), black respondents answer an average of 2.39 questions correctly—one fewer correct answers than those who are interviewed by black interviewers. The differences are both large and statistically significant (p= .001). However, as with the white respondents, we find no significant difference in the number of correct answers associated with the self‐identified race of the interviewers (p= .528). This finding reinforces the conclusion by Jackson, Hatchett, and Gurin (1990) that it is generally valuable to include perceived race of interviewer, not just self‐reported race of interviewer in studies of race differences in attitudes.            "
"8","Thus, how the interviewers classify themselves by race is not associated with different levels of performance on the political knowledge test. But the respondents' perception of the interviewers' race makes a great deal of difference for black respondents and no difference for white respondents. This result is highly consistent with a stereotype threat interpretation. When black respondents identify the test‐giver as black, they do much better on the test than when they identify the test‐giver as white or when the race of the interviewer is ambiguous, that is, the respondents are unable to put a black or white label on the interviewer.            "
"9","The findings with respect to the “ambiguous” category were unanticipated in our original design. Though based on only a small number of cases, they are intriguing. They suggest that even greater anxiety may occur when black respondents are given a test by a seemingly racially “neutral” (or at least not clearly identifiable) interlocutor. In any case, we find clear support for our overall expectation of higher performance on the test when blacks were interviewed by blacks."
"10","Controlling for respondent gender and education The foregoing analysis does not take into account other respondent characteristics that could account for some of the race differences in performance on the political knowledge test or, conceivably, the differences in performance associated with the race of the interviewers. One threat to the validity of the findings is that they could be produced by respondent characteristics such as gender and education.            "
"11"," Table 5 reports the results of OLS regressing the number of correct answers (as the dependent variable) onto perceived race of the interviewer, respondent's gender, and respondent's educational attainment. We should expect to find that men and persons with higher education are more knowledgeable about politics. This is indeed what we find, both for blacks and for whites.            "
"12","Even with the effects of gender and education taken into account, however, among black respondents we still find a substantial and statistically significant effect of respondent‐perceived race of the interviewer on the number of correct answers to the political knowledge test. Compared to the number of correct answers that they provide to black interviewers, black respondents provide an average of .436 fewer correct answers to white interviewers and .698 fewer correct answers to interviewers with “ambiguous” race. At the same time, for white respondents we find no significant differences in the number of correct answers associated with the perceived race of the interviewer."
"13","Controlling for interviewer‐respondent rapport Another threat to the validity of our inference that race‐of‐interviewer affects the political knowledge test performance is that something else in the relationship between respondents and interviewers is responsible for the observed patterns of responses. Conceivably, black interviewers establish greater rapport with black respondents than do white interviewers. This greater rapport might reduce the level of anxiety that respondents feel during the interview. If so, the better test performance of the black respondents interviewed by black interviewers could be due to the rapport between respondents and interviewers. However, if we can establish that the differences in test performance associated with perceived race of the interviewer hold up even after we take into account the rapport between interviewers and respondents, we would have even greater confidence in our interpretation.            "
"14","At the very end of each interview the interviewers were asked to evaluate how cooperative the respondent had been as well as how much interest he or she had shown in the survey.1 Since large majorities of the respondents were judged to be “very cooperative” and “very interested,” we dichotomized each of the initial four‐point scales into “very” and “not very” (cooperative, interested).            "
"15","We find no statistically significant difference among white respondents by race‐of‐interviewer in the percentage of respondents who are perceived as very cooperative or very interested in the survey (the data are not shown in a table). On average, 78 percent of the white respondents were judged to be “very cooperative” and 61 percent to be “very interested.” But these percentages did not vary significantly with the race of the interviewer."
"16","Among black respondents, too, we find no significant difference by race‐of‐interviewer in the percent who were perceived by the interviewers as very cooperative or very interested in the survey. On average, 75 percent of the black respondents were judged “very cooperative” and 61 percent “very interested.”"
"17","Because the two dichotomous variables are highly correlated with one another (Pearson's r = .54), we combined them to form a three‐point “rapport” scale which takes on the value of 2 if the respondent was judged by the interviewer to be both“very cooperative” and “very interested” in the survey, 1 if the respondent was either very cooperative or very interested, and 0 if respondent is neither very cooperative nor very interested. We then created dummy variables, Hirapport which takes the value of 1 if the combined rapport score was 2, and the value of 0 if not; and Mdrapport which takes the value of 1 if the combined rapport score was 1, and the value of 0 if not.1"
"18","When we introduce the terms Hirapport and Mdrapport into the previous regression equations (Table 6), we find not surprisingly that respondents who have high or medium level of rapport with the interviewers are likely to have offered more correct answers to the political knowledge questions. Those respondents were probably more motivated to perform the survey tasks. Of course this relationship can also be reciprocal: interviewers were more likely to judge respondents as cooperative or interested if they took the survey tasks more seriously.            "
"19","Even with both education and rapport taken into account, however, the race of interviewer effects remain among black respondents (and still do not appear among white respondents). Black respondents gave fewer correct answers to white interviewers or to those whose race was ambiguous (from the respondent's perspective) than they did to black interviewers."
"20","Test anxiety Standard introductions to questions on political knowledge are designed to reduce the potential threat or stigma associated with giving “wrong” answers. The 1985 NES pilot study (Zaller 1986) employed an introduction to such a battery of questions that explicitly states “this is not a test of any kind.” We modeled one variant of the introduction on this approach. That variant was given to a randomly selected half of the respondents who took the political knowledge test. We also hypothesized, however, that the effect of any “stereotype threat” would be intensified if the respondents were told explicitly that the political knowledge questions were a “kind of test.” That variant of the introduction was given to the other randomly selected half of the respondents to the political knowledge questions.            "
"21","We find no relationship between whether the threatening or the nonthreatening introduction was used and the number of correct answers offered to the political knowledge questions (Table 6). The coefficients for the test threat variable are small and not statistically significant for both white and black respondents. Nor are there any statistically significant interaction effects between the threat condition and other variables in the equation (not shown in the table). One reason for this result could be that even telling the respondent that “this is not a test” could heighten anxiety for some respondents. Because of the small sample size, we were not able to include a third variant—one in which the interviewers did not use the word “test” at all. So we do not regard our result here as definitive. Further experiments with question wording and order are warranted.            "
"22","We find that black respondents to a battery of questions about political knowledge in a telephone survey get fewer answers right when interviewed by a white interviewer than when interviewed by a black interviewer. These results are consistent with expectations based on the theory of “stereotype threat” that has been developed and applied to account for performance on standardized achievement and intelligence tests as well as athletic performance."
"23","The observed differences in performance on the political knowledge questions cannot be accounted for by differences in the educational background or gender of the individual respondents. Nor can the higher scores achieved by black respondents who are interviewed by blacks be accounted for by greater rapport between respondents and interviewers. Among both black and white respondents, the level of rapport does not differ significantly between those who were interviewed by black interviewers and those who were interviewed by interviewers from other racial groups."
"24","Although we can rule out the respondents' education and gender, as well as respondent‐interviewer rapport, as plausible rival explanations of the differences in the political knowledge test scores, we cannot say for sure that “stereotype anxiety” accounts for the differences. But the results are interesting in part because they suggest that research that heretofore has focused on standardized tests or on experiments with relatively low Ns, can be extended to “tests” of factual information in telephone surveys and to much larger samples in which it is possible to control explicitly for a variety of potential explanatory factors.         "
"25","Furthermore, these results suggest another way to think about the race‐of‐interviewer effects in social surveys. To the extent that minority group respondents regard their answers to survey questions as tests—whether the questions address factual issues or issues of attitudes or beliefs—they may be susceptible to anxiety produced by their role as subjects to a process in which they are at risk of being judged as giving “right” or “wrong” answers. In typical accounts of race‐of‐interviewer effects, respondents are said to mask their true feelings in an effort to please the interviewer or to appear to hold socially desirable attitudes. In some accounts, the respondents may exaggerate their conformity with socially approved norms and may even modify their subsequent behavior to fit the norms."
"26","However, in the present study, in which the task set before the respondents is to tell the interviewers what they know—and in which the interviewers (the survey researchers)—have an external standard for determining whether the answers are correct or incorrect, it is not possible for respondents (on average) to provide correct answers to questions to which they do not know the answers. Most respondents cannot make themselves look more knowledgeable than they actually are (except for those who may guess some correct answers). But it is possible for the respondents to appear to be uninformed or ill‐informed. And respondents who belong to racial minorities may experience added anxiety when they risk being uninformed in the presence of a member of the dominant racial group."
"27","The respondents were, of course, assured confidentiality and told also that they did not have to answer every question. They were not under the type of pressure to perform that they might experience if they had been given a large standardized test of knowledge or achievement. Also, as cooperative respondents committed to the task, few of the respondents who did not know the answers tried to avoid giving wrong answers by refusing to answer the questions. Instead, they mostly just gave more wrong answers. But black respondents were more likely to give wrong answers—to questions to which in some cases they probably knew the answers—when the questioner was from a different racial group than their own. And this, we suggest, looks like the consequences of stereotype anxiety.         "
"28","In future research, we plan to expand the types of tests and to experiment with a variety of test conditions to see whether we can replicate the results. One consideration is that the respondents in this survey may have been “race primed” (Steele and Aronson 1998) because the survey asked the respondents to identify their race before it asked the political knowledge questions.1 This may have increased the race sensitivity of the respondents to stereotype threat. This does not mean that the effects that we have observed are wrong, but it suggests the need to examine the effects of question order and content on the results.         "
