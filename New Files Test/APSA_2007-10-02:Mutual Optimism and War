"","x"
"1","We begin with an example that will provide some intuition for the general result that follows. Consider a game between two players, Alice and Bob, who have a choice between participating and not participating in a contest whose outcome is determined by chance. To start, each player is given a (fair) die to roll and the dice are compared. If Alice's die generates a higher number than Bob's, Alice wins. If the number on Bob's die is the larger he wins, and Bob and Alice tie otherwise. Suppose that each player maximizes expected utility and assigns a utility value of +1 to winning, −1 to losing, and 0 to a tie."
"2","Before deciding whether to participate in the contest or not, each player receives some information about the roll of the dice. In particular, Alice observes the result of her die and Bob observes the result of his die. After receiving this information, the two players simultaneously announce whether or not they agree to play the game of chance. If they both agree, payoffs are awarded as above and, in addition, each player pays a small cost c.4 If one or both players do not agree to play, then both receive a payoff of 0.         "
"3","To begin the analysis of this game, suppose a player naively considers only the private information he or she receives and does not make any additional inferences. That is, suppose Alice, for instance, observes the results of the first die and makes the assumption that the second die is equally likely to be any of the six possible values. Then it is easy to show via a simple expected utility calculation that if Alice observes 4, 5, or 6 on the first die, she would have positive expected utility for the contest, and if she observes 1, 2, or 3, her expected utility would be negative. Such a nonstrategic Alice would choose to play if she observed the first die is greater than or equal to 4 and would choose not to play for values less than 4. Clearly, the same would hold for Bob."
"4","If we stop our analysis here, the game would be played when both players have seen a roll of their die that causes them to think they are likely to win. However, these decision rules neglect an important aspect of the game and are therefore incomplete. Specifically, a strategic player must evaluate the effects of her opponent's information on the opponent's decision and incorporate those inferences into her own calculations. Consider Alice. If the contest is played in equilibrium, then it must be the case that it is “rational” for Bob to play. Therefore, in judging whether or not it is best response for Alice to play, she should consider the implications of Bob's strategy when he participates in the contest. Alice can then infer, by the above analysis, that even an unsophisticated Bob will not play if he observes that the second die is 3 or less. So, given Bob's strategy, Alice knows that the second die is at least a 4. But in that case, if Alice has observed that the first die is a 4, there is no chance of winning, because conditional on Bob agreeing to play, the best she can do is tie. Of course, by the same logic, Bob will not play if he observes the second die is a 4, because if Alice agrees to play, he can infer that the first die is greater than or equal to 4, and at best he will tie. Based on this analysis, then, Alice would only choose to play if the first die is a 5 or a 6, and Bob will also reach the same conclusion."
"5","Now, taking this line of reasoning one step forward, consider the case in which Alice, having made the above inference about Bob, observes the first die is a 5. Now knowing that Bob will only play if the second die is a 5 or 6, agreeing to play has negative expected utility! Likewise, Bob would choose not to play if he sees a 5. We are therefore left with the decision rules in which Alice only agrees to play if she sees a 6 and Bob only agrees if he sees a 6. But, as Alice and Bob can infer these decision rules, they know that if they both agree to play the result is sure to be a tie. However, because of the cost c, both players strictly prefer not playing to a tie, and therefore neither player will agree to play, regardless of how favorable their private information is. Thus, there cannot be a Bayesian‐Nash equilibrium in which the game is played because of differing beliefs that result from private information.         "
"6","Now consider what the intuition highlighted by this example reveals about mutual optimism between two adversaries. Suppose instead of Alice and Bob, we have two countries, East and West. Also, suppose that instead of looking at the roll of a die, the countries receive private information about the “quality” of their troops, the reliability of their allies, or some other relevant factor that directly affects their likelihood of winning a war. For East, a strong report would be equivalent to Alice seeing a high number on her die. Similarly, for West, a positive report about their troop quality would be like Bob seeing a high number on his die. In such a world, if East gets a good report (a high roll for Alice) and so does the West (a high roll for Bob), each side's expected utility from fighting might exceed that of the status quo, or some efficient settlement. Yet, like Alice and Bob, when East and West reflect upon what it means to fight an opponent who is going to resist, they must come to the same conclusion as Alice and Bob, namely that fighting cannot be a profitable alternative to peace. To summarize, the sequence of inferences described above reflects the fact that rational players in each example understand that it cannot be the case that both players expect to win in equilibrium."
"7","A typical story for how war might result from mutual optimism is as follows. Suppose the leaders of two countries have information about their military forces and tactics that their opponent does not. Moreover, suppose that this information influences each leader's assessment of their country's likelihood of success in combat. If both leaders then believe that their side possesses the “stronger” force, both sides may think they will prevail militarily and thus both leaders may choose to fight rather than pursue a peaceful settlement. In such an environment, the leaders' mutual sense of optimism could create a situation where there are no ex ante bargains both sides prefer to war, even though war is known to be ex post inefficient. The paradox is then that although rational leaders know that both sides cannot benefit from war at the same time, they still start wars that they would have preferred to avoid. In this section, we construct a game‐theoretic model and a corresponding framework for modeling knowledge that formalizes the idea of mutual optimism as a cause of war."
"8","Suppose two countries are facing a potential conflict. The dispute can be settled by war or resolved without armed conflict. To represent war as a mutual decision we assume that war only occurs if both countries decide to stand firm. We also assume that war is an inefficient method of settling disputes. In this construction, we focus on the private information that the countries may have about their ability to prevail in the event of war, their costs of fighting, and their expectations regarding the bargaining process. Initially, countries are uncertain about particular facets of the crisis situation, such as the balance of forces, technological differences, military strategy, latent resources of each side, support from allies, etc. The set of all such possible situations is denoted by Ω. An element of Ω is therefore a complete description of one possible situation and thus we refer to ω∈Ω as a (possible) state of the world. For simplicity, we assume Ω is a finite set. We may then ask, what do the two sides believe before they “know” anything about the true state of the world? If we assume that differences in people's beliefs about the state of the world are the product of private information, such as their personal background, confidential intelligence information, any inputs they may receive from advisors, etc., then it is logical to suppose all players share a “common prior.”5 Let the probability distribution π on Ω be this shared prior.            "
"9","The “information” in our model can be naturally classified into two categories. First, there is information that players agree will affect the two sides' respective likelihoods of success in the same way. For example, geography can favor one side, such as the advantage that being an island gave the British in the face of German attacks during World War II; it would indeed be strange to claim that the fact that Great Britain is an island was private information. Such commonly known information is described as “common knowledge.” The second type of information is private and only known to one side. This information could describe such aspects as troop quality, military strategy, and the plans of other countries in the international system. For example, the capabilities and tactics of German units on the eve of World War II would be an obvious source of private information for Germany. This private information would then generate differences in the two sides' respective assessments of the prewar likelihoods of success."
"10","To formalize this information structure we will need a model of knowledge.6 Generally, knowledge within a game is characterized by the ability of a player to distinguish between elemental states ω in Ω, as a player may possibly distinguish among decision nodes in an extensive form game. We are also interested in events, which are naturally defined as subsets of Ω. For example, if Ω={1, 2, 3, 4, 5} then E={1, 3} is an event. So here, events are related to information sets and describe a set of states consistent with the history of the game.            "
"11","To formalize what players know and when they know it, we use a possibility correspondencePi(ω) that maps every state ω to a nonempty set of states Pi(ω) ⊆Ω. For each ω∈Ω, Pi(ω) is interpreted as the collection of states that individual i thinks are possible when the true state is ω. Equivalently, a player's knowledge can be formalized by a knowledge correspondenceKi(E) ={ω:Pi(ω) ⊆ E}, where Ki(E) is the set of states where player i knows an event E has occurred, for sure. So i knows E at every state in Ki(E).            "
"12","As can be seen by the relationship between Ki and Pi, a player's knowledge can be discussed in terms of Pi or Ki. For example, let Ω={1, 2, 3, 4, 5} and let player i's knowledge be represented by Pi(ω) taking on the following values:               "
"13","Notice that in the preceding example, the two sets {1, 3} and {2, 4, 5} form a partition of Ω. It is typically the case that the structure of a player's knowledge is represented by a collection of disjoint and exhaustive subsets of Ω, called a partition.            "
"14","Definition 1  A possibility correspondence                                       P                     i                        (ω)                  forΩis partitional if there is a partition ofΩsuch that for everyω∈Ωthe setPi(ω)is the element of the partition that containsω.               "
"15","If Pi is a partition and if ω and ω′ are two states in Ω, then when ω and ω′ are in the same element of the partition, the decision maker cannot tell the difference between them. However, if ω and ω′ are not in the same element of the partition, the decision maker can tell the two states apart.               "
"16","At this point we place restrictions on Pi to represent the types of properties, or axioms, we desire in the processing of information by players.               "
"17","Definition 2  Let                                       P                     i                                          be a possibility correspondence for individual                  i. We say"
"18","                                    "
"19","                               P                              i                                                            is nondeluded                           if, for all                           ω∈Ω, ω∈Pi(ω),                         "
"20"," a player                           i                           knows that she knows                           if, for every                           ω′∈Pi(ω), Pi(ω′) ⊆Pi(ω),                         "
"21"," a player                           i                           knows that she doesn't know                           if, for every                           ω∈Ω                           and every                           ω′∈Pi(ω), Pi(ω′) ⊇Pi(ω).                         "
"22","These three properties are used to formalize the idea of rationality in knowledge. The first condition requires that a rational person always considers the true state of the world to be possible. The second condition requires that if any state an individual thinks is possible at the current state of the world were the true state, she would know at least her current knowledge, Pi(ω). That is, Pi(ω) cannot occur without the individual knowing that she knows it has occurred. Formally, this implies that if Ki(E) is the event that i knows E, then Ki(Ki(E)) ⊆Ki(E). The final condition requires that players also know what they don't know, i.e., . These three conditions ensure that Pi(ω) is consistent and that a player's possibility correspondence represents all that is knowable at each state.               "
"23","To see an example of how rationality is related to the conditions of definition 2, let us consider a possibility correspondence that does not satisfy all three conditions. It is then easy to see why such a correspondence does not represent all that a rational player could know at a given state of the world, ω. Suppose that there are five states of the world, Ω={1, 2, 3, 4, 5}. Since a rational model should never have players place zero probability on the true state of the world, let us consider a correspondence Pi(ω) that satisfies nondeluded, but not know that you know and know that you don't know. In particular, let                  "
"24","Now suppose that ω= 2; what could a rational player conclude? From Pi(2) the player knows that the true state of the world is 1, 2, or 3. But player i also knows that the state is not 1, because if the state were 1 she would know that the state was not 3. So i can deduce that the true state is either 2 or 3. Moreover, if ω= 3, i would know that the other possible states would be 2, 3, 4, but since she knows ω≠ 4, ω cannot be 3. Therefore, i can deduce that the true state is 2, and a rational player knows more than what is described by Pi(ω).               "
"25","In fact, we can justify the use of partitional possibility correspondences in a model with rational actors because it is easy, if somewhat tedious, to show that Pi satisfies nondeluded, know what you know, and know what you don't know if and only if it is partitional. That is, a partitional possibility correspondence is the only internally consistent representation of a player's knowledge and, therefore, represents all that can be known by a rational decision maker at a given state of the world.7"
"26","Now to use this model of knowledge in equilibrium analysis, we also need to be able to say something about what players know about what others know, what those others know that they know, etc. This is accomplished by considering events that are common knowledge. The concept of common knowledge was first explicitly described by Lewis (1969), and was later formalized by Aumann (1976) in terms of the meet of the information partitions for all the players at a state ω. Informally, an event F is common knowledge between players i and j, in state ω, if and only if ω is a member of every set in an infinite series such that player i knows F, player j knows F, player i knows player j knows F, player j knows player i knows player j knows F, etc.               "
"27","Like common knowledge events, another important class of events is the self‐evident event.               "
"28","Definition 3  An event                  E                  is self‐evident for a possibility correspondence                                       P                     i                                          if and only if for all                  ω∈E, Pi(ω) ⊆E.                "
"29","In other words, an event E is self‐evident if, for any state in E, a player knows E has occurred. Returning to our previous example where Ω={1, 2, 3, 4, 5} and Pi(ω) induces a partition on Ω of {{1, 3}, {2, 4, 5}}, the event {1, 3} is self‐evident, but {1, 2, 3} is not. The following useful fact is immediate. If Pi is nondeluded, then for a self‐evident event E,                  "
"30","Lemma 1  Suppose                                       P                     i                                          is nondeluded for all                  i. An eventFis common knowledge at a stateωif and only if there is anωand a self‐evident eventEsuch thatω∈E⊆Ffor allPi.               "
"31","We are often also interested in “public” events. A public event, unlike a private signal, is known to all players when it happens.8 Formally, we define a public event as follows:               "
"32","Definition 4  An event                  E                  is a                  public event                  if and only if, for all                  i, Ki(E) =E.               "
"33","Note that a public event is self‐evident to all players; this equivalence is given in the following lemma."
"34","Lemma 2  If                  E                  is a public event, then for all                                       i, E                  is self‐evident.                "
"35","Proof By definition of a public event Ki(E) ={ω∈Ω | Pi(ω) ⊆E}=E for all i. Therefore, for all ω∈E, Pi(ω) ⊆Ki(E) =E and E is self‐evident.               "
"36","Now that we have specified a model of knowledge, we can talk about knowledge at a given state of the world and the decision to go to war."
"37","Recalling that the state of the world is directly relevant to the question of which country will win a war, we define two functions, p1(ω) and p2(ω), that specify the probability that country 1 and 2 will win a war, given the true state of the world ω. Of course, p1(ω) +p2(ω) = 1 and 0 ≤pi(ω) ≤ 1 for all values ω∈Ω. Consider an arbitrary event E. If a country knows an event E⊆Ω has occurred, it can combine this information with the prior π via Bayes's Rule to form a posterior belief about the value of pi as follows:                  "
"38","It is equally likely that the negotiated settlement will depend on the underlying state of the world. We now define two additional functions, r1(ω) and r2(ω), that specify the bargaining outcome when the true state of the world is ω. Since bargaining is efficient, we assume that in each state r1(ω) +r2(ω) = 1. It is then immediate that countries' beliefs regarding the outcome of the bargaining process will depend on their private information as well.               "
"39","We represent the private information of country i by a possibility correspondence Pi : Ω→ 2Ω, which we assume is partitional. Recall that Pi(ω) is the set of states that country i views as possible, given the true state ω. Given a true state ω, a country can combine its knowledge of Pi(ω) with the prior π and equation (1) to construct its posterior belief about the probability it will win, , and its expected payoff from bargaining, . It is important to note that without additional assumptions or structure, it is certainly possible that  or  for some state ω. In this setting, mutual optimism occurs when  and .               "
"40","In the rest of this section, we place the preceding informational assumptions in the context of a game and show that, in equilibrium, countries cannot have mutual optimism and therefore, war cannot occur as a result. Because the information structure is quite general and can capture many aspects of the strategic interaction, the description of the game is abstract."
"41","Denote the set of actions for country i in some two‐player strategic form game by Ai, with elements {a1i, … , aki}. Depending on the choice of actions by both countries, the outcome of the game is either war or settlement. The expected payoff to war depends on the probability that a country will win, the utility of victory and defeat, and the inefficiencies present in fighting. We normalize the utility of countries to be 1 for victory in war and 0 for defeat, and we suppose there is a cost ci(ω) > 0 of fighting a war for country i. Thus the expected utility for country i of going to war is simply , where . On the other hand, the negotiation process provides an expected utility  for country 1 and  for country 2. It is important to note that we assume that neither the expected payoff to war or the expected outcome of negotiations depends on the choice of actions by the countries. That is, we exclude the possibility of gaining an advantage by surprise attack or making threats in order to gain bargaining leverage.9 However, we are completely general about how negotiations actually proceed and permit the outcome of the negotiation stage to depend on the private information of the two countries. In fact, the revelation principle tells us that any equilibrium of any choice of game for the negotiation stage can be mimicked by a mapping that takes states of the world into outcomes (Myerson 1979). This is because a game is defined as a mapping from players' negotiation choices into outcomes and a strategy is defined as a mapping of player types into choices, so without loss of generality we can define a new mapping, r(ω), that is a composition of the game form mapping and the strategy mapping. This new mapping takes states of the world into outcomes in the exact same way as an equilibrium to the underlying game. Our setup, therefore, lets us consider any distribution of the prize that countries may expect to get in the bargaining game that is an alternative to war. Our bargaining protocol is consistent with previous work, like Powell (1999), that argues a peaceful settlement should be an equilibrium to a bargaining game and should represent, through that equilibrium, the underlying balance of power as captured by the state of the world. By construction, r(ω) covers both conditions.               "
"42","To focus on the mutual optimism explanation of war, we assume that both countries must choose to “stand firm” for war to occur. Formally, this condition requires that for each country i, there is an action  such that, conditional on the opponent choosing to “stand firm,” the outcome is a settlement. In practice, if one country chooses to stand firm, the other country can stop a war by inducing the bargaining procedure instead. That is, war is an act of mutual consent and, by construction, also mutual optimism. As we have already discussed, if we drop this assumption and allow any single state to cause a war, the concept of war by mutual optimism loses meaning. Put simply, it is hard to understand what is mutual about mutual optimism if only one side's expectations enter into the decision to fight. Moreover, Fey and Ramsay (2007a) show that in certain cases, if a single country can start a war, it is impossible to write down any game form that guarantees peaceful outcomes.               "
"43","We now define strategies for each country. We reflect the fact that countries can condition their choice of action on their private information by defining a (pure strategy) strategy si∈Si as a function si : Ω→Ai with the restriction that                  "
"44","Lastly, we discuss the event war. It follows from Lemma 2 that if the outcome of the game is a publicly observable war, then war is common knowledge whenever it occurs. Since strategies associate states with outcomes, we can now offer a rigorous definition of the statement that war is a public event given our information model. For a strategy profile (s1, s2), let F be the set of states for which the outcome of the game is war. It follows that if war is publicly observable (for (s1, s2)), then the event F is a public event. If the event F is nonempty for a strategy profile (s1, s2), we say that (s1, s2) is a strategy profile in which war occurs.               "
"45","Let G denote any strategic form game of incomplete information that satisfies the preceding assumptions on information structure, payoffs, and strategies. We are now prepared to state our main result.10"
"46","Theorem 1  Suppose countries have a common prior, war is a public event, and                                       P                     i                                          is partitional for                                       i= 1, 2. Then there is no Bayesian‐Nash equilibrium ofGin which war occurs."
"47","Proof Suppose not. That is, suppose that the strategy profile (s*1, s*2) is a Bayesian‐Nash equilibrium in which war occurs. At state ω, war has an expected payoff to country i of . By choosing action , though, country i can ensure itself a payoff of . Define the following two events:                  "
"48","Since we assume war is a public event, the event W is a public event. By Lemma 2, W is self‐evident to 1 and 2, and therefore                  "
"49","This theorem shows that there cannot be an equilibrium in which both sides think they are better off fighting, and as a result, go to war. The intuition underlying this theorem is as follows. Each country knows that the other is optimizing in equilibrium, knows when a war occurs, and can deduce from the set of states and the prior probability the associated costs and benefits of each action for their opponent. Each player therefore knows that her opponent is willing to fight only in states where she is “likely to lose.” Knowing this, each player should condition her decision on this fact. As a result, the conjecture that the players' strategies form an equilibrium where war is a public event would unravel just as in the dice game between Alice and Bob discussed above.11 So the fact that wars are public events is inconsistent with inconsistent beliefs, even if leaders have private information about the likely outcome of conflict.               "
"50","We conclude this section with some additional remarks regarding the theorem. First, our result does not require that bargaining be costless, but rather that fighting a war is more costly. This is because in any world where bargaining is costly, but less costly than war, we can always normalize the settlement outcome and think of the cost of war as the relative loss from fighting. Second, we note that Wittman's (1979) classic mutual optimism argument is subsumed by a special case of Theorem 1. In particular, when r1(ω) =r and r2(ω) = 1 −r for all ω, we see that for any r∈[0, 1] there cannot be war by mutual optimism. That is, it would be false to conclude that mutual optimism can create a situation where countries can find no agreement that would dissuade at least one country from wanting to fight in equilibrium. In fact, Theorem 1 implies any efficient division will do. Our result, however, is significantly stronger than this. Theorem 1 shows that there are no “optimistic” beliefs that allow a public war to be preferred to a peaceful settlement in equilibrium even when the probability of success in war and the value of a negotiated settlement are arbitrary functions that may depend on the state of the world. Moreover, as the mappings r1(ω) and r2(ω) can represent any equilibrium of any bargaining game one could imagine, our results do not depend on the extensive form of the negotiation phase reached after some country has opted for negotiations. Third, one may wonder how our assumption that the game is in strategic form influences the generality of our theorem. The answer stems from the fact that the only requirements on the possibility correspondences of the two sides are that they be partitional and that war is a public event. As a result, the players' information may differ in a number of ways. One way it may differ is that one leader may know whether the other has chosen to stand firm or negotiate when making her decision. That is, our result applies equally to decisions made simultaneously and sequentially.12 Finally, our assumption that war is a public event is used in the proof to show that the event W is a public event. For ω*∈W, by Lemma 1, this event is common knowledge at ω*. So another way to state the conclusion of the theorem is that if war is common knowledge when it occurs, it cannot occur because of mutual optimism.               "
"51","While Theorem 1 is true for any mutual optimism game in which the decision makers rationally process information, one may wonder if the results depend on strictly rational learning. Can mutual optimism result in war if otherwise rational agents suffer from pathological misperception? In this section, we consider a class of games where, again, two countries are choosing whether to fight a war or resolve the dispute by some other means. Here, we show that even if players' information processing suffers from cognitive biases, war still may not be possible in an equilibrium of a mutual optimism game. In particular, even if both players ignore “bad news” or are inattentive, then war cannot occur because of mutual optimism."
"52","When it comes to information processing, a rational Bayesian may be able to deduce much more information from a “signal” than the signal carries at face value. For example, consider a world where there are two possible states, {a, b}. Suppose that when the true state is a it is brought to the player's attention that the state is in fact a. However, when the true state is b nothing is brought to the player's attention. In this situation a rational Bayesian can always deduce the true state of the world. When the state is a, the player is informed of that fact and knows it is a. When the state is b, the player knows that if the state were a she would have been told, but since she was not, the state must be b. The rational Bayesian, like Sherlock Holmes, learns from the dog that does not bark.            "
"53","There are, however, many cases in which we think that decision makers, particularly the leaders of countries, may not be processing information rationally. Consider the information processing errors found in the psychological international relations literature (Jervis 1976; Jervis, Lebow, and Stein 1985). For example, decision makers who have many responsibilities may face a volume of information that induces flaws in their learning. In particular, such decision makers may not update their beliefs when the state of the world is not explicitly brought to their attention. So while they may learn that the state is a when there is an explicit signal to indicate that is so, they may not deduce that the state must be b in the absence of a signal that the state is a. This error may occur because of a flaw in human psychology or it could be an information shortcut that allows decision makers to deal with a world far more complex than the two state example above.            "
"54","Alternatively, due to what Jervis, Lebow, and Stein (1985, 4) call motivated bias, a player's knowledge may be partly a matter of choice. So given that some people have strong predispositions to believe certain things to be true, this may prevent them from recognizing new information inconsistent with their worldview. That is, sometimes decision makers may consciously, or subconsciously, choose to ignore unpleasant information.            "
"55","Next we consider a game with players whose information processing is flawed in ways consistent with the learning processes described above. A common component of these cognitive biases is that the players' information processing allows them to learn from new information in some states of the world, but not in others. To capture this idea formally, we define a new restriction on the players' possibility correspondences, Pi. In particular, while we still assume Pi is nondeluded, we now allow players to “ignore” or “throw out” information at a given state of the world that would be known to a fully rational Bayesian. To allow such pathologies, we must allow for the possibility that some information sets are nested within, or subsets of, other information sets. That way we can capture the idea that inattentive decision makers do not deduce that the state of the world is a by lack of a signal that it is a or that decision makers might choose to ignore the deeper implications of the information in front of them. To do this, we replace the know that you don't know and the know that you know conditions with the requirement that the players' possibility correspondences are nested.13"
"56","Definition 5  A player's possibility correspondence is                  nested                  if for all                  ω, ω′∈Ω, either (1)Pi(ω) ∩Pi(ω′) =∅or (2)Pi(ω) ⊆Pi(ω′)or (3)Pi(ω′) ⊆Pi(ω).               "
"57","Possibility correspondences that satisfy nondeluded and nestedness represent a generalization of rational learning. That is, a decision maker with a nested possibility correspondence may process information in a rational way or she may ignore new information at a number of different states. Such a formalization is consistent with many forms of bias, because it is agnostic to the reason information is ignored. Players could fail to learn in some states because acquiring information is costly, because they are inattentive, or because they would rather not think about the implications of the information in front of them."
"58","As we have seen, a useful approach to model the limitations of a player's ability to process information is to consider a player's information partition that satisfies nondeluded and nested. Together, these conditions are weaker than the three conditions for a rational partition, yet are still sufficient to exclude optimistic war. In general, we now have:"
"59","Theorem 2  Suppose countries have a common prior, war is a public event, and                                       P                     i                                          is nondeluded and nested for                                       i= 1, 2. Then there is no Bayesian‐Nash equilibrium ofGin which war occurs."
"60","Proof: Suppose not. That is, suppose that (s*1, s*2) is a Nash equilibrium in which war occurs with a generalized information partition that satisfies nondeluded and nestedness.               "
"61","As in Theorem 1, define the following two events:                   "
"62","Since we assume war is a public event, the event W is a public event. By Lemma 2, and the fact that a self‐evident evident is well defined for any nondeluded possibility correspondence, W is self‐evident to 1 and 2, and therefore                  "
"63","Let  be the set with the largest cardinality such that ω∈Pi(ω′) for some ω′∈W. By nestedness  is unique and  for all ω∈W. Because W is self‐evident,                  "
"64","Theorem 2 shows that for some plausible types of “boundedly rational” actors, mutual optimism cannot be the reason two decision makers go to war. In the appendix, we give two examples that show that the conditions in Theorem 2 cannot be relaxed. That is, for the impossibility of war by mutual optimism, nondeluded and nested are minimally sufficient or “tight” conditions. In particular, we show that if either condition in the theorem fails, then there exist examples of mutual optimism games in which both countries choose to fight in equilibrium because of their private information.               "
"65","As mentioned above, considering information structures that relax the requirements of strict Bayesian rationality can help us understand just how general our mutual optimism result is. On the one hand, the analysis in this section shows that the mutual optimism result is not fragile. Clearly, some departure from rational Bayesian learning is acceptable and consistent with our results. In particular, if decision makers sometimes ignore unpleasant information or behave as if they have imperfect memory, then our result survives. On the other hand, the fact that Theorem 2 also contains the minimally sufficient conditions for our result to hold means that our analysis gives criteria by which one can determine the minimum level of rationality needed to rule out war by mutual optimism."
"66","It should be clear by now that the common priors assumption, while standard, plays a critical role in our analysis.14 Indeed, if we permit countries to hold different prior beliefs that are not explained by information, then it may be possible to find pairs of prior beliefs that result in war as an equilibrium outcome in our setting.            "
"67","In this section, prompted by Smith and Stam (2004) who explore a model where players do not have common priors and demonstrate that one possible consequence is war, we investigate what our results imply regarding the possibility of war by mutual optimism in an environment with noncommon priors. We show that there is an equivalence between common‐prior models with boundedly rational players and models with noncommon priors and fully rational players. In fact, we show that our analysis implies a set of conditions on the “noncommonness” of priors required to result in war by mutual optimism.            "
"68","Specifically, we give two propositions that identify the direct connection between games in which countries have a common prior and are boundedly rational in processing of information and games where countries have noncommon priors. The two propositions show that the characterization of minimally sufficient conditions on decision makers' information structures described in Theorem 2 has direct analogs in the noncommon priors framework. That is, our characterization of constraints on the possibility correspondences of decision makers implies bounds on the noncommon priors that can be held by rational Bayesians in an analogous noncommon priors model.15"
"69","To begin, we need to define a notion of strategic equivalence between any two games."
"70","Definition 6  A game                  is strategically equivalent to a game                  if there is an onto function                  ϕ: Ω′→Ω                  such that for every state                  ω′∈Ω′,                  "
"71","For our first proposition, we consider a game with nonpartitional information and show that there exists a strategically equivalent analogue in the noncommon priors framework."
"72","Proposition 1  For any finite game                  with nonpartitional information structure and a common prior, there exists a game                  that has a common state space                  Ω′, noncommon priorsΠ={π1, π2}, utility functionsu′, anda partitional information structure, and is strategically equivalent toG.               "
"73","Proof Let G be a game with state space Ω, a common prior π, action space A={A1, A2}, a utility function for each player , and a nonpartitional information structure.               "
"74","Let  and let . An element of Ω′ is given by ω′= (R1, R2, ω) and let . By construction, these Pi′ partition Ω′ for both players. Let ϕ :Ω′→Ω be an onto function such that ϕ(R1, R2, ω) =ω.               "
"75","Next define the noncommon prior                   "
"76","Our second proposition is a converse of the first. That is, we consider a game with noncommon priors and partitional information and show that there exists a strategically equivalent game with common priors and a generalized information structure."
"77","Proposition 2  For any finite game                  with a partitional information structure and a noncommon prior                  (Π={π1, π2}), there exists a gamethat has a common state space, a common prior, utility functions, and a nonpartitional information structure, and is strategically equivalent toG.               "
"78","proof  Proof:  Let G be a game with state space Ω, noncommon priors πi, action space A={A1, A2}, a utility function for each player , and a partitional information structure.               "
"79","Let  and define a function  such that ϕ(ω, k) =ω. Let player i's possibility correspondence be                  "
"80","These two propositions show that the approach taken in this article that explores boundedly rational information processing with common priors is strategically equivalent to an approach where information is processed rationally, but decision makers have noncommon priors. The real difference between these two approaches is then largely one of taste. In the noncommon priors framework, it is assumed that for reasons not related to private information or the way it is processed, decision makers “enter the game” with different beliefs. The generalized information structure approach, on the other hand, assumes that differences in beliefs are the consequence of private information and the way that information is processed. As a result, Theorem 2 gives a characterization of sufficient conditions for our optimism result to hold and a substantive interpretation of the limits in the rational decision process necessary for the result to fail. The noncommon priors framework can provide—it turns out—analytically equivalent conditions for the failure of our result, but does not provide a theoretical mechanism for its origin. In light of this fact, we prefer the generalized partition approach, but point out that, formally, the two perspectives are equivalent."
"81","Formalizing the mutual optimism hypothesis and using assumptions designed to test this hypothesis, we see that if war is a public event when it happens, it cannot occur between rational opponents because of mutual optimism. Moreover, when we consider some intuitive forms of “bounded rationality” in the way players learn, the result is robust. This result is somewhat surprising, given the existing work on the subject. In this section we discuss some specific aspects of our model as well as its implications and limitations for the study of international conflict."
"82","Mutual optimism is one of several ways that private information can lead to war. Our approach in this article is designed to serve as a test of mutual optimism as a valid explanation of war in a game‐theoretic rationalist framework. As we have argued, in order to isolate mutual optimism as a cause of war, we must ensure that when mutual optimism is not present, war does not occur. Otherwise, we cannot be sure if it is mutual optimism or some other aspect of private information that explains the conflict. Our game‐theoretic setting is thus designed to create conditions in which there is a clear link between mutual optimism and war."
"83","The reasoning behind our modeling choices also helps us to understand why mutual optimism is not a valid rationalist explanation for war, even though others have argued that it is. Intuitively, the mutual optimism explanation requires that, when the war starts, both sides believe they will prevail. Another way to say this is it must be that neither side prefers to settle rather than go to war. Clearly, if, in a model, an equilibrium (with war) exists in which one side wants to settle but is not able to, then this war was not caused by mutual optimism. Thus, war can be validated as a consequence of mutual optimism only in a model in which an equilibrium with war exists even though either side can deviate to negotiate some settlement. This is precisely what our main assumptions imply.16"
"84","Taken together, our assumptions are based on the idea that mutual optimism, as a cause of war, is a distinct mechanism and is, in fact, different from rationalist explanations for war that focus on the preferences players have over actions that risk war, but have higher peaceful payoffs, and “sure things” that guarantee peace at a price. To illuminate more precisely what is and is not covered by our result on mutual optimism, it is useful to consider a simple bargaining model in which war is possible. Suppose there are two countries A and B. Country A is uncertain about the type of country B, which is either weak or tough. In the first stage, A makes a low demand or a high demand and in the second stage, B either accepts the demand or rejects it, in which case war results. Suppose a weak type of country B will lose a war with high probability and a tough type will win with high probability. In this model, it is straightforward to find parameters such that both types of B will accept the low demand but, in equilibrium, A makes a high demand that will be accepted by the weak type but rejected by the tough type. Therefore, war is a possible outcome of this equilibrium. Intuitively, the first mover in this “risk‐reward” equilibrium knows that with some probability she will face a tough type and be likely to lose, but that this risk is offset by the reward of achieving a valuable concession from a weak type. Thus, war arises because there is no way for A to react to the private information of B.         "
"85","This sort of model is informative about the nature of optimal demands in the shadow of war. Yet, the occurrence of war in this model is related not just to the assumptions concerning the countries' information, but also the nature of the bargaining process. In this kind of model, the fact that war occurs is a consequence of the commitment value of country A's initial offer. It is not obvious that such a commitment to an initial demand is either reasonable or realistic. Moreover, the structure of the interaction implicitly assumes that all the bargaining power lies with country A. As shown by Leventoglu and Tarar (2006), however, if we relax the assumption that country A has all the bargaining power, then reasonable equilibria exist in which sufficiently patient players do not behave in the way suggested by our simple example.17"
"86","For our purposes, however, what is important in this simple example is that it is not the case that both sides believe they will prevail. In particular, at the terminal node in which war occurs on the equilibrium path, A can infer from the rejection of its demand that B is the tough type and will revise its belief about its probability of winning downwards. It is easy to show that after this updating, A would prefer to settle rather than go to war, but this option is not available at this point in the game. Thus, it is clear that this example of war does not satisfy our definition of mutual optimism that, at the instant before the war starts, both sides believe they will prevail.         "
"87","As we show in a companion paper (Fey and Ramsay 2007b), this is a specific instance of a general phenomenon. Namely, in a large class of games including games in which war is a unilateral act rather than a mutual act, there will always be states of the world in which war occurs but one of the two sides does not believe it will prevail. In fact, if the correct model of war is one in which any single country can start a war, the presence or absence of mutual optimism is irrelevant and, therefore, not a coherent rationalist explanation of war.         "
"88","Reflecting on this example, we can give an intuitive statement of our main result in the following way. If it is common knowledge that countries are going to fight, and these countries have a “hot line” available, then at least one side will always want to make a call and a proposal that will be accepted and avoid the war. That is, our result applies to a situation where countries can discuss war before making it, but after a proposal has been made and rejected. In situations where a firm offer is made that, if rejected, leads to certain war, equilibria with war can exist, but not because of mutual optimism; one side would prefer to settle but is locked into a war by the structure of the extensive form.18"
"89","Another important assumption in our model is that the settlement outcome does not depend on how the negotiation stage is reached. That is, while we assume that the underlying state of the world and the players' information about that state are important for determining the outcome of the negotiated settlement, that outcome does not depend on which of the players pursued the peaceful settlement instead of a war. Once again, it is important to emphasize that we make this assumption in order to guarantee that the sole cause of war in our model is mutual optimism and not some alternative cause. The following simple example of a game that does not satisfy this assumption (but does satisfy all other assumptions of our model) will illustrate this point. In this example, there is complete information and therefore no possibility of mutual optimism, and yet war is the unique equilibrium outcome. 19 Suppose each side is equally likely to win a war, the cost of war is not too large (c < 1/2), and both sides simultaneously choose whether to stand firm or negotiate. If both sides choose to stand firm, war results with payoff 1/2 −c; otherwise a negotiated settlement results, the payoffs of which depend on the actions. If both sides choose negotiations, they both receive payoff 1/2, and otherwise the settlement gives payoff 1 to the country that stands firm and 0 to the country that chooses negotiations. In this game, it is easy to see that war is the unique Nash equilibrium outcome as both sides have a strictly dominant strategy to stand firm. 20 It is just as easy to see that such a war has nothing to do with mutual optimism. In this example, war occurs because the structure of the settlement payoffs gives each side an incentive to take an aggressive posture in choosing actions, but these aggressive actions have nothing to do with any underlying uncertainty. While it is possible that, in the real world, strategic situations such as these may arise, and as a result wars may occur, the cause of such a war is not mutual optimism. Put another way, the mutual optimism explanation for war is a purely informational story and is not a story about “capitulation” or posturing or bargaining concessions. Our assumption about the settlement outcome serves to ensure that these other causes of war are not present in our model so that we can focus on the explanatory power of the mutual optimism explanation.21"
"90","Finally, we should comment on two of the assumptions we make about our informational structure: that the information partitions are themselves common knowledge, and that the players share a common prior over the states of the world. The first assumption is easily justified by the fact that war is clearly a public event, and thus its occurrence is commonly known. The second assumption has been addressed above. As we have argued, the common prior assumption makes explicit how differences in beliefs are grounded in differences in information. For this reason, we prefer to start with common priors and consider generalized information structures. Nevertheless, Propositions 1 and 2 demonstrate that the generalized partitions approach and the noncommon priors approach are analytically equivalent and the choice of which direction to push when departing from traditional rationality assumptions is largely a matter of taste. What is settled by our results, however, is the set of constraints—interpreted in the generalized information structure or in the noncommon priors world—that qualify our result concerning mutual optimism. It should not be surprising that as we allow our decision makers to become “less rational,” our optimism result eventually breaks down. What is more surprising, however, is how far we can go down that road before the optimism result fails."
"91","In sum, the results of our model are general, but not universal. Our results are not universal in the sense that we only address the use of mutual optimism as an explanation of war and have little to say about other mechanisms by which war occurs or other distinct rationalist explanations for war. However, our results are general in that the assumptions underlying the model are not heroic; the construction is consistent with, and even subsumes, arguments found in the informal and decision theoretic literature on mutual optimism and war; and our results hold for a number of different game forms and less‐than‐rational players."
"92","We have established two main findings by formalizing the argument that countries fight wars due to mutual optimism. First, if war is a public event among rational actors, war cannot occur because of mutual optimism. Second, relaxing the conditions in our model of knowledge shows that this result is robust to imperfect, or “boundedly rational,” learning. We have also shown that there is a formal equivalence between our bounded rationality approach to learning and the approach to modeling disagreement that assumes subjective (noncommon) priors. These claims are based on our demonstration that, for a general class of games where states contemplate war, there are no Bayesian‐Nash equilibria with war as an outcome. This analysis also helps explain why models with private information appear to show that mutual optimism leads to war. There are other ways in which private information can cause war, other than mutual optimism. In order to eliminate these other causes, we impose our assumptions which serve to ensure that in cases without mutual optimism, war cannot arise in equilibrium. In this way, our result that war cannot occur in equilibrium implies that mutual optimism is not a valid rationalist explanation for war."
"93","The modeling approach taken in our analysis is consistent with a broader research program that looks to explain the occurrence of inefficient wars from a rational choice perspective. Clearly, such a framework already limits the set of theoretically consistent explanations for the causes of war. The theoretical landscape, however, is still dotted with many theories of war initiation that can rightly be called rationalist explanations for war. Our result shows that one prominent explanation, war by mutual optimism, is not a coherent and internally consistent theory of war within the rationalist framework. Alternatively, our analysis leaves open many other rationalist explanations as possible avenues for further research. In particular, explanations for war that depend on the inability of countries to commit to agreements as there are shifts in the distribution of power, the indivisibility of disputed prizes, and incomplete information mechanisms that are not associated with mutual optimism, are all viable rationalist explanations and should continue to be a focus of theoretical and empirical research."
"94","To the extent that our theoretical results have empirical content, they ask us to reconsider some narratives describing the onset of war, such as those presenting stylized facts surrounding the start of World War I, and to reinterpret the competing historical accounts in light of the internal inconsistency of the mutual optimism argument. Was the key mechanism causing these wars the onset of mutual optimism among groups of otherwise rational decision makers? Should we believe that decision makers in Germany were optimistic concerning the outcome of a war with France and Russia? Or should we believe, as Moltke wrote, that the prospect of a conflict with Russia in a year or two left “… no alternative but to fight a preventative war so as to beat the enemy while we [Germany] could still emerge fairly well from the struggle”(Wohlforth 1987, 362) and thus understand the war as prompted by commitment problems, rather than mutual optimism? In the presence of multiple viable explanations for war, each with supporting historical evidence, we would suggest that those explanations which are consistent, given their overarching framework, should be given precedent over those that are incoherent. By this criteria our results suggest that, when it comes to mutual optimism, we should look elsewhere for our causes of war.         "
