"","x"
"1","The workhorse quantitative method in political science is regression analysis. By its very nature, the regression model is an attempt to represent complex parts of the world in a highly parsimonious way by taking a number of dimensions (i.e., a set of explanatory variables) and reducing them to one (i.e., the dependent variable). Some historians reject the notion that the world can be expressed usefully in terms of such simple relationships. This criticism applies not just to dimensionality reduction but also to the direction of causality, as it is difficult for historians to accept that there are variables that are truly exogenous to others."
"2","Although social scientists have recently paid a good deal more attention to unearthing more persuasive and powerful instrumental variables to address endogeneity and identify causal effects (Angrist and Pischke 2009), our focus here is on the substantial progress that can be made by augmenting standard models with techniques that have only recently come to the attention of political scientists. These techniques work within the framework of the regression model in ways that satisfy a desire for parsimony while incorporating features historians see as crucial to representing historical events and development.         "
"3","A key feature of this alternative approach is to posit more general models than are commonly employed and to rely more heavily on the data to tell us about the complexity of the model's structure. While historians often feel uncomfortable with the restrictive confines of a regression model, at some level these kinds of restrictions are unavoidable. But we can incorporate more flexibility by having researchers impose less a priori structure on the phenomena under investigation."
"4","The main reason that standard regression models are poorly equipped to address concerns about context, specificity, temporality, and periodicity is that they typically treat parameters as nonvarying over long stretches of history. Understanding events may require grouping them into particular phases or epochs despite perpetual uncertainty about the nature of the periodization and the multiplicity of plausible ways to divide historical time and context. It is not uncommon for political scientists to estimate a regression model over decades, even centuries, where the relationships among variables are treated as constant over the entire time span of the data.2 In doing so, such studies assume away a significant amount of complexity in the development and evolution of historical processes. While such simple models are consistent with the desire to derive and test general theories, they raise an alarm for scholars who doubt the tremendous—perhaps excessive—determinism that such models imply. While statistically significant relationships stemming from large sample sizes may give us confidence that we have discovered a grand and fundamental pattern of behavior or an institutional truth, such models tend to impose far too much structure on data, concealing important nuances and thereby providing unsatisfying and perhaps even misleading accounts. We may draw the wrong inferences about historical processes if the relationship between variables is nonexistent in certain periods but is exceptionally strong for others.         "
"5","Parameter variation offers a potentially powerful solution by permitting the effects of explanatory variables to change and evolve along dimensions that are thought to be important. For historical analysis, time is generally the most important dimension. For some research questions, we are interested in the values of parameters before and after some watershed event—a structural break or critical juncture. In other instances, we are interested in how parameters might change gradually but decidedly over time. In either case, the estimation approach that we use must allow parameters on variables of interest to change temporally and contextually, even as the values of those variables may be changing over time and with context. Note that we are not arguing that political scientists should forsake parsimony in their desire to incorporate complexity. We are sympathetic to arguments that more explanatory variables do not necessarily lead to better models or more thorough analysis. Yet a small number of variables with varying parameters over time can accomplish a remarkably nuanced account that is appropriately sensitive to historical complexity."
"6","Suppose we want to analyze annual data over a broad swath of history. Time‐series analysis of the kind typically conducted in political science would likely estimate one coefficient value for a given explanatory variable for the entire series. Flexibility of the kind historians believe to be essential can be introduced by letting that coefficient vary over the series. But letting parameters be different for each observational unit in the series (i.e., each year) is not desirable either. Such a move makes it impossible for a univariate time series to identify annual coefficients, since it would yield as much, or more, parameter variation as variation in the data. Nor would this degree of parameter variation always be preferable, since it may very well leave us with results that are not useful for hypothesis testing and making general inferential claims."
"7","Yet it is possible to locate an attractive middle ground, especially if we have data variation along another dimension beside time. A key concern is that as the number of parameters that we are estimating increases, it becomes harder to estimate them with satisfactory precision, since less data are being brought to bear on the estimation of each parameter (see Bartels 1996). We might mistakenly infer variation in the relationships among variables simply because we are unable to obtain very precise estimates of parameters. Estimation strategies that are data dependent in terms of establishing more of the structure of models need to strike a balance between the amount of information that is used to identify varying parameters from the data and the amount of structure imposed by the researcher. What would be helpful practically and theoretically is to allow coefficients in a regression model to vary while linking them together in ways that are sensitive to temporality, periodicity, specificity, and context. We suggest that historically oriented political scientists could employ two sets of methods to accomplish this effectively: structured additive regression models and flexible methods for modeling structural change. While other potentially useful methods certainly exist, we think these two sets of approaches are particularly powerful for addressing the concerns discussed in the previous section.         "
"8","Structured additive regression (STAR) models extend generalized additive models by incorporating flexible nonparametric functions of covariates that can account for nonlinear effects and build in complexities in relationships among variables that are not possible in standard regression models (Fahrmeir and Tutz 2001; Hastie and Tibshirani 1990). STAR models generalize several classes of models familiar to political scientists, including generalized additive mixed models, variable coefficient models, and multilevel/hierarchical models. STAR models can capture parameter variation as well as unobserved heterogeneity that is likely to exist in the data while performing parameter smoothing to reduce the estimation instability that can result when we increase the parameter‐to‐data ratio. Smoothing can be done in a way that is particularly sensitive not just to historical time but also in ways that provide flexibility over other dimensions as well, such as region and policy area.            "
"9","Bayesian approaches to estimation of STAR models provide the kind of flexibility that we seek. While frequentist approaches that use smoothing splines—especially splines over the time dimension—offer flexibility, a key advantage to going the Bayesian route is that we can use priors that incorporate assumptions that are particularly useful for historical analysis. These assumptions pertain to ways that relationships among variables might evolve over the time dimension and with variation in context and help us to manage the trade‐off when increasing the parameter‐to‐data ratio.3"
"10","For example, suppose we were examining the effects of different factors on the roll‐call votes of members of Congress on civil rights measures over the course of the nineteenth and twentieth centuries. Parameters on member‐specific characteristics could be permitted to vary annually or by congress if we believe that different factors may have different effects over time. Or we may have specific periodization schemes where parameters would be constrained to be similar across specific years. While we could impose these constraints explicitly, a STAR model can be employed with Bayesian estimation approaches that would enable us to have the data determine to a large extent which periodization scheme is most appropriate."
"11","Particular kinds of priors offer solutions to the problem of pooling observations over long stretches of history. Complete pooling of the data is the kind of transgression that historians refer to when they complain that political scientists ignore the “texture and complexity” of history (Silbey 2000, 326). Allowing the effects to vary across the time dimension builds in some complexity that complete pooling would ignore. Yet, of course, we cannot let parameter effects vary completely, or we risk explaining nothing. We also want to avoid overstating the variance of parameter estimates.            "
"12","Bayesian estimation of semiparametric models can help us strike a balance between incorporating more of the complexity that historians believe to be essential and imposing the kind of structure that is necessary to model behavior quantitatively with the goal of revealing underlying patterns. For example, we could conduct the roll‐call analysis mentioned above using a hierarchical version of a STAR model where congresses are grouped according to the party systems within which they occurred. It is quite likely that roll‐call voting behavior will vary under different party systems given how parties line up along issue cleavages. Allowing parameter effects to vary across congresses in this way can help account for periodicity and variation in context. If we believe that particular variables are related to period‐specific or contextual variation, we can model parameters as functions of these variables."
"13","The downside to doing this, of course, is that if we get the periodization scheme or contextualization wrong—whether by specifying it in terms of measurable variables or not—it could result in misspecification bias. Undoubtedly, there will be disagreement over any explicitly imposed structure on parameter variation. To resolve such disagreements, we could choose to let periodization or contextualization schemes be substantially data dependent. One way to do this is to employ directed and undirected autoregressive priors, which could be used to smooth parameters such that the effects of variables will be more similar for adjacent time periods (Breslow and Clayton 1993).            "
"14","For example, in a roll‐call analysis, immediately adjacent congresses could be designated as similar without specifying exactly the nature of the similarity apart from proximity in time. Let  denote a congress at time t.  and  would be designated most similar to . The similarity would decay as we move away from t, so that we would posit that  would be less like  than , and so on. In this way, parameters for a given congress would be estimated by “borrowing strength” from proximate congresses without imposing an explicit periodization scheme. Borrowing strength in this manner enables parameter variation that is consistent with Gaddis's arguments (2002, 95) about the importance of distinctions among immediate, intermediate, and distant temporal causal factors, while striking a balance with respect to the precision of estimates. As the parameters are smoothed across time periods, periodization/contextualization schemes would emerge dynamically based on what is occurring in the data. By defining hyperpriors on variance parameters, the amount of smoothness can be estimated simultaneously with the regression coefficients to see what patterns emerge in terms of which observational units are more similar than others.4 Splines along the time dimension could be employed here to smooth over temporally varying parameters and capture complex nonlinearities in the effects of explanatory variables (Brezger and Lang 2006).5"
"15","The modeling of proximity need not be constrained to the time dimension. Priors that link geographic or policy areas could be adopted, drawing on methods from spatial statistics to introduce complexity of this nature (Cressie and Wikle 2011; Franzese and Hayes 2008), permitting a multidimensionality that should be particularly appealing for those who wish to see more complexity in the models deployed to study history. To continue the roll‐call voting example, in addition to incorporating priors that account for proximity over the time dimension, we could expand these priors to model proximity in terms of type of vote—for example, on amendments, on final passage, on substantive issues, and on procedural matters. The effects of variables could be allowed to vary both across time and context (in this case, type of vote), leading to an expansion of parameters that would be made manageable by the priors. Tremendous progress has been made recently in the theory and implementation of Markov random field (MRF) priors, which are particularly useful for dealing with this type of parameter variation. MRF priors set up a general functional relationship for the parameters for different observational units that captures the similarity or proximity of the units along different dimensions—such as time and/or geography.            "
"16","While periodization schemes may emerge from this kind of approach, variation is likely to be smooth and may fail to capture more abrupt change in the form of structural breaks. Determining the existence of structural breaks and locating when they occur can be tricky with conventional methods. A standard approach to testing whether an event is historically important or not is simply to include a dummy variable—possibly interacted with other variables of interest—that distinguishes observations before and after the occurrence of the event in question. As Western and Kleykamp (2004, 355) point out, the crudeness of this approach can be problematic. Suppose the event occurs at time t, but we do not observe a change in outcomes until time . Does this mean that the event was not the source of the structural change? Or if another event occurs at time , it is entirely possible that a dummy variable indicating observations before and after time t will have a (misleading) statistically significant coefficient. If we estimate several different models each with a dummy variable indicating a different time point for the break, conventional critical values need to be adjusted to reflect prior uncertainty about the location of breaks.            "
"17","The most commonly used method in political science for testing for a break in a time series is the Chow test, which assumes that it is valid to break a series into two parts—before and after some posited significant event. Yet it could be the case that the series should be broken into more than two parts and that the most important breaks occur at different points in time from those explicitly posited. If there are more structural breaks in the data than specified, we could reach incorrect inferences."
"18","We seek a more flexible and comprehensive approach in both determining the existence and location of structural breaks as well as for estimating coefficients in different periods demarcated by the breaks. Fortunately, several approaches are available that do not have the restrictions of commonly employed methods. Barry and Hartigan (1993) develop a Bayesian changepoint method for univariate time series that does not specify the location of the change (or changes) a priori. Instead, their method computes the posterior probability of a change occurring at each point in the series. The data are broken into different potential partitions where the means and length of each partition are allowed to differ. The algorithm that Barry and Hartigan employ compares the values for individual observations with the means for various potential partitions. The number and location of partitions is then updated, and posterior means are computed based on current partitions. The algorithm proceeds iteratively until convergence.6 Chib (1998) develops a multiple changepoint model that posits regimes as hidden states from which observations are drawn. An unobserved discrete state variable, indicating which regime an observation belongs to, follows a Markov process, which allows us to estimate the transition probabilities to different states/regimes and determine which transitions are most likely to occur. This approach employs hidden Markov models where the data‐generating process depends on transitions among states, which we can specify as different periods in longitudinal data.            "
"19","Park (2010) expands on the hidden Markov model approach, treating the changepoint analysis as a problem of model selection. Each state is represented by a different model with potentially different parameter values. Parameters are allowed to vary across states, and the degree of parameter heterogeneity is essentially determined by comparisons of various nonnested models implied by the states. Transdimensional Markov chain Monte Carlo (MCMC) methods are used to explore more efficiently the model space and parameter values within specific models. Park (2012) uses this approach to develop a changepoint model for unobserved unit heterogeneity in panel/time‐series cross‐section data. Changes in the unobserved unit heterogeneity essentially permit us to consider heterogeneity in temporal shifts across cross‐sectional units observed over time, both with respect to the number and location of changepoints.7"
"20","Flexibility with regime‐change estimation is not restricted to Bayesian approaches. Bai and Perron (1998, 2003) develop a frequentist method for continuous variables that allows for multiple break points without specifying their locations. It identifies potential break points and provides tests to determine how many breaks, if any, occur in the series. Additionally, it calculates confidence intervals to provide measures of uncertainty around break‐point estimates. Bai and Perron's algorithm is based on a dynamic programming approach that computes the optimal number of break points by determining the global minimizers of the residual sum of squares. The sequential procedure involves breaking the series into smaller and smaller possible partitions and checking to see which of these give the optimal fit to the data. The method can be used to assess whether there are breaks in the series itself or in the effects of explanatory variables from a multivariate regression model, making this method particularly attractive. Thus, while either approach can be used to locate breaks in a series, which may be the result of unobserved or unmeasured factors, Bai and Perron's method is more general than others available in that it permits more direct hypothesis testing with respect to changes in the relationships between measurable variables.            "
"21","As the discussion in this and the previous section indicates, historical researchers have a variety of methods available that enable them to incorporate parameter heterogeneity in ways that capture temporality, periodicity, specificity, and context. All of the methods discussed above can be implemented using software that is publicly available.8 In the next two sections, we demonstrate the feasibility of these methodological recommendations with examples of applications drawn from recent work.            "
"22","Brunell and Grofman's (1998) investigation into historical patterns in split‐party U.S. Senate delegations speaks to a set of important topics in American politics, including realignment theory, the impact of the 17th Amendment, and the degree to which voters choose divided government to balance extreme parties. They develop a theory that explains split‐party delegations as a result of cyclical dynamics surrounding partisan realignments. Given that Senate elections are staggered and that, barring vacancies due to death or resignation, no two Senate seats in a given state are on the ballot in the same election, split‐party delegations will occur as senators of the formerly dominant party are gradually replaced by members of the new favored party. Thus, it will typically take at least three consecutive elections before every seat has been exposed to realigning forces. The prevalence of split‐party delegations increases in the transition from one party to another and then eventually declines as the number of seats occupied by the new dominant party increases. As Brunell and Grofman put it, “[o]ver the course of each realignment era, there should be a clear cyclic shift in the extent to which Senate delegations are unified” (1998, 392). However, the 17th Amendment also plays a role in their story: they suspect that the move to direct election of senators would lead to an increase in split‐party delegations due to the rise of candidate‐centered elections within the context of an electorate that consists of many voters with no strong partisan attachment.         "
"23","They conduct a time‐series analysis covering a broad swath of history—from 1788 to 1996—where the percentage of split Senate delegations is regressed on lags and lagged differences to account for the directionality of the multistage realignment process, variables that mark the received locations of realigning elections (e.g., 1830, 1862, 1896, and 1932), and a dummy that indicates the move to direct election. The empirical results provide substantial support for their theoretical argument. The coefficients on the realignment variables, save the one for 1932, have statistically significant coefficients in the right direction, as does the post‐1912 dummy. They argue that their “approach largely sidesteps controversy as to whether it is 1928 or 1932, 1828 or 1832, say, which should be taken as the defining election. It also suggests very different answers to the question of how best to periodize the changing epochs of American party politics”(Brunell and Grofman 1998).         "
"24","While Brunell and Grofman's analysis is extremely well done and generally more sensitive to historical concerns—especially with respect to temporality and periodicity—than most quantitative political science studies, we see significant potential for the methods we advocate to provide a better assessment of historical patterns in split Senate delegations. Given the questions that Mayhew (2002) and others have raised recently about realignment theory, one possible way to improve the analysis is to employ a model that is more flexible about the locations of the changepoints that define shifts in partisan dominance. Brunell and Grofman impose a fair amount of structure in how they operationalize their realignment variables, specifying values of +2 for election years when the realignment is believed to have occurred, −1 for three cycles after this election, +1 for three cycles prior to this election, and 0 for other years. This is essentially a type of smoothing that may be better left to an estimation approach. We could also give the data more of a say in how the cycles of unified and split‐party delegations play out rather than imposing a binary structure for breaks.         "
"25","We replicated the Brunell‐Grofman study using the Barry‐Hartigan and Bai‐Perron methods.9 Both of these methods let the data speak more to the location of changepoints, but only the latter enables us to specify a regression that would include the lagged variables contained in the specification in the original analysis. The results of the analysis, displayed in Figure 1, suggest a story that differs from what Brunell and Grofman found. The Barry‐Hartigan approach finds the highest posterior probability for changepoints in 1794 (posterior probability = .94), 1826 (.90), 1832 (.88), 1862 (.96), and 1908 (.77). While the years 1826–32 and 1862 correspond with realigning elections, the posterior probabilities for the two other periods of realignment—1896 and 1932—are much lower. The highest posterior probabilities for the 1896 realignment occur in 1892 and 1898, but these values are both only .53 (the value for 1896 itself is .36). While the low posterior probabilities around the New Deal realignment are consistent with the original analysis, the relatively low probabilities around the 1896 realignment raise concerns that the theory works only for the antebellum period.         "
"26","Changepoint Analysis of the Proportion of Split‐Party Senate Delegations."
"27","Note: The vertical dashed line is the changepoint located by the Bai‐Perron method, while the vertical dotted lines represent the upper and lower bounds of the 90% confidence interval.                     "
"28","The finding of a relatively high posterior probability for a changepoint in 1908 calls into question the impact of the 17th Amendment, since this occurs at least three elections before the amendment went into effect. Elections in the run‐up to adoption produced relatively high turnover for this period, and while states were adopting their own reforms for direct selection of senators during this time, turnover rates did not differ across reform and nonreform states (Stewart 1992). Considering that the years 1902 and 1906 had the lowest proportion of split delegations in the series, it is not surprising that high turnover would have produced a sharp increase in this measure, despite the absence of realigning dynamics.         "
"29","The Bai‐Perron approach is much less charitable toward the realignment theory of split‐party delegations when lagged dependent variables are included in the regression specification. The best‐fitting model involves only one break, and that break is estimated to occur in 1946. The upper bound of the 90% confidence interval is 1966, which suggests that this could be related to shifts in partisan alignments that occurred in the wake of the passage of the Civil Rights Act of 1964 and the Voting Rights Act of 1965."
"30","Including the lag terms forces a trade‐off since the method requires that minimum segment length be greater than the number of regressors. With an intercept and two lag terms as regressors, the minimum segment length is 4, which may be too long to recover the cyclical pattern Brunell and Grofman posit. If we drop the lags from the regression, which reduces the minimum set length permissible, we see results that are more consistent with those obtained from Barry‐Hartigan. As reported in Figure 1, Bai‐Perron locates break points at the same locations where Barry‐Hartigan finds the highest posterior probabilities. Bai‐Perron also raises the possibility that realignment‐induced split delegations are an antebellum phenomenon and questions the role of the 17th Amendment. While the confidence intervals around the 1908 break point include 1914, they also include earlier elections, suggesting perhaps an even earlier break. Bai‐Perron also indicates a period of elevated split delegations beginning in 1964 and ending in 1998, which does not appear to be explained by standard realignment dynamics.10"
"31","Brunell and Grofman rightly argue that their analysis is superior to previous studies because it includes a broader swath of history and conducts a more systematic analysis of how realignments affect representation in the Senate. But the replication reported here raises some questions about their results and the power of realignment theory to explain split Senate delegations. It suggests a more limited reach for the theory, implying that it might work only for the antebellum period—and even there, we see dynamics in the very early years of the Republic that demand explanation. State delegations displayed partisan diversity in the early years of the Senate, which gave way to more unity in the first party system. Perhaps this is simply due to the difficulties in identifying partisan affiliation prior to the institutionalization of party labels. The replication also calls into question the role of the 17th Amendment, since a shift in the proportion of split delegations began prior to the amendment's adoption. This calls for a more nuanced state‐level analysis to explain the dynamics that produced so few split delegations in the first few years of the twentieth century, followed by substantially higher turnover toward the end of the aughts."
"32","Farhang and Katznelson's (2005) investigation into sectional influences on the construction of labor policy during the New Deal and Fair Deal offers a rich site for a replication that demonstrates the usefulness of STAR models. A key claim of Farhang and Katznelson is that important, indeed dramatic, changes in Democratic support for labor‐friendly policies took place at this critical time in American history. During the early years of the New Deal, southern Democrats behaved much like their northern colleagues because labor policy was explicitly designed so that it would not interfere with the southern system of racial apartheid. Specifically, domestic and agricultural sectors—occupations in which the majority of African Americans were employed—were largely exempted from New Deal labor protections. The basis of this arrangement was a set of Faustian bargains in which liberals outside the South allowed a distinctly illiberal social and political order to perpetuate for the sake of securing and maintaining national majority coalitions. As labor unions began to mobilize in the South, and as their inroads began to undercut Jim Crow through the partial racial integration of union locals and by the challenge they posed to the region's racialized, low‐wage political economy, senators and representatives from that section became less willing partners in the New Deal coalition. Pursuing an insight of Key's (1949), Farhang and Katznelson show how this decline in the southern propensity to vote with their northern counterparts on labor questions was the opening wedge for the later emergence of the Conservative Coalition that linked Republicans and southern Democrats in votes to resist a more robust federal government.         "
"33","Farhang and Katznelson analyze roll‐call voting data from the 73rd through the 80th Congress (1933–48). Reporting Rice “likeness scores” that clearly demonstrate the changing coalitional patterns with regard to votes that concerned unions and labor markets, they make the case for the role that unionization plays primarily through narratives that discuss in detail key labor legislation considered during this period. The analysis that Farhang and Katznelson offer can be conceived as one of changing parameters. The southern reaction to union efforts became more intense over time as they perceived a more severe threat to Jim Crow; as labor activity in their region increased, southern members became less likely to support prolabor policies."
"34","The parameter variation permitted by STAR models provides an alternative and complementary approach to test their unionization hypotheses by making it possible to capture more precisely how southern congressional behavior changed. To take advantage of what STAR models have to offer, we specify the following structured additive predictor for a generalized regression model:            "
"35","Specifying the model in this way captures an important nuance in Farhang and Katznelson's argument. First, there is a temporal component of accelerating concern. It could be that southerners not only responded negatively to unionization, but also that their response became more intense over time as they perceived a growing threat to the racial order. Thus, there is an element of periodicity to the marginal effect of union activity. Second, the circumstances surrounding a particular vote or set of votes might produce contextual effects. Union efforts during World War II, for example, under conditions of a tight labor market and an ideological campaign against Nazi racism, may have been more menacing to southern representatives than equivalent activities before the war. Finding differences in parameter estimates across levels j and k indicates that context and periodicity were an important part of the unionization hypothesis and thus that these innovations to the model are valuable.         "
"36","To permit parameter variation but with smoothing, we adopt Markov field random priors over regions and periods. For example, the priors for the region‐period effect can be represented by            "
"37","To measure union activity (denoted UN in equation 1), we employ data collected by Troy and Sheflin (1985). While this is the most accurate and direct state‐level measure of unionization available, it exists only for 1939 and 1953. We impute state‐level estimates for the remaining years by distributing national‐level measures across the states according to the percentages given in the 1939 and 1953 data and then weight by state population.12 This enables us to fully explore potential parameter variation across the New Deal and Fair Deal periods, which is essential since Farhang and Katznelson's (2005) aggregate analysis suggests that the unity that existed between southern and nonsouthern Democrats in the early New Deal had already begun to break down, if only slightly, in 1938.         "
"38","In addition to the unionization variable, we also include variables that measure the proportions of African Americans and of individuals living in urban areas in a state (denoted AA and URB). Both variables should have an impact on labor voting, but we might also suspect that their impact would vary over region and periods. For example, Farhang and Katznelson's argument implies that we should expect a negative relationship between African American population and support for prolabor positions in the South. Urbanization should also have a differential impact, since the threat presented by unions to Jim Crow arguably would be intensified in urban areas where unions could organize more readily. We also want to make sure that any effects that we find for unionization are not confounded by these other factors.13"
"39","The specification also includes in  a Democratic party indicator and an indicator for membership on the committee with jurisdiction over labor issues. The reasons for including the former are obvious. We include the committee‐membership indicator since the “textbook” account of Congress during this period suggests that, if a committee product makes it to the floor voting stage, it likely has widespread committee support. The distributive theory of legislative organization also suggests that members from states with extensive union organizations would seek membership on the labor committee, which means that including this variable helps ensure that we are not seeing spurious correlations between prolabor predispositions and our measure of unionization.         "
"40","We estimated this model using MCMC methods on an expanded set of labor‐relevant roll‐call votes in order to bolster generalizations and obtain a more complete picture of the evolution of roll‐call voting behavior over time.14 To provide a baseline for comparing the performance of the more sophisticated approach that we advocate, we also estimated a set of congress‐by‐congress regressions imposing no priors or restrictions on the relationship among parameters. The simple probit results are reported in the appendix (see Table A‐1 and Figure A‐1). The coefficients jump around a fair amount, and many of them are estimated very imprecisely, particularly in the Deep and Border South regions, where very few of the coefficients are bounded away from zero. We see no discernible trends over time in the parameters, largely due to the imprecision of the estimates.         "
"41","The results for the model that uses MRF priors are reported in Table A‐2 (in the appendix) and Figures 2 and 3 (temporal patterns are more easily discernible in the figures). The parameter estimates are much more stable over time and display more precision compared with the congress‐by‐congress regressions (we report 90% credible intervals throughout; note that the scale of the variation in the parameter estimates is much smaller with the Bayesian approach).         "
"42","Estimated Coefficients and 90% Credible Intervals for the Key Parameters from the Analysis of Labor Roll‐Call Votes in the Senate Using Markov Field Random Priors (73rd–80th Congresses)"
"43","Note: Estimation using MCMC implemented in BayesX, 100,000 iterations (first 10,000 discarded).                     "
"44","Marginal Effects: Differences in Simulated Probabilities for Voting Prolabor"
"45","Note: The simulated probabilities are computed from the results reported in Figure 2. The circles represent the differences in the simulated probabilities when the variable values are set to median values for the region and period and when the variables of interest are increased by one standard deviation. The vertical line segments represent 90% credible intervals. The scale of the figures is held constant across regions to facilitate comparisons in the magnitude of marginal effects.                     "
"46","Substantively, the use of priors helps to tease out interesting patterns of variation over time and region in the parameters. The most interesting pattern is with the coefficients on the unionization variable for Border South senators. For all congresses covered in the analysis, these coefficients are positive and bounded away from zero, indicating, in a fresh finding, that Border South senators were more likely to vote prolabor with increases in unionization throughout the New Deal and Fair Deal periods. Crucially, this discovery permits a recovery of internal southern heterogeneity, both across the region and within the border states themselves. Although southern senators, including those in the border states, were less likely than nonsouthern Democrats to support unions in congressional votes, the likelihood that border‐state senators would do so was affected positively, not negatively, by successful union efforts. This finding thus introduces a key aspect of complexity into the analysis by Farhang and Katznelson (2005) concerning unions and the South and reinforces Key's understanding that position taking by the southern members in Congress was driven by the leadership and example of Deep South representatives.         "
"47","To assess the magnitude of the effect of unionization, we report in Figure 3 the differences in the predicted probability of voting for the prolabor position (with credible intervals to indicate estimation uncertainty) when the variables of interest are at their median values and then increased by one standard deviation. In the figure, we report differences in predicted probabilities for changes in the unionization variable alone as well as with changes in the proportion of African Americans and degree of urbanization.         "
"48","The simulated probabilities for Border South senators are all bounded away from zero and suggest that the marginal effect of unionization increases as we move through time. In earlier congresses, an increase of unionization by one standard deviation is associated with only about a 3 to 4 percentage‐point increase in the probability of voting for the prolabor position. In the 79th and 80th Congresses, this is associated with a 9 to 10 percentage‐point increase, which is substantively significant, especially when compared with the other regions. For Deep South senators, the coefficients on the unionization variable are bounded away from zero for only the 74th, 75th, and 79th Congresses. When we examine the marginal effects, we see that the change in probability is either small—between 1 and 3 percentage points—or not statistically distinguishable from zero. We see similar results for nonsouthern senators: while the coefficients are bounded away from zero for all congresses except the 79th and 80th, all of the confidence bounds from the changes in predicted probabilities include zero."
"49","Turning to the other coefficients that are permitted to vary, we see that the coefficients on the measure of African American population are generally negative and bounded away from zero across all regions. The one exception is for nonsouthern senators in the 80th Congress. These results confirm the part of the Farhang‐Katznelson (2005) argument that concerns the linkage between antilabor sentiment and race. Consulting the plots for the marginal effects, increases in the proportion of African Americans in a state are consistently associated with a 6 to 7 percentage‐point decrease in the probability of voting prolabor among Border South senators. For Deep South senators, we see decreases ranging from 9 to 13 percentage points in the 74th, 77th, 79th, and 80th Congresses. For nonsouthern senators, we actually see a small increase in prolabor voting—between 1 and 5 percentage points with increases in the proportion of African Americans in the 77th–80th Congresses. Despite the negative coefficients that we see for senators from this region, they generally have a higher baseline support for prolabor positions, which explains why they appear to become more prolabor with increases in African American population.         "
"50","When we jointly consider increases in unionization and the percentage of African Americans, we observe a distinct regional pattern developing over time. As both variables increase by one standard deviation, senators from the Deep South are mostly predicted to respond negatively, with a decrease in support for prolabor positions by between 7 and 10 percentage points (for the 73rd, 75th, and 78th Congresses, this difference is not statistically distinguishable from zero). By contrast, while the difference in predicted probabilities for Border South senators goes from negative to positive from the 73rd to 80th Congresses, all of the credible intervals around the point predictions include zero. A similar pattern occurs for senators from nonsouthern states, but the point estimates are bounded away from zero for the 79th and 80th Congresses."
"51","A thorough examination of the Farhang‐Katznelson (2005) argument is advanced by a consideration as well of the urbanization variable. The urbanization measure has consistent effects across periods and regions. It is bounded away from zero and negative for all periods for the Deep South and Non‐South (except for the 80th Congress); for the Border South, it is negative in the four congresses for which it is bounded away from zero. When we consider an increase in this variable in conjunction with an increase in the unionization and African American population measures, we can discern a particularly interesting story, a pattern that both is consistent with the core thrust of Farhang‐Katznelson, but that suggests a more complex pattern across the South. Deep South senators have a dramatic and striking negative response to increases in these variables. Their predicted probabilities are all bounded away from zero except for the 75th Congress, with particularly strong negative responses in the 74th and 79th Congresses of about 18 percentage points. This is what we would expect, since senators with large numbers of African Americans in their states and a higher population concentration in urban areas would feel a greater threat from unions.         "
"52","By contrast, Border South senators were about 10 to 12 percentage points less likely to vote in the prolabor direction for the 73rd–76th Congresses, but this propensity decreases during the 77th–80th Congresses, when none of the changes in predicted probabilities are statistically distinguishable from zero, meaning that we essentially would predict no change in the likelihood of voting a particular way on labor votes. For nonsouthern senators, we predict no change in voting behavior with increases in these variables for all of the congresses covered by the analysis, except the 80th, when they become slightly more prolabor.15"
"53","Allowing parameters to vary over time and region while employing historically relevant priors thus reveals a fascinating nuance inside the more general pattern identified by Farhang and Katznelson(2005)—one that indicates an interesting and significant modification to our understanding of this era's labor policymaking. While senators from the Deep South were much less supportive of labor as unionization, the African American population in their states, and urbanization increased in tandem, their colleagues from the Border South were significantly less hostile to labor into the Fair Deal period. These results suggest that senators from this region were cross pressured, caught between their overarching desire to protect a system of white supremacy and the need to be responsive to their voters, some of whom were drawn to unions and their capacity to improve life situations. While segments of constituencies in this region feared the threat to desegregation and the southern order that union activity presented, other constituents were actually being mobilized to join unions, implying that they might pose effective opposition to reelection‐seeking senators who were hostile to labor. As a result, some southerners in Congress may have hedged their bets in places where unions were experiencing the most success at organizing and where, concomitantly, preferences for segregation were weaker. The methods we have applied provide clear and unexpected evidence that unionization in the Border South tempered defections from the majority party position in the 1940s, a pattern within a pattern that had been missed not only by Farhang and Katznelson (2005) but also by all the extant literature on unions and the South written by historians and social scientists, including Marshall's (1967) still standard work.         "
"54","In all, this replication demonstrates the usefulness of permitting parameter heterogeneity while constraining it with historically relevant priors. Using MRF priors enables us to borrow strength from temporally adjacent congresses and spatially adjacent regions in order to improve estimation precision and uncover interesting patterns in the evolution of roll‐call voting behavior. It also indicates a larger potential to disclose historical arrangements, relationships, and processes that otherwise would remain obscure, thus shifting the character of objects of analysis and opening the way for the development of fresh hypotheses to account for what happened within a richer universe of behavior than otherwise would be ascertained."
"55","This article is motivated by the concern that as historical research grows in political science, forms of mutual incomprehension, semiaccurate caricature, and beliefs about the proper range of assumptions and research methods have erected barriers separating scholars with richly nuanced qualitative approaches to history from colleagues who make quantitative methods central to their studies of political behavior and institutions. If we do not attempt to overcome these barriers by addressing key points of contention, both worlds of scholarship will fail to meet their full potential."
"56","Within the framework of identifying the main legitimate reservations about mainstream quantitative scholarship that is historical by those who practice historical research as their primary craft, our main goal is to advocate how thoughtful utilization of approaches that privilege parameter variation can serve as promising means, though not the only ones, to bridge these research communities by systematically capturing just those features about parameters and their alteration that most interest the historical community. From our perspective, it is imperative not only to take seriously the worry among historians and historical social scientists that quantitatively oriented political science fails sufficiently to attend to context, historical specificity, temporality, and periodicity but also to acknowledge that unless such matters can be made constitutive features of inquiry, their skepticism will remain justified. Good research on historical periods cannot proceed by a flattening universalism. Rather than expect models to predictably port across time, we should be building models that seek to internalize and reflect central historical features and processes by integrating parameter heterogeneity and complexity inside their very construction."
"57","In turn, though, such efforts, to the extent they succeed by illuminating the historical process, put pressure—a welcome kind of pressure—on political historians and qualitative political scientists to deepen and broaden their research repertoire. It simply is not good enough to express skepticism about mainstream approaches to multivariate analysis and, with varying degrees of dismissiveness and willful unawareness, continue with a “business as usual” attitude that largely ignores advances in empirical modeling and their potential to causally investigate historical processes."
"58","We have discussed specific prescriptions for moving forward to produce more robust historical quantitative analyses that put front and center the concerns that historians have expressed about standard political science methodology. Temporality can be captured by using splines and directed, undirected, and MRF priors that tap into temporal evolution in parameter effects. Hierarchical modeling is particularly well suited to incorporate contextual considerations. Structural change or changepoint models, especially given recent advances in their estimation, offer tremendous opportunities to systematically unveil periodicity that can have a profound impact on our evaluation of temporally centric hypotheses. Of course, we do not argue that the methods discussed here exhaust the options available to researchers who want to incorporate more historical sensitivity into their work.16 Beyond this expanded use of existing methods, we also see an imperative to develop new modeling and estimation techniques that address problems unique to historical political analysis.         "
"59","A long list of fundamental questions could be more thoroughly and compellingly explored through historically oriented analyses that moved beyond the standard methodological toolkit in the ways that we have advocated. Within American politics, the list includes how to think about party in relation to preferences; issues concerning the number and substantive meaning of ideological and policy dimensions; questions about the structuration of lawmaking and the impact of organizational features on outcomes; the ways patterns of representation orient constituency ties; the meaning of roll‐call votes and the balance between those which are partisan and those which are not; and the barriers to legislative productivity and responsiveness, both institutional and behavioral. Even well‐tilled areas of inquiry that are inherently historical, such as the debate over the existence and impact of partisan realignments, could be revisited fruitfully by using the modeling innovations we have discussed to more fully resolve the attendant theoretical and empirical controversies. Major questions in other subfields also cry out for more sophisticated methodological approaches to history. Questions of the effects of democracy and trade on peace, of the relationship between economic and democratic development, and of economic and political inequality all have historical dimensions that should be central to the empirical methods used to address them."
"60","If we wish to probe these issues, irrespective of our disciplinary orientations and methodological priors, we will need to find ways of working that, at once, are deeply substantive and systematic. Here, we have advocated a set of empirical tools that serve as a means to this end. To the extent that our proposals are persuasive, they also imply obligations about the range of issues, literatures, and methods that quite disparate research communities might learn to share, and thus entail commitments that will be difficult, sometimes painful, to achieve. But the payoff promises to be considerable."
"61","Table A‐1 and Figure A‐1 report results from congress‐by‐congress regressions imposing no priors or restrictions on the relationship among parameters. Table A‐2 reports results from the analysis using MRF priors.            "
