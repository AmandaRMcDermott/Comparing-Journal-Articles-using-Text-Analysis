"","x"
"1","Why might we expect people to respond more favorably to an outcome rendered by Process A than to that very same outcome rendered by Process B? Indeed, many observers of politics seem to assume procedures are not really of much relevance, that people view processes as merely means to ends, and that all that matters to them is what they get. Spatial theories of voting, for example, locate people on policy space and then assume that individual voters are motivated solely by the desire to maximize their policy (outcome) preferences by voting for the candidate or party they believe to be closest to those preferences. People's perceptions of the process never enter the picture. As Popkin puts it, the prevailing wisdom is that people make judgments on the basis of “results and are generally ignorant of or indifferent about the methods by which the results are achieved” (1991, 99)."
"2","Still, in several social science disciplines as well as in the natural sciences, interest in the consequences of “nonoutcome” characteristics of decision‐making settings has grown tremendously in recent years. In psychology, Tyler has led the way in demonstrating that people do “not react to the degree to which they received a personally beneficial decision. Instead, they react to how fairly the decision was made by the authority” (Tyler 2001, 234; see also, Boehm 1999 and Tyler 1990, on why people are averse to self‐serving authority figures). Tyler's conclusions are often based on data from participants in the legal system. In a study typical of his approach, Tyler targeted 652 Chicago residents who had “recent personal experiences with the police and courts” (2001, 233). By administering a posttest survey, he found that among those defendants who were found guilty, satisfaction with and acceptance of the verdict was greater when they had positive perceptions of the process that led to that verdict. Though this general finding of an independent effect of process is now widely accepted by psychologists, disagreement has long been present over the particular features of the process that lead to the most favorable (or unfavorable) reactions (see Brockner and Wiesenfeld 1996; Cohen 1985; Thibaut and Walker 1975).         "
"3","In economics, a growing and influential group of scholars has compiled impressive evidence that people are not just interested in absolute gains.3 Some of these researchers, for example, have stressed people's preference for relative as opposed to absolute gains. It turns out, people express high levels of satisfaction when they receive $3 from another player who keeps $3, but low levels of satisfaction when they receive $3 from another player who keeps $13. By holding constant the payoff offered to the receiver and then varying the size of the pot (and therefore the amount the other player proposes to keep), the crucial role of relativity becomes apparent (Frank 1999, 115–21; Kahn and Murnighan 1993). As such, these findings run against the more traditional economic claim that when making decisions people exclude from consideration the interests of their “opposite number” and focus only on maximizing their own absolute gains (Buchanan and Tullock 1962, 18).         "
"4","Scholars from a variety of fields, including political science, have demonstrated the extent to which social context influences people's reactions to decisions. People are affected by whether they have interacted (even briefly) with the decision maker prior to the decision, by whether they are likely to interact with the decision maker again, by whether they perceive the decision maker to be a member of their “in‐group,” and by whether the decision maker is perceived to be a decent human being or to have “earned” in a fair contest the right to be the decision maker (see Blount 1995; Dawes, van de Kragt, and Orbell 1990; Guth and Tietz 1990; Hoffman, McCabe, and Smith 1996; Kahneman, Knetsch, and Thaler 1986; Lubell and Scholz 2001; Masters 1982; Masters and Sullivan 1989; Morris and Sim 1998; Orbell and Dawes 1991; Ostrom 1998; Ostrom and Walker 2002; Smith 2000; Sullivan and Masters 1988; Thompson, Kray, and Lind 1998). Typically, for example, people are more than willing to take a loss themselves in order to punish someone who has behaved badly or to cooperate with someone who has behaved nobly (see, for example, Boyd and Richerson 1992; Henrich and Boyd 2001; Thaler 1992).         "
"5","The evidence that people are concerned with factors other than outcome is undisputed; instead, the dispute centers on the reason people are so influenced by the decision‐making setting and by perceptions of the other people involved in the interaction. In fact, this dispute, involving as it does classic arguments about nature versus nurture, is one we do not pretend to be able to resolve. Here, we provide only a taste of the arguments and an indication of the theoretical perspective generating our hypotheses."
"6","One common explanation for nonmaximizing behavior is that humans retain in their psyches a strong and innate desire for fair distributions (see Kravitz and Gunto 1992; Rawls 1971). Two problems with this explanation immediately suggest themselves: one empirical and one theoretical. In experiments, people do gravitate toward fair allocations, even if doing so is costly, but their tendency to be fair vanishes if steps are taken to protect their identity from the experimenter and, especially, from affected players (see Hoffman et al. 2000; see also Larimer 2002). People are less concerned with fairness than with the appearance of fairness. But even if this desire for fairness were more robust, we would still be left with the question of why humans would carry with them such a nonrational concern. A satisfactory theory for people's behavior must go beyond the simple assertion that “that is the way people are.” Such a statement is not a theory but merely an atheoretical admission that we cannot understand—and as a result must just accept—the human condition.         "
"7","Another (related) explanation is that, after beginning life with a concern only for our own tangible outcomes, we learn social sensitivity and even empathy as we develop. As one supporter of this view puts it, our “heritage has hardwired us to be boundedly self‐seeking at the same time that we are capable of learning heuristics and norms, such as reciprocity” (Ostrom 1998, 2). The message is that self‐serving behavior is what we are programmed to do but we can be trained to be nice under certain conditions. Given this theory's view that nonmaximizing behaviors are tacked on, it is no wonder they are generally characterized as “paradoxes,”“anomalies” (Thaler 1992), “quirks,” and “oddities” (Cosmides and Tooby 1994, 327).         "
"8","This view that a concern for others and, therefore, for the context of decisions is not natural but rather the product of societal teaching and norms is currently the dominant view in the social sciences.4 We cannot disprove this theory here but we can describe and briefly defend an alternative and, we believe, more satisfying theory. In brief, this theory flows from Darwinian biology and holds that, far from being an add‐on, our sociality—that is, our frequent concern for the welfare of our group and for our own place in the group, our eagerness to conform and to gauge our own success by that of those around us, our desire and ability to “read” and to empathize with other people, and our tendency to view members of out‐groups with disfavor—is deeply ingrained in the human condition and has been for millions of years.5"
"9","Humans' sensitivity to social arrangements may very well be “hardwired” into our nature. Depending on the specific environmental conditions, this sensitivity will result in great variation in the extent to which human behavior maximizes absolute short‐term interests or is other‐regarding. In this sense, the answer to the nature or nurture question is “yes.” But the notion that humans must be taught to be social is almost certainly inaccurate. At a remarkably early age, babies display empathy (Pinker 2002). We can learn maximizing behavior from environmental stimuli just as much as we can learn social behavior, as is evident in the research showing that students taking economics courses are more likely to increase their level of maximizing behavior than students taking other courses (see Frank, Gilovich, and Regan 1993; Marwell and Ames 1981).         "
"10","The idea that behavior has even a modest biological basis is still upsetting to many people, including scholars. But upsetting or not, the evidence seems firm and is growing. Beavers know how to build a dam even when they have not seen other beavers do so; monkeys raised isolated in a lab fear a snake after viewing a videotape of another monkey's fear of a snake but can never be taught to be scared of other creatures and objects no matter how many videos they see of monkeys being scared of those things (Dawkins 1982; Mineka and Cook 1993).6"
"11","In humans, people suffering from autism (a condition known to be at least partially genetic) help us to see the kinds of social skills that the vast majority of the population takes for granted. Most autistic individuals are said to lack a “theory of mind,” meaning they are unable to view social situations from the perspective of another person (see Baron‐Cohen, Tager‐Flusberg, and Cohen 2000); thus, they are often unable to form normal social relationships. Autistic individuals have difficulty understanding how to make other people happy since this requires empathic abilities they lack. The point is that the “sociality as a learned behavior” theory seems to suggest that all humans are first autistic but then most learn to be otherwise, a vision of human development that is not accepted by experts in the area. Along with evolutionary psychologists, we find more attractive and accurate the notion that, with a few unfortunate exceptions, people are born social. Clearly, some of these social abilities cannot manifest themselves until brain development has reached a certain stage, but children who have been raised with insufficient human contact do not turn out to be maximizing but otherwise regular people; they turn out to be behaviorally dysfunctional. We are programmed for social contact. When this contact fails to materialize we are not left in a “natural” state but rather in a lamentably unnatural state. In this sense, ascribing second‐class citizenship to social as opposed to maximizing behavior is mistaken.         "
"12","Not surprisingly, computer simulations have revealed that socially sensitive individuals have a clear evolutionary advantage over those with fixed decision rules such as “always maximize personal short‐term gains” or “always sacrifice for other people” (see Fehr and Gachter 2002; Rauch 2002). In these simulations, groups composed of egoists do not trust each other and are unable to take advantage of any of the benefits that group life was designed to produce in the first place, such as repelling predators and securing prey (just as Fukuyama 1995, and Putnam 2000, point out also happens in the modern world). Groups composed of altruists also lose out in these simulations since they are vulnerable to the presence of even a single mutant egoist and their defenses against out‐groups are wanting. Instead, the groups that survive in simulations are those whose members follow a more complicated set of rules: (1) cooperate with others in the group as long as others are cooperating; but (2) when others are behaving in a self‐serving fashion, cease cooperating and look for avenues to punish noncooperators even if punishment is personally costly. Not coincidentally, this behavior is similar to the tit‐for‐tat behavior that Trivers (1971) found so successful in nature and that Axelrod (1984) found so successful in his computer simulations.7 We call individuals who follow these rules wary cooperators since their first impulse is to cooperate8 but they are ever wary of the behavior of others. And the evidence is strong that social behavior of this sort is advantageous in the long run.         "
"13","Wary cooperators display two, often competing, desires. They want a reputation as a fair, desirable, possibly generous, but certainly not selfish, person. But they know this is not enough. No matter how solid their personal reputation for contributing to the group, a danger still exists that some miscreant within the group will treat them with less respect and thoughtfulness than they deserve. In other words, in addition to nurturing their reputation, people must also worry about members of the group who would take advantage of others if given the chance. Those who have been accorded a special, powerful place in the group (decision makers in modern governments, for example) are especially dangerous to the rank and file and are likely to come in for special scrutiny (more on this shortly). People thus spend much of their existence trying to avoid being perceived as a leech by those who are other‐regarding and being played for a sucker by those who are self‐serving.9 Either eventuality could result in losing a valued, perhaps essential, place in the group.         "
"14","With regard to life in populous representative democracies, interactions with government are more likely to be about sucker aversion than about leech aversion. Not being perceived as a leech is generally accomplished through the decisions we make, while not being played for a sucker is more likely to entail deciding whether or not to accept the decisions of others. Most people residing in large representative democracies such as the United States rarely make binding collective allocation decisions themselves. By definition, this task is typically left up to representatives. But most people in representative democracies do react to the allocation decisions of others, and this is precisely the topic of the research reported in this article: the conditions under which people are more or less likely to accept an authoritative decision made by others.         "
"15","In sum, the theory that successful group life requires humans to be particularly sensitive to self‐serving behavior by others, particularly by the powerful, provides an explanation for previous findings indicating the importance of nonmaximizing goals, and it also offers guidance into the particular types of goals that people are likely to have regarding the decision‐making process. Specifically, the theory suggests that people are using decisions and decision processes to draw inferences about decision makers. Are decision makers concerned for others? Are they trying to feather their own nests? Are they driven by personal ambition? Recent public opinion research indicates that the substance of most individual political decisions is of only passing concern to most people but the traits of other people, and especially the traits of powerful other people, is of great concern (see Hibbing and Theiss‐Morse 2002). As a result, other things being equal, people should be more accepting of authoritative decisions when they are made by decision makers believed to be unconcerned with either acquiring power or with benefiting themselves at the expense of others.10 In other words, we predict that decisions will be more acceptable if they indicate that the decision maker is the kind of person who would help to make a viable social group.11"
"16","In order to test this theory, we need a setting in which people can be observed reacting to an authoritative decision made by someone else, and we need to be able to hold the outcome itself constant while altering the procedure used to arrive at that outcome. Clearly, an experimental setting is necessary to meet these requirements. The framework we employ for testing the theory utilizes the so‐called ultimatum game. This game was first introduced by Guth, Schmittberge, and Schwarze over 20 years ago (1982), and since then has been replicated and extended in hundreds of scholarly publications to the point that it will soon surpass the prisoners dilemma as the single most employed experimental scenario (see Nowak, Page, and Sigmund 2000, 1773; for a good review, see Guth and Tietz 1990). In this single‐shot, two‐player game, Player 1 (the allocator) is asked to divide a sum of money with Player 2 (the receiver). The receiver is then presented with the allocator's proposal and has the choice of either accepting or rejecting that proposal; however, if the receiver's decision is to reject the allocator's proposal, neither player receives any of the money.         "
"17","The way to maximize short‐term tangible benefits is for the allocator to give the receiver the smallest amount of money greater than zero (epsilon) since this places the receiver in the position of either taking that small amount or being left with nothing—and short‐term maximizers faced with this choice will take the small amount. But without exception the actual results of ultimatum experiments depart dramatically from this standard expectation.12 With regard to the allocator, rather than keeping all but a modest portion of the money, the modal decision is to split the pot equally between the allocator and the receiver, and the median proposal is for the allocator to give up about 40% to the receiver. Not to be outdone, receivers also typically fail to maximize short‐term tangible benefits. On those rare occasions when the allocator does decide to keep most of the pot, thereby offering only a small allocation to the receiver, a large percentage of receivers reject the proposal. To be specific, offers of 30% or less are rejected better than 50% of the time (Nowak, Page, and Sigmund 2000, 1773). As one scholar colorfully described it, the attitude of receivers toward allocators is often “take your offer of epsilon and shove it” (Thaler 1992, 35).         "
"18","Economists have been far and away the main utilizers of the ultimatum game, and their primary emphasis, not surprisingly, has been on the allocator's initial decision. Experimental designs have rarely included a survey of the receiver measuring the extent to which the decision is accepted as legitimate, fair, or satisfying.13 This is unfortunate since, as political scientists, our interest in the ultimatum game centers around what it can tell us about the reactions of those affected by decisions (the receivers not the allocators), and it is these reactions that we must understand if we hope to make sense of people's relationship with their government and if we are to gain some insight into how that relationship might be improved. In short, while psychological and economic experimental research has pointed us in a useful new direction, designs such as the ultimatum game need to be modified if they are to help us understand the political arena generally and people's acceptance of authoritative and unfavorable decisions specifically.         "
"19","Like all experiments, ours will simplify reality but it does capture many of the essential features of the modern governing process (power given to a decision maker who makes an allocation decision that is less generous than the recipient would like). If, within the confines of this experimental setting, we can identify the conditions that increase and decrease the likelihood that subjects will accept an unfavorable, binding decision made by an individual who has been granted authority, we will have gained insight into the situations in which people will accept decisions made by real‐life governments."
"20","To test the hypothesis that procedure affects acceptance, we modified the ultimatum game in the following fashion. The experiment was set up so that, while receivers thought they were playing against another real person, in actuality allocation decisions were dictated by us ahead of time and only seemed to be influenced by a player at one of the other computer terminals. We presented each experimental subject (all playing the role of receiver) with identical allocation offers, thereby enabling us to observe variations in acceptance attributable solely to the manner in which that allocation proposal was determined."
"21","Here is how the experiment was conducted. In late 2001, subjects were recruited from the greater Rice University community (some students, some staff). They were promised $10 for their participation and told that there was a chance they could receive up to $20 more depending upon decisions made during the experiment. Subjects were ushered into a room with 29 computer terminals in individual cubicles. A pretest survey came on their screens, and subjects were told that they would receive $10 for completing the items. In this fashion, we compiled information on subjects' political involvement and views, on their demographic background, as well as on their trust in others and in the government. Once the instrument was completed, for purposes of realism, subjects were asked to wait a moment for their “partner” to complete the survey; then the ultimatum game began.14"
"22","The first screen described the game to subjects and asked them to wait a moment while the computer, via random selection, identified either the subject or the matched player as the allocator (as opposed to the receiver). After this delay, a screen popped up telling the subject that he was the receiver. At this point the process intervention was introduced. All subjects were told that there was $20 to be allocated (with whole dollars being indivisible) and that the allocator (the fictitious Player 1 in the dyad) could choose one of three methods to allocate the money. First, the allocator could opt for personal discretion and simply decide how much to keep and how much to offer to the receiver (obviously, the total of these two figures had to equal $20). Second, the allocator could leave the allocation to chance. If this option were selected, subjects were told that the computer, using a random number generator, would identify the specific allocation to be offered, with each of the 21 possible allocations ($10‐$10 plus ten options favoring, by varying degrees, the receiver and ten favoring, by varying degrees, the allocator) having an equal chance of being selected. Finally, the allocator could decide to base the allocation on a form of merit. One of the pretest questions was “how far did you travel to get to the experimental site today?” In this last option, subjects were told the computer would calculate the differential in travel of the “two” subjects and prorate the payoff accordingly, with those traveling farther in relative terms receiving the greater share."
"23","Subjects were then told which allocation process the allocator decided to employ. In actuality, subjects were randomly assigned one of three cells (corresponding to the three processes for arriving at an allocation proposal). Subjects in the “allocator discretion” cell were asked to wait while the allocator determined how much to propose to give and to keep; subjects in the “random” cell were asked to wait while the computer used the random number generator program to select a proposal; and subjects in the “desert” cell were asked to wait while the computer calculated the distances each player traveled and produced the corresponding allocation proposal. After a brief delay, all subjects, regardless of their experimental cell, were then informed that the proposed allocation was $18 for the allocator and $2 for the receiver. Same outcome, different process."
"24","Subjects were reminded that, as per the rules of the game that had been described to all at the outset, they as receivers now had the opportunity to decide whether or not to accept the proposed allocation. If they accepted, they would receive $2 from the pot, and the allocator would receive the other $18. If they rejected the proposal, it would be void and neither player would receive any money. Subjects were then asked to make their decision, after which they answered a few posttest items on their views of the experiment and the allocator, were debriefed, thanked, and excused.15"
"25","We have stated our general belief that variations in the process will have an important impact on citizen acceptance of decisions but to this point have not identified the specific procedures we expect to engender relatively positive reactions. Consistent with the theory of wary cooperation, our primary expectation is that receivers will be the most put‐off by allocators who intentionally used their position to give themselves an untoward share of the money. Those subjects placed in the cell where allocators had used their own discretion are most likely to feel victimized since another human being made a conscious decision to give only a little of the money to the receiver. In the other two cells, however, the receiver believed the unfavorable outcome was not due to a greedy allocator but rather to bad luck or to the existence of an opposing player who was in some sense more deserving.16 On their face, these last two processes introduce objectivity in that the allocator has given the receiver a more or less equal shot at a favorable allocation. For this reason, the acceptance rate for the “allocator discretion” cell should be much lower than that for either the “random” cell or the “desert” cell.         "
"26","According to Figure 1 this is precisely the case. Only 32% of those thinking they received $2 (of $20) due to allocator discretion accepted the proposal, meaning that better than two‐out‐of‐three people were willing to forego a positive offer. But this much is essentially a confirmation of findings from the standard ultimatum scenario. What makes our results unique is that they permit us to compare this acceptance rate with that generated by allocations made via other processes. When the allocation was ostensibly determined by calculations of the respective distances traveled by the two players, the acceptance rate of the same $2 (of $20) allocation jumped to 71%, and when the allocation was determined by chance, the acceptance rate of, again, a $2 (of $20) allocation was even higher—80%. Even though the cell sizes are not large (40, 29, and 28, respectively), the differences between allocation by allocator discretion and the other two processes easily meet traditional tests of significance (p < .01).17"
"27"," The Effects of Process on Decision Acceptance                      "
"28","The major point of this section is that process matters. Just as previous research has established that behavior is not driven solely by absolute outcome and that relative outcome is a crucial predictor, our research shows that behavior is not driven solely by the size of the outcome—absolute or relative. When we control for outcome by freezing in a payoff that is small both in absolute and relative terms, substantial and significant variation is apparent in acceptance of that payoff depending entirely on the manner in which it was derived. Too often, analysts assume people conflate a fair outcome with a fair process. Our findings help to pull apart these two very different concepts. Few could argue that an allocation of $18 for one person and $2 for another is a fair outcome, but if that outcome is believed to have resulted from a fair (random) process four out of five people accept it.18"
"29","In addition to observing whether subjects accepted or rejected the authoritative decision, we also administered a short posttest questionnaire to the receivers. The central item on this instrument asked whether subjects thought “the divider was fair, unfair, or somewhere in between.” Responses could range from 1 (fair) to 7 (unfair). Our expectation is that subjects who believe the allocator decided to make the decision himself will perceive the decision maker as much less fair than subjects who believe the allocator left the decision up to chance or desert. As can be seen in Figure 2, the results are perfectly supportive of this expectation. Receivers dealing with an allocator who decided to retain authority to make the allocation decision perceived the allocators to be quite unfair, an average placement of 6.6 on a scale running from 1 (fair) to 7 (unfair). Allocators who agreed to tie the allocation decision to a comparison of the relative distances traveled by the allocator and receiver in coming to the experiment were perceived as much less unfair (4.9 with 4.0 being the midpoint between fair and unfair). And allocators who left the decision to random selection were perceived as more fair than unfair (3.7). Once again, the actual outcome was the same for all subjects (they received just $2 of the $20 pot) so these results show that perceptions of fairness on the part of authoritative decision makers are not entirely dictated by outcome.         "
"30"," The Effects of Process on Receivers' Perceptions                      "
"31","In fact, even perceptions of the outcome are to a certain extent dictated by process. We also asked subjects how satisfied they were with the money they received. Even though all subjects received $2 and even though the great majority were unsatisfied with this outcome, there was still a statistically and substantively significant difference in satisfaction with the outcome (money received) traceable solely to the manner in which the distribution was determined (see Figure 2). When it was allocator discretion that led to the $2 outcome, receivers were very unsatisfied (6.6 on a scale running from 1 [very satisfied] to 7 [very unsatisfied]); when it was a comparison of travel distance, dissatisfaction dropped to 5.9, and when it was a random number generator, dissatisfaction dropped even further to 5.5 (both of the latter two means are significantly different (p < .05) from the mean for allocator discretion). While an apparently fair process cannot make people happy with a lousy outcome, it clearly can make them less unhappy. More specifically, the outcome resulting from a process in which decision makers took direct steps to enrich themselves is viewed as a less satisfying outcome than the same outcome produced via more objective means. Two dollars is not always $2.         "
"32","If the theory of wary cooperation is correct about the importance of traits attached to the decision maker, the same basic decision process may produce quite different levels of acceptance depending upon those perceived traits. The trait we focus on here is the perceived motivation or ambition of the decision maker, a trait with obvious relevance to the political world. Specifically, we analyze the effects of variation in the decision maker's desire to make the decision. This is an area in which previous research has produced useful if somewhat tangential empirical findings. When the allocator is given that advantaged position not because of random selection (as has been the case in our experiments to this point) but because he in some way earned the right to be the allocator (apparently no matter how specious the “earning” process may have been), allocators tend to be less generous to receivers and, more relevant to our concerns, receivers tend to be more accepting of unfair allocations (see Smith 2000; also see Ridley 1996, 140).         "
"33","But the extension of this finding to the political arena may be problematic. Earning a position does not equal coveting a position and previous experimental work has never analyzed the difference. Why should it matter? Because earning does not reflect a person's motivation. In the earning experiments, an experimenter simply said, “now we will have a contest.” In the motive experiments, the participants were not given the chance to opt in or out and therefore the wary cooperator's perception of their opposite number's desire to be the decision maker cannot be a factor. Why shouldn't subjects be somewhat more deferential to the “winner” of this contest, however trivial and irrelevant it may have been? But suppose the decision maker is the decision maker because he wanted to be in that position. The wary cooperator immediately becomes suspect. Why would a person strive to be in an authoritative position if not to take advantage of it?"
"34","How does all this relate to politics? In the United States at least, the campaign process is certainly viewed as intense and demanding. The candidates who survive the electoral gauntlet may well be thought to have “earned” the right to be decision makers and therefore to have their decisions accepted. On the other hand, from the citizens' point of view, candidates' willingness to put up with all the hard work and negativity of the campaign may only confirm their suspicions about the sizable personal payoffs available to those serving in office. By this logic, elected officials are less likely to be viewed as those who have earned their position than as those who are simply more eager than ordinary people to be self‐serving. If our reading is correct, decisions will be less acceptable when they are made by those who wanted to make them than when they are made by those who may not have wanted to make them."
"35","To test this hypothesis, we introduced an additional experimental intervention. Subjects randomly assigned to a fourth experimental cell were put through procedures similar to those described above except that in this case subjects believed the allocator had no choice regarding the allocation process. Recall that in the main experiment above, Player 2 was told that Player 1 (the allocator) was allowed to choose whether to rely on chance, merit, or personal discretion in dividing the money. Here, the choice of how to make the allocation is forced on Player 1. Neither random nor desert procedures were an option so the allocator (whom subjects believed was selected randomly) was forced to use personal discretion. The acceptance rate of receivers in this cell can usefully be compared with the acceptance rate of receivers in the first column of Figure 1; that is, with those receivers who reacted to allocators they thought could have selected alternative procedures (random or desert) but instead wanted to make the decision themselves. We believe that receivers will be more likely to accept a proposed allocation when the allocator had discretion thrust upon him than when the allocator overtly opted for discretion. Allocators in the first instance may not have wanted to be given unfettered choice in how to divide the money; allocators in the second instance did, and we hypothesize this will make a difference to receivers as they react to allocation proposals (still always $18–$2).         "
"36","As expected, receivers were much more willing to accept decisions made by decision makers who did not overtly crave power. From Column 1 of Figure 1 we know that just 32% of receivers accepted a $2 (out of $20) allocation from an individual who could have opted against making the allocation decision personally. But Figure 3 shows that when allocators had no option other than making the allocation decision themselves, over 53% of receivers accepted an identical $2 allocation (p < .05). That people react so differently to outcomes that are identical in absolute and in relative terms, that have been rendered by identical processes (that is, allocator discretion), and that differ only in that one was made by a person who seemed eager to maximize their own discretion and the other by a person who was pushed into that position is a remarkable statement on the importance to people of the perceived characteristics of decision makers. People care not just about who gets what and how they got it but also about who gave it to them. To our knowledge, this is the first empirical evidence that, controlling for perceptions of greed, the belief that decision makers are ambitious has an independent and relatively strong inverse effect on decision acceptance. Apparently, being treated badly by someone who did not necessarily want to be in a position to treat us badly is much more tolerable than being treated badly by someone who machinated to be in a position to treat us badly.19"
"37"," The Effects of Decision‐Maker Motive on Decision Acceptance                      "
"38","We have seen in Figure 1 that subjects are much less accepting of decisions made by people who appear to be taking advantage of them than they are of identical decisions that did not entail decision makers intentionally using their position to benefit themselves. But the theory of wary cooperation holds that being played for a sucker has the potential to create such serious problems that the brain deals with it differently than other eventualities. In addition to leading to a rejection of certain decisions, aversion to being taken advantage of may also lead to a different type of response in the brain. Social scientists are increasingly using modern medical technology to observe the human brain as decisions are being made. For example, McCabe et al. (2001) used functional magnetic resonance imaging (fMRI) to discover that the brain functions completely differently when cooperation games are played against a computer than when they are played against another human being.20 Similarly, using electroencephalograms (EEGs) instead of fMRIs, Wilson, Stevenson, and Potts (2001) produced preliminary evidence that subjects respond quite differently to simple games in which no assessment of the other player is needed than they do when playing more complicated games with mixed strategies where the actions of the other player matter.         "
"39","In light of these differences in activity, we thought it possible that the brain circuitry involved in reacting to being played for a sucker is quite different from that involved in decisions and outcomes that did not make subjects feel that they had been intentionally victimized. We were not in a position to attach our experimental subjects to medical devices, but we are able to provide suggestive evidence because we made careful note of the amount of time it took subjects to respond to the actions of the divider. Our hypothesis is that when people believe they have been played for a sucker, little time and thinking are needed in formulating a response because the brain is hardwired to react negatively to being played for a sucker but can afford to react to other scenarios at a more measured pace. In some respects, testing this hypothesis constitutes the next stage in understanding differences in brain function across varying situations. The research cited in the previous paragraph shows the differences that exist when human agency is involved and when it is not. In our research, another human is always relevant, but in one case the decision maker has behaved in a self‐serving fashion and in the other case the decision maker has not. If differences in response time are evident, more elaborate tests, preferably with fMRIs would be valuable to learn more about the peculiarities of brain reactions when it is confronted with self‐serving behavior on the part of others."
"40","Our operating hypothesis is that receivers responding to allocators who used their discretion to propose a self‐serving allocation will respond more quickly and viscerally than subjects reacting to allocators who did not use their own discretion (those in the “random” and “desert” categories). We measured the length of time subjects took to respond to the posttest item asking respondents about the fairness/unfairness of the allocator and compared the response time of those subjects victimized by allocator discretion (here we combine allocators who sought power and those who were given it) with those subjects whose allocators left the decision up to chance or desert."
"41","As can be seen from Figure 4, results conform nicely to expectations. Subjects who had been played for a sucker by an allocator who used his/her own discretion to keep $18 of the $20 responded to the fairness/unfairness item relatively quickly, after just 6.6 seconds. But subjects who were not the victims of a self‐serving allocator (but were simply unlucky or undeserving) took well over 10 seconds to respond to the fairness/unfairness item, a difference that is significant at the .01 level.         "
"42"," The Effects of Process on Response Time for “Unfairness” Item                      "
"43","We want to be careful not to overinterpret these results. A difference in response time of three‐and‐one‐half seconds does not constitute conclusive evidence that a new theory of human behavior is needed and available. Nonetheless, the pattern in response time is perfectly consistent with the belief that people are naturally frustrated and even vindictive when they perceive others to have been self‐serving. This pattern, along with the findings presented earlier showing people's tendency to reject self‐serving decisions and to view with disfavor the makers of those decisions, suggests that one of the pillars of our social behavior is quite likely aversion to certain arrangements. People often have a better sense of the procedures they want to avoid than those they want to establish. This is so not because people are unimaginative but because they quite rightly divine the potential threat of an authoritative decision maker bent on furthering his own lot at the people's expense. It is not justice people crave so much as injustice they abhor, and this preference ordering makes perfect biosocial sense."
"44","Both the theory (the evolutionary advantages of certain social behaviors) and the methodology (laboratory experiments) employed in this article are nontraditional. With regard to theoretical perspective, as mentioned previously, we readily concede that evolutionary psychology is not the only theory that could account for the findings we present. Human sensitivity to the social environment could be learned or it could be the product of an urge to be fair, but such assertions beg the question of why people are socially sensitive or interested in fairness. The value of the evolutionary perspective is that it offers an explanation for these traits. Whether this perspective is right or wrong, it is being hotly debated in the other social sciences. Certainly some political scientists have used this theory in their empirical research but they are few in number,21 and the discipline's major journals have largely ignored original investigations that employ the theory. Political science should be more involved in the exchange over this theory even if it is only to present evidence and arguments countering it.         "
"45","Turning to methodology, isolating the effects of process as well as the traits of decision makers requires that the decision itself (the outcome) be controlled. Locating two situations in the real political world in which people view the payoff to them as identical but the decision process as different seems an impossible task. Indeed, simply measuring the payoffs people receive (or think they receive) from a given political decision is probably not feasible. In light of these difficulties, we believe it is reasonable to test the importance of process and traits by using experiments. Still, perhaps the specific design decisions we made prevent the experiments from being as relevant to real decisions and to real politics as could have been the case. We cannot defend our design against every charge but we will address four likely complaints."
"46","First, some psychologists worry that subjects may react differently to monetary payoffs than to nonmonetary payoffs. If true, our results would only apply to political decisions that were thought to involve pocketbook matters and not issues of a more social nature. The consensus, however, certainly among economists, is that the evidence indicates a preference is a preference (whether it is monetary or not) and that the more telling issue is the size of the stakes (see Smith 2000, 16–17), which leads us to the second complaint. Results generated when $20 is at play, as was the case in our experiments, are not likely to be similar to those obtained when $200 or $2,000 is at play. We agree with this point completely, and it has been amply demonstrated in previous research (see Brockner and Weisenfeld 1996; Cameron 1999). Nonmaximizing considerations take on decreasing importance as the stakes are raised. But evidence suggests that for most ordinary people typical political issues are low stakes games (see Hibbing and Theiss‐Morse 2002). Rank‐and‐file Americans simply do not believe they have much invested in run‐of‐the‐mill political outcomes. As such, outside of being prohibitively expensive,22 using high‐stakes laboratory experiments to draw conclusions about people's acceptance of typical political decisions would be grossly misleading.         "
"47","Third, not only did our experiments involve fairly small‐stakes monetary payoffs, they involved a situation in which subjects received an inappropriately small payoff. The mean allocation in a $20 ultimatum game is between $7 and $8. The allocation in our experiment was just $2. Again, we do not deny (and previous research has demonstrated) that other payoffs would lead to different behaviors on the part of the receiving subject. Our reason for incorporating a relatively unsatisfying allocation into the experiment is the fact that public opinion research has indicated that most Americans feel they do not receive their fair share of resources from the government. We wanted to replicate this environment by making subjects feel they had not received a fair share from the allocator. Finally, our experiment was single‐shot (not multiple‐play), meaning subjects were told that, subsequent to the one game, they would not be interacting any more with the other player. Why? Of course, cooperative behavior goes up in typical multiple‐play laboratory games because players believe (rightly) that their actions in Round 1 will affect the decisions of their compatriot in Round 2 and beyond. This is unlikely to be the case in repeat interactions with the government, however. Roles in the game are never reversed since the government is always the allocator; moreover, the government is rarely influenced by an individual receiver's acceptance/rejection of an earlier decision. So a multiple‐play laboratory experiment seemed unnecessary and perhaps even ill‐designed to capture the realities of citizen reactions to governmental allocation decisions."
"48","Even as we believe our decisions are defensible, we see great value in subsequent research manipulating our design so that the consequences of these changes can be observed. In fact, this approach is the only way we will obtain a more complete view of the conditions under which people tend to accept or reject authoritative decisions. Absent this empirical research, all that is possible is idle speculation about what a reader thinks might have happened if this feature or that had been altered. If our research does nothing more than stimulate further empirical research on the effects of political decision‐making processes, we will have accomplished something."
"49","And just what do our findings have to say about these effects? That if people are convinced the political process makes it impossible for decision makers to benefit themselves at the expense of non‐decision makers, they will be surprisingly accepting of governmental decisions, even those that are unfavorable to them from a substantive point of view.23 This is especially true if the people believe that decision makers did not want to be decision makers in the first place. With apologies to Groucho Marx, people do not want an individual to be a member of the decision‐making group if the individual wants to be a member of that group.         "
"50","The key question people ask in determining how they will react to a governmental decision is not, “what did I get?” It is, “have I been screwed?” Far from being a quirk, an anomaly, an oddity, or a learned reaction, people's intense desires to contribute but to avoid being taken advantage of, even if acting on these desires means getting less of a payoff than they otherwise would, are core compositional features of humans. And these features would appear to have important implications for politics generally and specifically for the kind of authoritative decisions people are likely to accept and to reject. People will accept decisions that ask them to sacrifice if they believe others (especially decision makers) are behaving appropriately, but if they believe others are behaving in a self‐serving fashion, they will not only cease cooperating, they will spend their own resources to punish the malefactor."
"51","The essence of the human condition may not be pretty but it is sensible from the point of view of a species reliant upon viable group environments. In struggling to understand political and other behavior, we must recognize that this essence is embodied in neither the peaceful, unambitious, totally altruistic, noble savage of Rousseau nor the self‐obsessed, uncaring, materialistic demander of immediate tangible gratification described by Hobbes. Altruists and egoists walk among us but they are overwhelmed everywhere and always by wary cooperators."
