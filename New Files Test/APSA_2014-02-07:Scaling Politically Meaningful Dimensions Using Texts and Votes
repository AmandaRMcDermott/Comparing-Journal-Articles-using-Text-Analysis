"","x"
"1","Scholars have increasingly argued that additional information is required to make sense of spatial preference estimates in a variety of contexts, ranging across the European Parliament (Hix and Crombez 2005), the U.S. Congress (Crespin and Rohde 2010), the Brazilian legislature (Zucco and Lauderdale 2011), and the U.S. Supreme Court (Lauderdale and Clark 2012). The goal of leveraging metadata is to overcome the limitations of multidimensional scaling models, which only recover dimensions in voting behavior that maximize statistical fit, even when those dimensions conflate many substantive dimensions scholars want to study. Metadata about the subject of particular votes have the potential to provide the estimator with information about the substantive meaning of the dimensions.         "
"2","To understand the intuition, consider a comparison between scaling models in political science and in educational testing. Major educational tests like the SAT and ACT are split into sections—math, verbal, and so forth—based on the test designers' knowledge of what the questions are about. This is viewed as preferable to attempting to recover multiple traits from an undifferentiated collection of test items because it does not require the scaling model to be able to differentiate the questions into different topics. By contrast, traditional multidimensional scaling in political science is akin to educational tests in which the verbal, math, and other questions are collectively scaled in two (or more) dimensions, without any labeling of which questions are expected to test which abilities. The consequence is uncertainty about what is being measured, which is avoided in the educational testing context by writing separate tests that each aim to test primarily a single ability of interest. Fortunately, while political actors do not usually provide researchers tidy, discrete categorizations of which votes are about which issues, they do provide metadata information—texts of bills, opinions, oral arguments, and legislative debates; citation data to legal statutes and precedent cases; and so forth—that can help us figure out what their votes were about and what preference dimensions those votes reveal. While manual coding of votes into discrete categories is a viable approach in some applications, political scientists often examine large sets of votes, making automatic processing of metadata valuable."
"3","We focus on textual metadata in this article. The most widely analyzed quantitative feature of texts—relative usage of different terms—tends to reveal a great deal about what issues are being discussed. For example, consider the Supreme Court case Florence v. Board of Chosen Freeholders of the County of Burlington, decided in 2012. This case considered whether police need to have specific reasons to suspect contraband in order to conduct a strip search of an individual who is already being jailed. The majority opinion repeatedly uses terms like jail (50 appearances), search (45), detainee (37), inmate (28), contraband (27) and drug (14), which also appear frequently in some other Court decisions but appear rarely in most opinions. One can infer that the subject of the Florence case is more similar to opinions that use terms like detainee and search than opinions that do not use those terms. Of course, there are other terms like petitioner (23) that are much more generic features of Supreme Court opinion texts and provide little information about which issues are at stake. Using a statistical model of text, we can determine a mix of issues implicated in the opinions. Our approach relies on the assumption that this mix also reveals which preference dimensions are relevant to this vote. A text that is purely about a single issue is assumed to imply a vote that only depends on preferences on that issue.         "
"4","Consider a simple example, with just two issue dimensions. Voter i has a position  on issue A and  on issue B. The question for any given vote is this: to what extent is that vote about issue A and to what extent is that vote about issue B? Our approach is to use the text to estimate the answer. Specifically, let  represent the degree to which the vote is about issue A and  represent the degree to which the vote is about issue B, where , and . Figure 1 shows several special cases for this two‐dimensional spatial model. Panel A shows possible cutting lines—the lines separating yes voters from no voters—if the vote is entirely about issue A (). Different cutting lines will correspond to different coalitions of yes and no voters, but only  will predict the behavior of any voter i. On such votes, preferences with respect to issue B are irrelevant to voting behavior. Panel B shows the corresponding case for votes that are purely on issue B.         "
"5","Cutting Lines for Several Mixtures of Two Topics"
"6","Note: The top left panel (A) shows possible cutting lines that can be estimated given a text that is entirely drawn from issue A. The top right panel (B) shows possible cutting lines that can be estimated given a text that is entirely drawn from issue B. The bottom left panel (C) shows possible cutting lines that can be estimated given a text that is equally drawn from issues A and B. The bottom right panel (D) shows cutting lines that are impossible under the model.                     "
"7","Panel C shows the case of a bill that is equally about issue A and issue B (). We assume that the weight each dimension plays in each vote is directly proportional to the proportion of text coming from each issue. We measure a vector  such that each element  and  from the text, and then apply these relative weights to voter i's position  across dimension d in determining her latent voting preferences on vote j. These are nontrivial identifying assumptions: they determine how observed votes that mix multiple issues shape our estimates of preferences across those issues.         "
"8","Panel D shows cutting lines that are impossible under the model. These are cutting lines that would describe coalitions of issue A conservatives with issue B liberals opposing coalitions of issue A liberals with issue B conservatives. While such coalitions are, of course, conceptually and politically possible, ruling them out by assumption is a consequence of using a vector of mixture weights  to identify the rotation of the cutting line. A valuable side effect is that this restriction on which cutting lines—more generally, hyperplanes—are allowed enforces consistent liberal/conservative labeling across dimensions. Nearly all of the possible rotations and reflections of the space that do not change predicted voting patterns under a standard multidimensional IRT model (Rivers 2003) do change predicted voting patterns under our model because of this restriction.         "
"9","In principle, we could estimate the orientation of the cutting hyperplanes for each vote using any of a variety of models to map textual data about votes into vectors of mixture components . LDA is well suited to generating suitable , using minimally processed text and without prior specification of topics. Many other approaches are possible, including discrete topic models for text or expert issue codings, that would only allow a single preference dimension to predict each vote.         "
"10","Our model has two major components. We first estimate the latent distribution of topics across and within a series of documents using LDA. We then use the posterior estimates of the distribution of topics for each text from the LDA model to model the extent to which the vote on that text was about each dimension. The LDA portion of the model is identical in specification and implementation to previous MCMC implementations (Griffiths, and Steyvers 2004; Heinrich 2009); however, we change some notation for compatibility with the notation of the voting model. The notation for indices, parameters, and data in the model is listed in Table 1.            "
"11","The LDA model terminology refers to words, terms, topics, and documents. A document is considered a sequence of words. Each word is an instance of a particular term. For example, the sentence “The Republican and the Democrat disagreed” has six words and five terms (the term the appears as both the first and fourth word). LDA assumes the relative frequency of different terms in different documents reveals which topics are being discussed. The model can be summarized as follows. Each word that appears in a document is assumed to have a latent topic. The latent topic  for word k in document j is assumed to be a multinomial draw from the distribution of topics in that document: . The observed term  for word k in document j is assumed to be a multinomial draw from the distribution of terms in the latent topic : . The multinomial parameter vector describing the distribution of terms t within each topic d is assumed to be a draw from a Dirichlet distribution with hyper parameters : . The multinomial parameter vector describing the distribution of topics d within each document j is assumed to be a draw from a Dirichlet distribution with hyperparameters : . The model assumes that a set of topics describes variation in term use across the corpus of documents: the topic for each word location in each document is a multinomial draw from a distribution of topics characteristic of that document, and the actual term that appears in that word location is a multinomial draw from the distribution of terms characteristic of that topic.            "
"12","We are particularly interested in the , the vectors of mixture components describing the fraction of the text for each vote  that is in each topic . We are also interested in the term frequency distributions  for each topic, since these allow us to substantively label the topics by calculating which terms are most indicative of a word being drawn from each topic.            "
"13","In D dimensions, the Jackman (2001) model for observed votes  has the following form:               "
"14","For the LDA model, the choice of priors determines the symmetry and sparsity of the recovered topics. We use symmetric Dirichlet priors, which yields topics of roughly equal total text length. While this may not be ideal for all topic‐modeling applications (Wallach, Mimno, and McCallum 2009), it ensures that roughly equal quantities of voting data are brought to bear on estimating each dimension. Having chosen symmetric priors, we still must choose the values of the hyperparameters γ and δ. Smaller values of γ lead to more decisive assignments of documents to a small set of topics. Smaller values of δ lead to more decisive assignments of terms to a small set of topics. We are more interested in decisive assignment of documents to topics than terms to topics, so we assume different values than those recommended in the literature (Griffiths, and Steyvers 2004). We set the hyperparameter for the assignment of topics within documents equal to  and the hyperparameter for the assignment of terms to topics .            "
"15","For the IRT model, we use normal priors with mean 0 and variance 4 for the vote parameters  and :  and . For the ideal points, we assume a multivariate normal prior with mean 0, and a covariance matrix with 1 on the diagonal and  off the diagonal. The mean of 0 centers the ideal point scale, and the diagonal components of the variance matrix define the spread of the ideal point scale. The positive off‐diagonal elements of the variance matrix orient all the issue‐specific dimensions with conservatives at the same ends and provides shrinkage of ideal points in each dimension to their common mean across dimensions. We put a uniform prior over positive values of this correlation: .1"
"16","We estimate our model by MCMC simulation. Our estimator is built from the LDA collapsed Gibbs sampler described by Griffiths and Steyvers (2004) and the IRT Gibbs sampler described by Jackman (2001). Rather than estimating a fully joint model we simulate the LDA model, and then condition the IRT model on the current draw of  from the LDA model. We describe our sampling procedure in the online appendix.            "
"17","Choosing the best number of topics for a topic model is a difficult problem in general, and several additional considerations are introduced by our application of the topic mixture vector  to predicting votes. A common approach to assessing the best number of topics in LDA modeling is to assess the model's perplexity under a number of topics (Blei, Ng, and Jordan 2003). Perplexity is a measure that evaluates how well the model predicts held‐out textual data. This criterion is used to find when adding more topics stops making appreciable increases in the model's predictive power; however, such a criterion is only appropriate if the goal is predicting the textual data. Our goal, by contrast, is predictions of roll‐call votes. If we estimate too few topics, we will fail to find variation in preferences across issues that could improve the predictive power of the ideal point estimates. If we estimate too many topics, we will have only a few votes on each issue and will lack sufficient data to learn much about preferences on that issue. To balance these concerns about having enough votes per topic with having enough topics to adequately describe the voting space, we use the deviance information criterion (DIC; Spiegelhalter et al. 2002) to optimize predictive power of the ideal points for votes. Because we estimate the LDA and IRT models in two steps, we can easily calculate the DIC on the basis of only the latter. Where the deviance , we calculate the DIC as two times the mean posterior deviance minus the deviance of the mean posterior estimates of the parameters:               "
"18","Our model assumes that all voters are voting on the same mixture of dimensions: if 35% of the text is from topic A and 65% from topic B, then every voter's preference is a 35–65 weighted average of his or her preferences on dimensions A and B. This assumption is required for model identification, but there are two possible substantive objections in our application. First, the proportions of text are surely not identical to the relative importance that the justices put on each of the two dimensions in making their decisions. Second, the justices may differ in which dimension they think is most relevant to a given case. Unfortunately, if we explicitly allow justices to respond to different mixtures of dimensions, by using only the opinion texts that a given justice wrote or joined, the preference scales we estimate will no longer be comparable across justices. However, even if justices really are responding to somewhat different dimensions, our approach is a reasonable approximation. This is also an argument in favor of assigning cases to mixtures of topics, rather than using a discrete topic model or a discrete expert coding: if the justices talk about multiple issue areas in their opinions, allowing their preferences in all those areas to predict their decisions is a more reasonable compromise than identifying just one area."
"19","There are two senses in which the estimates we derive under this approach are not unique. First, as noted previously, the LDA model combined with text is only one way to generate a matrix of weights  for each vote j across each dimension d. Each method for defining  will define a different multidimensional preference space. This is sufficient to meet the identification restrictions identified by Rivers (2003); however, it is vital that one uses information that is appropriate for defining a meaningful, multidimensional political space. This is more or less guaranteed if one uses a type of metadata that immediately provides a valid  matrix. For the Supreme Court, the Spaeth issue and issue area codes provide an expert, discrete issue coding, which we discuss in comparison to our estimated topics later in this article. For legislatures, originating committee is often used as a topic coding. For textual and other sources of metadata, it is important to have a substantive justification for why the chosen metadata model provides a useful and meaningful mapping of votes onto dimensions. In our application below, we provide this justification with reference to the limitations of the Spaeth codes by examining the details of the recovered topics and by demonstrating that the estimates generate novel insights into preference variation on the Court.            "
"20","Second, even once one has decided to fit a topic model on a particular set of texts to define the , it is important to recognize that such models do not yield “definitive” topical decompositions (Blei and Lafferty 2009). The idea of “topics” is useful for characterizing variation, but there are no “true topics” to discover in the data. Thus, there is no generally “correct” answer to the dimensionality issue. The performance of the models in terms of fit (as assessed by the DIC) will vary to the extent that the topical decomposition tracks the underlying variation in the preferences of the voters. Moreover, when LDA is estimated by MCMC as in this article, it does not generate exactly the same topics each time it is reestimated. The appropriate way to think about this is as a descriptive model: we find a set of topics that explains variation in term usage, but those topics are not fixed. For some applications, having a fixed‐topic coding scheme is vital, and so a supervised topic model for text should be used (Blei and McAuliffe 2007; Hopkins and King 2010). However, for exploratory analyses like the one we describe below, an unsupervised topic model works well and does not demand any ex ante specification of political issues. Analysts must exercise substantive judgment about the political spaces they wish to use to describe preferences; they must choose whether they want to generate a space via an exploratory tool like LDA or instead use some other method that allows greater control over the recovered space.            "
"21","The model we develop above is broadly applicable to many political institutions. The voting data modeled with the IRT model must be linked to documents that vary in term usage primarily as a function of the issues at stake in the vote. Such texts are not hard to find: legislators often have recorded debates about proposed laws, courts write opinions summarizing the issues and legal questions associated with the particular case they are deciding, and bodies like the United Nations vote on resolution and treaty texts. To illustrate the utility of our model, we employ data from the U.S. Supreme Court. Our roll‐call data consist of 4,321 nonunanimous Supreme Court decisions from 1949 to 2006. These include the votes of 30 justices, of whom no more than nine were involved in any single decision. The text we associate with each decision is that of the opinions in a case.2 We employ the full text of opinions, rather than isolating specific aspects, such as the holding, because we believe the larger content of the opinion is important for establishing the mix of issues considered by the Court.         "
"22","In order to fit the model, the first question we must consider is the dimensionality of the model we wish to estimate: how many topics for the LDA model best fit the voting data? To roughly estimate the appropriate number of dimensions, we ran short simulations—2,000‐iteration burn‐in, 4,000‐iteration sample—for a range of topic counts from 1 to 40 to find which numbers of topics lead to the best prediction of votes by the DIC as described above. Figure 2 shows the results of these simulations. We find improvement in the DIC up to around 25 topics, and little improvement beyond. The predictive power of the model does not get worse either, primarily due to the cross‐dimensional shrinkage of the ideal points.         "
"23","There is no “correct” number of dimensions. We select 24 dimensions for further analysis because that number seems to provide a reasonable point at which further marginal decreases in the DIC are small. Just as importantly, when we look at the terms that are most characteristic of each topic, this is also around the point at which additional substantive nuance diminishes. Making this evaluation is not amenable to a statistical criterion, but we can see the principle in action by considering the topics recovered when we fit a two‐dimensional model. As Figure 2 shows, this model represents a significant improvement in fit over the one‐dimensional model. The two topics recovered from the texts describe the two major functions of the Supreme Court: some of the terms that are most indicative of the first dimension are act, congress, and federal, whereas some of the terms that are most indicative of the second dimension are trial, jury, and evidence. The first dimension captures constitutional review of the legislative and executive branches: acts of Congress, issues of federalism, taxes, etc. The second dimension captures oversight and administration of the judiciary: criminal defendants' rights, rules of criminal and civil procedure, etc. However, as we show below when we examine the 24‐dimensional fit, we can recover many more than two substantively meaningful topics, and as the DIC above indicates, this improves predictive performance. In other words, a combination of both statistical fit and substantive inspection should guide selection of dimensions.         "
"24","Unlike most potential applications of our model, for the Supreme Court we have an existing expert coding to compare to the LDA model's assignment of texts to topics. Issue area codings are available from the Supreme Court Database (Spaeth et al. ). Figure 3 is a heat map showing the distribution of Spaeth issue areas across LDA topics. We adopt the common practice of using the top three terms for each topic as a label. For example, union, labor, and board are the most distinctive terms in a topic consisting of text related to union regulation.3 While our 24 topics are necessarily distinct from the 13 issue areas, there is much in common. Relatively unpopulated Spaeth issue areas like Unions, Interstate Relations, Federal Taxation, and Miscellaneous fall heavily into single LDA topic areas, whereas more common issue areas involve cases that mix across multiple topics.            "
"25","Spaeth issue areas versus LDA issues."
"26","Note: The figure shows the frequency with which each Spaeth issue area is attached to each LDA topic. Darker shades correspond to more frequent appearance.                        "
"27","These estimated topics turn out to be superior for predicting variation in justices' voting behavior. We compared the DIC from estimates based on a 13‐dimensional LDA topic model to the DIC from estimates using the Spaeth issue area codings to define the λ matrix and found that the former was lower. We then converted these 13‐dimensional topic estimates from the LDA model into a discrete topic coding by assigning each case j to the category d that had the largest estimated . Using the discretized LDA topic assignments, there was still an improvement in DIC versus the Spaeth assignments, but not as large. Thus, in a comparison of 13 dimensional models, some of the gain in prediction versus Spaeth is due to using texts rather than the Spaeth coding scheme, and some is due to allowing cases to be assigned to mixtures of topics.4 Further gains in prediction then arise from moving from 13 to 24 topics.            "
"28","The fact that some of our gains in predictive power are due to the fact that cases can be assigned to multiple topics, with estimated weights, highlights one of the advantages of our approach versus expert coding. In matters as complex as litigation or legislation—the matters on which we often scale votes—preferences over multiple issues may influence decisions. Depending on coding rules, an expert coder might be forced to choose a single topic to assign a vote, might have the option of selecting multiple issues without specifying their relative weight, or might have the option to assign weights to topics. In the former two scenarios, we do not have the benefit of knowing how relevant different topics are; in the final scenario, the coder has a very difficult task and reliability may be low. The text‐based approach avoids these pitfalls by employing a clearly specified model of topic mixtures and relying on straightforwardly measured information: the distribution of terms in documents. This is not to say that the expert‐coded topics convey no information, only that the gains they provide over a unidimensional model are not as large as the gains from the mixture topics we recover from the opinion texts. If no texts were available, using this kind of discrete coding to define the  would be a good way to proceed.            "
"29","Figure 4 shows the relative fraction of text in each LDA topic over time. Some topics— “negligence,” “maritime,” “admiralty,” and “commission,” “rates,” “gas”—are far more prevalent early in the period, whereas others appear only after specific legislative or legal events— “title,” “vii,” “employment,” and “child,” “abortion,” “children.” Consider cases dealing with the death penalty (the topic associated with the terms jury, death, and penalty). We see a relatively low level of representation by this topic during the early period here, followed by a steady increase from about 1970 through 1990, and then a subsequent leveling off or even decrease over the next 15 years. This pattern is consistent with qualitative studies of the death penalty, which document increased litigation during the 1970s and 1980s, followed by a slight decrease during the 1990s (e.g., Walker 2009). As another example, consider the topic related to abortion cases (the topic associated with the terms child, abortion, and children). We see a spike in this topic during the 1970s, followed by a steady decrease from 1980 through 2000. This pattern comports with other studies of doctrine that show in the wake of Roe v. Wade (1973), there was a lot of Supreme Court litigation that sought to clarify and extend the rule announced in Roe, whereas the Supreme Court has paid less attention to this line of doctrine since the mid‐1980s (e.g., Clark and Lauderdale 2012). As a final example, consider the topic associated with the terms district, habeas, and appeal. We see here a spike during the Warren Court era (1953–1968), followed by a sharp decrease during the Burger Court (1968–1986), and then a slower but steady increase during the Rehnquist Court years (1986–2005). This pattern comports with conventional understandings—namely, that the Warren Court spent a lot of time dealing with the rights of criminal defendants, that the Burger Court turned its attention away from such cases, and that the Rehnquist Court again returned to these cases (albeit from a different ideological perspective than that of the Warren Court).            "
"30","Frequency of Issue Appearance over Time"
"31","Note: Each panel shows the frequency of appearance for each issue over time. The title of each panel is the top three most distinctive terms for the issue. Gray regions identify the chief justice. The four chief justices included in these data are, chronologically, Vinson, Warren, Burger, and Rehnquist.                        "
"32","Turning from the content of the Supreme Court's docket to the preference estimates, in Figure 5, we show the relative positions of the 30 justices in our data, in each issue area. Justice Douglas is not visible on the plots, as he is so far off the left edge of the scale that including him would obscure the more relevant differences between other justices. The justices are listed from top to bottom in decreasing average ideal points across all issue dimensions. The justices' rank orderings across issue dimensions are correlated, but not perfectly so. The preferences in two tax issues—“property”, “income”, “tax” and “tax”, “commerce”, “interstate”—are very weakly related to preferences in the other dimensions. We also find that the category “congress”, “act”, “usc”, which contains generic terms related to all Court reviews of congressional statutes, has an ordering that is weakly related to other issues. The more that the text of a case's opinions comes from this category, the more that text is about abstract issues related to judicial review in general, and so it is perhaps unsurprising that the typical preference ordering of the Court applies less and less in these cases. In these three areas, it is not just the case that the orderings of justices are atypical, but it is also the case that we cannot be very confident of any ordering. There is not much difference among the justices on these issues. This result is one that is alluded to among scholars of the courts, though rarely documented (but see Martin and Quinn , 4).            "
"33","Justice Locations for Each Issue"
"34","Note: Each panel shows the posterior mean and standard deviation for each justice, in each issue. The title of each panel is the top three most distinctive terms for the issue. Justices are sorted on their average positions across all dimensions. Justice Douglas's estimated positions are to the negative extreme of each dimension and are excluded to maintain legibility for the remaining justices.                        "
"35","The model recovers a number of features that one should expect to find, providing evidence of the model's validity. For example, as noted, Justice Douglas is the left‐most justice on all dimensions, whereas the two most conservative justices on most dimensions are Justices Thomas and Scalia (they are the top two justices depicted in each panel of Figure 5). One exception is the topic associated with the terms “property,” “income,” and “tax,” which does not exhibit much variation in the justices' expressed preferences at all. However, the model does more than just recover well‐known ideological consistencies among extremist justices; there are many examples of individual justices with peculiar views in particular issue areas. For example, it has been previously documented that Justice Black had more conservative views on issues of criminal rights than on other issues (e.g., Lauderdale and Clark 2012; Newman 1997), and this pattern is recovered here, as is apparent in the topic “search,” “fourth,” “warrant;” the topic “prison,” “inmates,” and “parole” and the topic “jury,” “death,” “penalty.” Taken together, the patterns depicted in Figures 3-5 show that our model is capturing substantively meaningful dimensions of judicial decision making and substantively relevant variation in the justices' preferences across those dimensions.5"
"36","Figure 6 shows the location of the median for each topic for each of the 57 years covered by our data. These issue‐specific consequences of justice replacement are entirely masked by unidimensional preference estimates. For example, most models of judicial preferences suggest the Court became increasingly liberal during the Warren Court and has turned in a conservative direction since, primarily due to justice replacement. This general pattern is reflected in our estimates—the median justice moves to the left on most topics during the Warren Court. However, that overall trend has a number of interesting exceptions, which demonstrate the heterogeneity of preferences across topics. Consider the topics associated with economic issues, such as “antitrust,” “price,” and “securities”; “union,” “labor,” and “board”; and “commission,” “rates,” and “gas.” These topics are associated with little change, or even conservative change, during the Warren Court. Indeed, the justices appointed by President Franklin Roosevelt, who served until the 1950s, were particularly liberal on topics of economic regulation (they were chosen for that very reason), and as a consequence, their replacements during the Warren Court actually shifted the Court to the right, rather than the left, on these topics. At the same time, we find the anticipated pattern that the Warren Court moved farthest to the left on issues relating to civil rights and civil liberties.            "
"37","Location of median justice over time for each issue."
"38","Note: Each panel shows the location of the median justice for a given topic, over time. The title of each panel is the top three most distinctive terms for the issue. Medians are calculated term‐by‐term; terms with Court composition change use the longest Court composition during that term.                        "
"39","The location of the median justice across the various topics similarly helps identify when, and on what issues, the Court has moved in a conservative direction since the late 1960s. A conventional understanding of the Burger Court is that President Richard Nixon's attempt to move the Court to the right was a failure, though some have recently argued that this is largely because Nixon was focused on a few issues and did not really want to effect a wholesale conservative revolution on the bench (e.g., McMahon 2011). Figure 6 reveals that the Nixon appointees in fact effected a fairly dramatic conservative shift on issues of civil liberties and criminal procedure, whereas they brought about a much smaller shift on other issues, such as labor rights and employment discrimination, economic regulation, and religion.            "
"40","This discussion of topic‐by‐topic preferences requires some caveats. Only a few of the cases are assigned entirely to a single topic; many cases are a mix of topics. While this motivates the structure of the model, it also raises the question of how we should interpret preferences on a single dimension. One answer is to note that the distribution of posterior assignment probabilities is highly bimodal, with posterior probabilities nearly 0% for most topics and over 90% for a single topic. Thus, many cases map mostly to a single topic. The notable exception to this pattern is the topic associated with procedural issues and statutory interpretation (“congress,” “act,” “usc”). Some cases are entirely about procedural issues, but among those that are not, there is often a considerable procedural question presented in the case. A second answer is that even in the absence of a case that is entirely contained within a single topic, knowing the Court's median with respect to that topic informs our understanding of how cases implicating the topic change over time. For example, at the same time that the median justice was becoming increasingly liberal on issues of free speech and criminal procedure (during the Warren Court), the median was not changing (or even becoming more conservative) on issues of religion and public schools and labor‐business relations. The implication is that cases blending free speech and union issues would experience a less liberal shift than a case blending free speech and criminal procedure. The issue‐specific ideal points can be thought of as indices of ideal types: measuring relative conservatism within a specific issue, recognizing that many cases will blend together multiple topics."
"41","The measurement model we have proposed does more than simply introduce a substantively grounded multidimensional ideal point model that is portable to any number of institutional settings. It also opens the door to new theoretical questions scholars were not previously able to study. In this section, we briefly describe three of the applications and implications of our estimates of Supreme Court ideal points: the politics of judicial nominations, the development of law, and roll‐call analysis."
"42","Students of politics have spent considerable time studying the impact of executive nominations to courts, agencies, and other bodies. Confirmation battles over Supreme Court nominees have become particularly contentious over the past 30 years. In this vein, the literature has increasingly focused on the extent to which any given nomination will affect the median of the Court, as that is usually seen as an important indicator of the policy consequences of a nomination (Krehbiel 2007). Our analysis demonstrates that the consequences of replacing a justice may vary across areas of the law because the justices differ in their relative rank orderings across areas of the law (see Lauderdale and Clark 2012).            "
"43","As an illustrative example of how an analysis of confirmation politics may play out, consider the replacement of Justice O'Connor by Justice Alito in 2005. In general, through the 1990s and early 2000s, Justice O'Connor and Justice Kennedy were two pivotal members of the Court. With four relatively liberal justices (Stevens, Souter, Ginsburg, and Breyer) and three relatively conservative justices (Rehnquist, Scalia, and Thomas), how these two justices voted on any given case was often dispositive."
"44","Figure 7 shows the posterior distribution of the difference between Justice Kennedy and Justice O'Connor's positions for each of our 24 dimensions. Positive values indicate Kennedy being more conservative than O'Connor; negative values indicate Kennedy being more liberal than O'Connor. The plots reveal that we have high posterior confidence that O'Connor was to the left of Kennedy on roughly six issues, whereas Kennedy was to the left of O'Connor on roughly four issues. Importantly, this comparison helps illuminate the substantive impact of O'Connor's departure from the Court in 2005, which is widely believed to have left Kennedy as the dominant median justice on the bench (Lane 2006; Lithwick 2006). However, our estimates suggest the ideological impact of this change should depend on the subject matter.            "
"45","Comparison of Justice Kennedy's and Justice O'Connor's Ideal Points on Each Issue dimension"
"46","Note: Each row shows the posterior distribution of the difference between Kennedy's and O'Connor's ideal points, with the median posterior and central 90% interval depicted along the x‐axis. The label of each row is the top three most distinctive terms for the issue.                        "
"47","Indeed, these expectations are borne out in the data. Table 2 compares the ideological orientation of the Court's disposition—as coded in the Supreme Court Database (Spaeth et al. )—in cases involving eight issues both before and after O'Connor's departure from the Court. In the top half of the table, we consider the cases where our preference estimates suggest her replacement by Alito should have a conservative effect—employment discrimination, abortion, the death penalty, and religious freedom. While the numbers of cases are small, we see that in each of these areas, the rate of liberal decisions has declined. In the bottom half of the table, we consider the cases where our preference estimates suggest her replacement by Alito should have little effect—securities regulation, employment arbitration, patents and copyrights, and attorneys' fees. In these four areas, we see no shift toward conservative decisions; in fact, if anything, there is a shift in the liberal direction since O'Connor left the Court.            "
"48","In a small voting chamber like the U.S. Supreme Court, variation in preferences across issues can be highly consequential. Consider the landmark ruling in Citizens United v. FEC (2010), which held corporations may spend unlimited amounts of money on behalf of political campaigns. The ruling has had significant implications for American politics in the years since, and there is good reason to believe that the 5–4 decision would have come out the other way had Sandra Day O'Connor still been on the Court. Recent journalistic accounts note that in earlier challenges to the campaign finance restrictions, O'Connor had sided in support of the FEC, and it was only after her replacement by Justice Alito that the Court tilted in favor of corporate spending (Toobin 2012). As we see in Figure 7, Kennedy is indeed to the right of O'Connor on the “political,” “election,” “party” topic.            "
"49","The upshot of this discussion is that we might expect different kinds of struggles to emerge during a judicial nomination, as a justice's departure may affect different issues differently. When Kennedy departs the Court, there will likely be much debate, as he is currently so pivotal on many issues. While our approach cannot provide estimates by issue for a nominee before he or she joins the Court, it can identify those areas of law in which Kennedy is the median, and therefore his replacement is guaranteed to move the median in one direction or the other. In areas where Kennedy is not the median, a new justice will only shift the median of the Court if the new justice is on the opposite side of the median from Kennedy."
"50","A second implication and potential future application of our analysis concerns the development of law in the U.S. Supreme Court. Scholars have long been interested in how doctrine and case law build sequentially through a series of decisions, and much attention has been paid to the use of strategic litigation to shape development of the law. Some of that scholarship has focused on the incentives created by changing membership on the Court to being new cases. Our analysis suggests that, even given a fixed membership on the Court, a strategic litigant may be able to shape the law by framing cases in a particular way. For example, our analysis reveals that Justice Kennedy is relatively conservative on topics of religion and relatively liberal on topics of individual freedom."
"51","Theoretical models of multidimensional preferences in judicial rule making have gained more attention in recent years (Lax 2007). One of the central questions in the economic and political science analysis of legal doctrine concerns how different cases, presenting different mixes of issues, interact over time to build a body of doctrine (Gennaioli and Shleifer 2007; Kornhauser 1992). Indeed, some empirical work has been directly concerned with this dynamic (e.g., Epstein and Kobylka 1992; Wedeking 2010). Our methodology provides an opportunity to gain empirical leverage on the theoretical tensions those models isolate. Our approach allows analysts to investigate the dimensionality of judicial voting and evaluate theoretical predictions about how different mixes of dimensions will split judges differently. This type of analysis might be particularly useful for the analysis of strategic litigation by policy‐minded litigants in combination with methods for scaling the content of the opinions themselves (e.g., Clark and Lauderdale 2010).            "
"52","A third implication and potential future application of our methodology extends beyond the judicial politics examples on which we have focused thus far. The method we propose for discovering and describing the dimensionality of a voting space is particularly attractive for estimating multidimensional ideal points in small chambers. However, even in the context of a large voting body, where existing methods work more reliably, our method has the advantage that the dimensions are substantively defined. The requirements for any future application are only (1) a matrix of voting data and (2) a source of metadata that can be used to generate mixture or discrete assignments to dimensions. Here we have used the texts of judicial opinions to assign cases to a set of dimensions. Alternatively, one might use expert codings of case topics (such as the issue codes in the U.S. Supreme Court Database or the topic codes from the Policy Agendas Project). The critical component is that one is able to generate a matrix  that defines a meaningful political space in which to map voting behavior.            "
"53","The rise of widely available metadata on political voting—such as text of debates and legislation—is, we believe, a particularly promising avenue for such applications in the future. Students of supranational legislative and judicial institutions, for example, have access to increasingly extensive textual information and also are becoming increasingly interested in more nuanced descriptions of cleavages on the Inter‐American Court of Human Rights, the European Court of Human Rights, the European Parliament, the United Nations General Assembly, and the World Trade Organization, among others. One of the most compelling applications of our method is exploratory: it can be used in conjunction with many forms of metadata to discover and summarize the nature of political cleavages in both large and small voting bodies."
"54","The model we describe in this article does not generate sets of ideal point estimates that we can call the ideal points of the actors. There is no true number of issues to be uncovered; the number of issues we can usefully estimate is in part a function of data density, rather than any fundamental truth about how many issues a voting body considers. Indeed, in our example, a wide range of values for the number of estimated topics all yield roughly equal values of the DIC, the criterion that we use to evaluate fit. However, this limitation is fundamental to all scaling models. Ideal point estimates exist on scales that researchers create: they are useful fictions that help us describe patterns in large data sets. Similarly, our approach does not remove the need to carefully consider whether a scale is appropriate to use as an explanatory variable in a secondary analysis (Martin and Quinn ). Analysts need to consider whether using measures of issue‐specific ideology that are derived from voting behavior—whether at large or in a domain identified by word use in opinion (or other) texts—creates a threat to the kind of inference that they intend to make.         "
"55","Unidimensional ideal points provide especially parsimonious summaries of political conflict in legislative and judicial bodies, reducing a large matrix of voting patterns to a single measure of relative preference. But while these are useful first‐order approximations to behavior, politics is not so simple as one (or even two) dimension(s). Methodological obstacles have kept scholars from getting much more from ideal point estimators than the first two dimensions. Even in two dimensions, identification and interpretation problems quickly dominate the process of analyzing roll call data: only by simultaneously examining actors with extreme positions and votes with large loadings on particular dimensions can labels be put on a standard ideal point estimates, whether those estimates come from NOMINATE, optimal classification or Bayesian IRT. Beyond two dimensions, these informal labeling techniques quickly become infeasible. Researchers have sought to overcome these problems by leveraging metadata to overcome identification and interpretation problems (e.g., Clinton and Meirowitz 2003; Jessee 2009; Lauderdale and Clark 2012; Zucco and Lauderdale 2011), though these approaches have tended to be methodologically tied to the particular institutions under study in ways that limit their general applicability.         "
"56","Our approach provides better descriptions than previous ideal point estimation techniques because it addresses the reductionism problem and the labeling problem simultaneously, while also being generally applicable to the full variety of roll–call data that researchers have examined. Using textual data enables more nuanced descriptions of voting behavior, with that nuance provided in terms of the actual terms that describe the issues at stake. Unsupervised text models like LDA, applied to vote‐specific texts, are an excellent tool for exploratory analyses like the one we present here. Supervised text models, which impose a predefined categorization, will be useful for estimating issue preferences on particular topics of interest to researchers. More broadly, any clustering algorithm or mixture model, applied to vote‐specific metadata that vary primarily by the topic of the vote, will produce a valid λ matrix of issue weights for our modified IRT model. For example, if one had network data describing which votes were on similar issues (Lauderdale and Clark 2012), one could use community detection methods (Porter, Onnela, and Mucha 2009) to generate a suitable discrete categorization. Given the range of metadata on votes that exists across institutions, our approach is potentially applicable to most existing roll–call data sets: any voting data for which there are a set of substantively relevant documents associated with the votes, such as recorded debates, bills, court opinions, treaties, and resolutions. This methodology will be especially useful for the study of small voting bodies like the Supreme Court, where estimating typical multidimensional models is difficult because there are not enough observations for each vote. Our approach will also be especially useful for highly multidimensional voting bodies like the European Parliament (Hix, Noury, and Roland 2006). In a voting body like the U.S. Congress, there is less variation to describe beyond the first dimension (Poole and Rosenthal 1997), but even in Congress there are some legislators who are not fit well by a unidimensional model because their preferences vary across different issues (Lauderdale 2010).         "
"57","In our analysis of the U.S. Supreme Court, we have documented not only the extent to which different subjects have dominated the Court's docket over time, but also how the justices' preferences have systematically varied across those issues. Political scientists have collected a wide range of roll–call data over the past two decades and characterized one or two aggregate dimensions of conflict in many voting bodies. By leveraging metadata about votes and the increasing variety of classification techniques, we can more richly describe political cleavages."
