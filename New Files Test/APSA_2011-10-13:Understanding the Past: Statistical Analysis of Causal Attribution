"","x"
"1","Causal inference is an important goal of social science. Scholars in various disciplines seek to uncover causal relationships underlying social phenomena. Although more basic, descriptive inferences are often of immediate concern in empirical research, political science theories usually go beyond pure description and make statements about how social entities and phenomena are causally related with each other. Some may also argue that prediction is the ultimate goal of any scientific discipline, but good predictive inference typically requires sufficient understanding of underlying causal relationships."
"2","However, the meaning of something being “causal” is often not made explicit in applied studies. For example, what does it exactly mean that x causes y? Is it different from x having a positive causal effect on y? Indeed, there are numerous types of causal questions one can ask about a given set of variables, and one must choose appropriate methods to analyze different types of causal hypotheses. Below, I focus on one of these possible causal hypotheses which has been substantively important, but methodologically almost neglected, in the field of political science.         "
"3","A causal hypothesis in political science often takes the following simple form: “x was a cause of y,” or equivalently, “x caused y.” This type of question typically arises when a researcher seeks to explain the reason a past event happened. For example, in comparative politics, one long‐standing question is why some third‐world countries successfully became democracies after World War II while many others did not. To answer this question, some argue that a sufficient level of economic development was a major cause of democratization (e.g., Lipset 1959; Przeworski et al. 2000), while others maintain that cultural and religious changes played a more important causal role in some cases (Huntington 1991). In American politics, scholars are interested in whether a particular irregularity in the 2000 presidential election, such as a butterfly ballot (Wand et al. 2001) or miscounted overseas absentee ballots (Imai and King 2004), caused the victory of George W. Bush.            "
"4","But what does this statement exactly mean? As demonstrated by the long history of philosophical literature (e.g., Hempel 1965; Hume 1739; Mackie 1965; Mill 1843), a cause can be defined in various ways. However, one widely accepted definition is the one based on counterfactuals, which has origins in both analytic philosophy (Lewis 2001) and statistics (Neyman 1923). Under this framework, causality is defined via counterfactual events, or what would have happened if a certain event had been absent. In recent years, this definition has become increasingly popular among both statisticians and applied researchers. Indeed, the introduction of counterfactuals to statistics has spawned various methods for both randomized experiments (e.g., Fisher 1971) and observational data (e.g., Rosenbaum 2002) to discover causal relationships. The empirical applications of these methods are too numerous to be listed here. Moreover, the advantages of the counterfactual account of causation are also widely recognized in the philosophical literature (e.g., Halpern and Pearl, 2005a, 2005b; Hitchcock and Woodward 2003; Menzies and Price 1993; Price 1991; Woodward 2003).            "
"5","From the counterfactual viewpoint, x is said to have caused y when y would not have happened had x been absent. That is, an event was a cause of another event when the absence of the former would also have implied the absence of the latter. In fact, this is often precisely the way many social scientists conceptualize a causal relationship, either implicitly or explicitly. For example, Huntington states that “if it were not for the changes within the Catholic Church and the resulting actions of the Church against authoritarianism, fewer third wave transitions to democracy would have occurred and many that did occur would have occurred later” (1991, 85, emphasis added). Similarly, Wand et al. summarize their main conclusion in the following way: “Had [Palm Beach County] used a ballot format in the presidential race that did not lead to systematic biased voting errors, our findings suggest that, other things equal, Al Gore would have won a majority of the officially certified votes in Florida” (2001, 803, emphasis added). Indeed, as Fearon (1991) pointed out, political scientists routinely engage in this type of counterfactual reasoning when they make causal claims about past phenomena.1"
"6","To formalize this notion of causality, I use the notation based on the potential outcomes model of causal inference (Holland 1986; Neyman 1923; Rubin 1974). Let Xi∈{0, 1} be a binary variable representing either the presence (Xi= 1) or absence (Xi= 0) of a condition or an event for unit i. This variable will also be referred to as the treatment, following the convention. Next, I consider the following two binary variables denoting the potential outcomes for each unit: Yi(1) ∈{0, 1}, which represents whether the outcome, or the event of interest, would have occurred (Yi(1) = 1) or would not have occurred (Yi(1) = 0) with the presence of condition x, and Yi(0) ∈{0, 1}, which denotes the same event without the presence of x.2 Then, based on this notation, it can be said that for unit i who actually experienced both x and y (i.e., Xi=Yi= 1), x was a cause of y if and only if Yi(0) = 0. It is important to note that the presence of x here is a necessary condition for the occurrence of yfor this particular unit i, holding other preexisting conditions constant.3"
"7","Although identifying this type of cause for particular units is often the ultimate goal of empirical research, it is usually not possible without making very strong assumptions. This is primarily because, by definition, one can only observe the actual outcome, Yi=Yi(Xi), for each unit and never observe the conterfactual outcome, Yi(1 −Xi). Thus, instead of seeking to provide a causal explanation for a particular unit, it is necessary to modify the causal question and focus on an alternative quantity of interest. Particularly natural is to examine the probability of causal attribution defined as               "
"8","The rest of this article is focused on the question of how we can make valid inferences about the probability of causal attribution, as defined in equation (1), using observed data. In principle, the identification of pA faces the same problem as that of a unit‐level causation since the former quantity still refers to the counterfactual outcome. However, it can be shown that this probability can be identified by observed data under less restrictive sets of assumptions, as I discuss in the analytical section below.            "
"9","Before analyzing the problem of causal attribution, it is worthwhile to clarify the differences between this concept and causal effects. Attribution and effects are quite distinct causal concepts, though they are of course closely related5 (Table 1). While causal attribution is defined at the unit level by whether the event y would still have occurred in the hypothetical absence of x, a causal effect is typically defined by the change in the value of Yi induced by the hypothetical manipulation of Xi. That is, x is said to have a causal effect on y for unit i when Yi(1) −Yi(0) ≠ 0. As further explained below, an important difference between the causal effect and causal attribution is that the former is defined for any unit in the population regardless of the actual value of Yi, whereas the latter can be conceptualized only for those who actually experienced both x and y, i.e., Xi=Yi= 1.            "
"10","Although political scientists often posit causal hypotheses in the form of causal attribution, they routinely use quantitative methods that do not have direct correspondence to these hypotheses. In particular, a vast majority of standard tools for causal inference are for the estimation of causal effects, instead of causal attribution. For example, a typical causal estimand in both experimental and observational studies is the average treatment effect (ATE) of x on outcome y, which is defined as               "
"11","It is well known that the standard tools of causal inference, such as randomized experiments and covariate adjustments for observational data, are often well suited to estimating these causal effects. For example, the difference‐in‐means estimator is unbiased for the ATE in a randomized experiment (Rubin 1974), and in an observational study one can consistently estimate the ATE via a linear regression of Yi on Xi and a set of pretreatment covariates when the strong ignorability assumption is satisfied (Freedman 2008; Rubin 1977). Moreover, the ATT is typically the estimand of a matching estimator, such as propensity score matching (Rosenbaum and Rubin 1983). Thus, when one uses any of these standard techniques to draw a causal conclusion, it is causal effects that are being estimated.            "
"12","The differences between causal attribution and effects are not only mathematical or semantic, but also substantive and practical. The probability of causal attribution is defined as the conditional probability of the absence of the outcome in the hypothetical absence of the treatment (Yi(0) = 0) given the actual presence of both (Xi=Yi= 1). The target of inference here is thus the subpopulation to which the outcome of interest in fact occurred. This implies that the probability of causal attribution is of most interest when this subpopulation is clearly identified, i.e., when the event y already happened in the past. Thus, causal attribution is of particular relevance when one’s interest is in explaining past phenomena.            "
"13","In contrast, estimating the ATE corresponds to estimating the magnitude of the impact of a hypothetical intervention to the population, regardless of the actual outcome that would result without the intervention. Such an inference is most meaningful when one can think of implementing this type of intervention as a real possibility, as opposed to a pure thought experiment. One such example in social science is the use of a natural experiment or randomized field experiment when a researcher seeks to estimate the likely effect of implementing a particular policy, such as an increase in the minimum wage (Card and Krueger 1994) and the use of telephone calls as opposed to mailing in get‐out‐the‐vote campaigns (Gerber and Green 2000). Thus, while causal attribution is useful for understanding the past, causal effects have more relevance to questions which involve the possibility of future interventions.            "
"14","The discussion in the previous paragraphs sheds light on the important methodological debate regarding whether one should “select on the dependent variable.” When one’s interest is in explaining past events, a common practice is to study only cases where these events actually happened. This type of research design is particularly prevalent in qualitative comparative studies (e.g., Porter 1998) but can also be found in large‐n studies (e.g., Pape 2003). The current wisdom of political methodology strongly recommends against such a practice. Because studying only positive cases represents an extreme example of selection bias, the estimates of causal effects based on such samples will be seriously biased (Ashworth et al. 2008; Geddes 1990; King, Keohane, and Verba 1994). However, this advice is often received with bewilderment by applied researchers to whom the only “universe of a phenomenon” that is relevant is positive cases (Pape 2008).            "
"15","From the proposed perspective, the motivation for selecting on the dependent variable stems from the researcher’s interest in causal attribution. When one is interested in explaining why past events happened, the goal is to make an inference about whether these particular events would not have happened in the absence of the hypothesized cause. Focusing on these positive cases thus appears to be reasonable, as some researchers have argued (Collier, Mahoney, and Seawright 2004; Pape 2008). However, while it is perfectly reasonable to set one’s population of interest based on the dependent variable, it does not imply that one can also sample based on the dependent variable. As will become clear in the next section, a representative sample from the entire population is still necessary even when one’s direct interest is in the population of positive cases, because the negative cases must be used to make inferences about counterfactual outcomes of the positive cases. Thus, the standard recommendation against selection on the dependent variable is also valid for estimating causal attribution, even though the original argument was made for inferences about causal effects. This highlights the importance of making a clear distinction between estimands (i.e., quantities being estimated) and estimators (i.e., statistics used for estimation) in causal inference.            "
"16","The potential outcomes model of causal inference provides a useful methodological framework for analyzing causal attribution. However, this counterfactual nature of the proposed approach also leads to an important challenge. Under the current binary setup, a researcher can only identify either Yi(0) or Yi(1) as a realization of the potential outcome from the observed data for each i. Because of this “fundamental problem of causal inference” (Holland 1986), it is generally impossible to directly compute a unit‐level causal quantity (e.g., the first row of Table 1) from the observed information.         "
"17","Thus, an important question is how much we can learn about a causal quantity of interest from the observed data alone before making any statistical or functional form assumptions about the underlying causal process. Nonparametric identification analysis, as advocated by Manski (1995, 2007), seeks to answer this question by formally deriving the bounds within which the quantity of interest is guaranteed to be located.6 By deriving these nonparametric bounds under various sets of assumptions, the identification analysis can formally characterize the role of each assumption in the inferential process. In this section, I use this approach to explore the sets of assumptions which allow for meaningful inferences about the probability of causal attribution.         "
"18","Before presenting the main analytical results of this article, I briefly review the existing identification results by Pearl (1999), which, among others, specify a set of assumptions for identifying the probability of causal attribution. The key result is that the same assumption that is sufficient for the identification of the ATE also partially identifies the probability of causal attribution, although an additional assumption is necessary for its full identification.            "
"19","It is widely known that the ATE given in equation (2) and related causal effects (e.g., ATT) can be fully identified when the following assumption is satisfied.            "
"20","Assumption 1 (Exogeneity)                     "
"21","Theorem 3.1 (Pearl, 1999).   Under Assumption 1, the probability of causal attribution has the following sharp upper and lower bounds.                                    "
"22","Relatedly, Tian and Pearl (2000) derive sharp bounds on pA for the situation where Assumption 1 does not hold in the population, but one can also obtain experimental data by randomly assigning Xi and combine them with the observational data. They show that the resulting bounds with the combined data are tighter than those with the experimental data alone. Researchers should thus use their bounds instead of those in equation (3) if such data are available. In practice, however, only in rare circumstances can one randomly manipulate the causal variable of interest, as well as obtaining observational data on the same population.7 This article therefore focuses on the more realistic bounds in Theorem 3.1 where researchers must rely on control variables Wi to ensure the exogeneity of Xi.               "
"23","To draw stronger conclusions about causal attribution, one needs to impose more stringent assumptions about the causal relationship between x and y. Pearl (1999) considers the assumption that the effect of x on y is nonnegative for every unit in the population, which can be stated as follows.               "
"24","                  "
"25","He then proves that Assumptions 1 and 2 are sufficient to identify the probability of causal attribution. The resulting expression for pA is given in the following theorem.               "
"26","Theorem 3.2 (Pearl, 1999).   Under Assumptions 1 and 2,                  pA                  is identifiable and given by                                    "
"27","Rosenbaum (2001) also derives the same expression under the same assumptions. This result implies that in order to fully identify the probability of causal attribution, one must make the rather strong assumption that x can only affect y in one direction for every unit, in addition to the exogeneity assumption. Thus, causal attribution is more difficult to identify than causal effects.               "
"28","Nevertheless, it is noteworthy that the quantity in equation (4) coincides with the lower bound of Theorem 3.1. This implies that, even when Assumption 2 is not entirely plausible, the estimated probability of causal attribution based on equation (4) is never greater than the true value of pA (provided, of course, that Assumption 1 is satisfied) after taking into account sampling variability. This result is useful when one is specifically interested in the least possible proportion of the units for which the (hypothetical) absence of x would have prevented the (actual) occurrence of y. One example of such a situation is when one’s aim is to test whether x was a necessary cause of y for the entire population, i.e., pA= 1.               "
"29","Estimation and statistical inference To apply these identification results to empirical data, it is necessary to estimate the population quantities like equations (3) and (4) from a random sample. For empty Wi, estimation of these quantities is straightforward; one can first estimate the conditional distributions of Yi given Xi=x for x= 0, 1 using their sample analogues, and then substitute these estimates to obtain a consistent estimate of the whole expression.               "
"30","When Wi is nonempty, the population bounds on pA can be obtained by adding the conditioning on Wi to all the probabilities in each expression and taking the population average of the entire expression over the distribution of Wi.8 Then, to estimate these bounds using a random sample, one can in principle compute the bounds for each stratum defined by Wi and then take the weighted average of these values across the strata. In practice, however, this fully nonparametric subclassification approach is often infeasible because Wi is high‐dimensional and/or Wi contains continuous or near‐continuous variables. Thus, one must typically rely on some semi‐parametric or fully parametric estimation techniques. Fortunately, the expressions in Theorems 3.1 and 3.2 have a form particularly suited for such estimation procedures. Since all the components are conditional probabilities of Yi given Xi and Wi, they can all be estimated by standard regression models, such as logit, probit, or linear probability models. It is also straightforward to use other balancing techniques, such as propensity score matching, subclassification, or weighting procedures. The empirical section of this article provides some examples.               "
"31","The estimation of statistical uncertainty is slightly more complex. When the probability of causal attribution is point identified under Assumptions 1 and 2 and given by equation (4), one can estimate its variance via standard procedures, such as the Delta method and simulation‐based approaches. For example, Cai and Kuroki (2006) derive an approximate variance of equation (4) based on the Delta method for the case where Wi is empty. In the empirical applications, I use confidence intervals based on bootstrap standard errors.               "
"32","For the sharp bounds under Assumption 1 (i.e., equation 3), the computation of confidence intervals is more complicated because the true value of pA can be located anywhere within the interval. The literature divides into two approaches, depending on whether to focus on the confidence regions that cover the entire bounds (e.g., Chernozhukov, Hong, and Tamer 2007; Imai and Soneji 2007) or those that contain the true value with a certain confidence level (see Tamer 2010, for a recent review). In the empirical applications in this article, I use the symmetric and uniformly convergent confidence interval by Imbens and Manski (2004).               "
"33","The findings of Pearl (1999) show that the probability of causal attribution is identifiable under the assumptions of exogeneity (Assumption 1) and monotone treatment effect (Assumption 2). A natural question, then, is whether these assumptions are plausible in applied studies in political science. Unfortunately, both assumptions are often dubious in situations where researchers are interested in causal attribution. First, Assumption 1 requires either that the condition x be effectively random (in which case the conditioning set Wi would be empty) or that there be no omitted variable that affects both x and the outcome y (i.e., Wi includes all such variables). Since in typical observational studies x cannot be viewed as randomly assigned (but see the first empirical example, which is based on a natural experiment), and it is difficult, if not impossible, to collect sufficient information about suspected confounders, the exogeneity assumption is likely to be violated in many situations. Second, Assumption 2 requires that the researcher a priori knows that x can never affect y negatively for every unit in the population. Although this assumption may be reasonable in some situations, many applied researchers are likely to be uncomfortable about such a strong statement, particularly because the quantity of interest itself concerns the causal relationship between x and y.            "
"34","Thus, an important question is whether one can make any progress without making these rather strong assumptions. In this section, I extend the findings by Pearl (1999) to the important case where exogeneity does not hold but there is an instrumental variable which satisfies a standard set of assumptions. In many fields of social science, using an instrumental variable has become a common identification strategy in observational studies where the exogeneity assumption is likely to be violated (Sovey and Green 2011). Here, I consider the three assumptions about the nature of a binary instrumental variable (IV), Zi, that were originally introduced by Angrist, Imbens, and Rubin (1996). They prove that these assumptions have to be made in order to interpret standard IV estimators, such as the two‐stage least squares (2SLS) estimator, as estimating causal effects (Angrist and Imbens 1995; Imbens and Angrist 1994). Below I show that these standard IV estimators can also be used to estimate causal attribution under the same set of identifying assumptions.9"
"35","Assumptions Following Angrist, Imbens, and Rubin (1996), I first introduce additional notation to incorporate an instrumental variable into our statistical framework. Let Xi(z) be the potential treatment status for unit i when the unit receives z as the value of the instrument. Similarly, we denote by Yi(z, x) the potential outcome for unit i when the unit receives x and z for the treatment and instrumental variable. Then the observed value of the treatment and outcome can be written as Xi=Xi(Zi) and Yi=Yi(Zi, Xi(Zi)), respectively. By construction, Zi is a variable that causally precedes both Xi and Yi and potentially has causal effects on these variables.               "
"36","With this notational framework, I can now state the three assumptions. First, I assume that the assignment of Zi is exogenous with respect to the potential outcomes and the potential treatment status, possibly after controlling for observable pretreatment confounders. Formally, this assumption can be stated as               "
"37","Assumption 3 (Exogeneity of the Instrument)                     "
"38","Second, I assume that Zi can affect Yi only through its effect on Xi. Formally, we write this assumption as               "
"39","Assumption 4 (Exclusion Restriction)                     "
"40","This assumption says that the potential outcomes are invariant to changes in the value of Zi as long as the treatment Xi stays at the same level. Under this assumption, the potential outcome no longer directly depends on the value of Zi and thus can be rewritten simply as Yi(x), x∈{0, 1}.               "
"41","Finally, I assume that the instrument cannot affect the treatment status in the negative direction. Formally,"
"42","                  "
"43","Under this assumption, the instrument can only encourage the units to receive the treatment. Below I examine the consequences of these three assumptions for the identification of causal attribution."
"44","Identification for compliers Under the current binary setup, the units can be categorized into four distinct causal types, or principal strata (Frangakis and Rubin 2002), based on the potential response of their treatment status to the instrumental variable. First, there are units whose treatment values are positively affected by the instrumental variable, i.e., Xi(1) = 1 and Xi(0) = 0, or more concisely Xi(z) =z for z∈{0, 1}. These units are called compliers (Angrist, Imbens, and Rubin 1996). Second, there are units who would always be in the treatment condition regardless of the value of the instrument (Xi(1) =Xi(0) = 1) and also units who would always be in the control condition (Xi(1) =Xi(0) = 0). These types are called always‐takers and never‐takers, respectively. Finally, there are units, called defiers, whose treatment is negatively affected by the instrument (Xi(1) = 0 and Xi(0) = 1). By Assumption 5, there exists no defier in the case currently being considered.               "
"45","Angrist, Imbens, and Rubin (1996) show that under Assumptions 3, 4, and 5, the average causal effect on compliers can be identified from the observed information. Here I focus on an analogous quantity of interest, the complier probability of causal attribution, which is defined as follows:                  "
"46","This quantity differs from the probability of causal attribution only in that it additionally conditions on the fact that unit i is a complier. Thus, pC represents the proportion of the compliers to whom the hypothetical presence of x would have prevented the outcome y from happening. This implies that the conclusions based on this quantity may not generalize to the entire population because the compliers may be systematically different from the rest of the population with respect to their response to the treatment. Although it is an important limitation of the proposed methodology, the lack of external validity in exchange for internal validity is a common feature of any identification strategy based on an instrumental variable.               "
"47","It can be shown that under Assumptions 3, 4, and 5, the complier probability of causal attribution can be partially identified and the sharp bounds can be expressed in a closed form. The result is summarized in the following proposition."
"48","Proposition 1 (Sharp Bounds on pC with an Instrumental Variable)  Under Assumptions 3, 4, and 5, the sharp bounds on the complier probability of causal attribution can be given as                                    "
"49","A proof is given in Appendix A.1. Proposition 1 shows that if an instrumental variable is available, it is possible to make a valid inference about the complier probability of causal attribution without either Assumption 1 or Assumption 2, although the probability is only identified up to the large‐sample bounds given in equation (9). Analogously to Theorem 3.1, the lower bound is informative if and only if the complier average treatment effect (Angrist, Imbens, and Rubin 1996) is greater than zero, implying that a positive causal effect translates into some degree of causal attribution. The upper bound is identical to that of Theorem 3.1, even though Assumption 1 is now violated. Although Proposition 1 shows that the point identification is not possible without making additional assumptions, these bounds are often narrow enough to draw substantively interesting conclusions about causal attribution; the last empirical application of this article provides such an example.               "
"50","Next, I consider the situation where in addition to Assumptions 3, 4, and 5 one can assume that the effect of the treatment on the outcome is also nonnegative, i.e., Assumption 2. The consequence of this additional assumption is substantial; in fact, one can now fully identify the complier probability of causal attribution. The result is given in the following proposition.               "
"51","Proposition 2 (Identification of pC with an Instrumental Variable)  Under Assumptions 2, 3, 4, and 5, the complier probability of causal attribution defined in equation (8) can be point identified and given by                                    "
"52","A proof is provided in Appendix A.2. Proposition 2 states that if one is willing to make the additional assumption of monotone treatment effect, i.e., Assumption 2, the proportion of the compliers for whom the outcome can be causally attributed to the treatment is point identified and thus can be consistently estimated from observed information. Here again, an analogy can be made between this proposition and Theorem 3.2; in both cases, adding Assumption 2 to the set of assumptions that identifies average causal effects is sufficient to further identify the probabilities of causal attribution."
"53","Another interesting connection with earlier results is that pC here is identified as the complier average treatment effect (Angrist, Imbens, and Rubin 1996) divided by , whereas pA in Theorem 3.2 is identified as the ATE divided by the same probability. Finally, equation (10) coincides with the sharp lower bound given in equation (9). This implies that even if Assumption 2 is in fact violated, the estimate based on Proposition 2 will never overestimate the true complier probability of causal attribution. Thus, by reporting the point estimates on the basis of equation (10), one is always conservative about the degree of causal attribution.               "
"54","Identification for the population So far, my discussion has focused on the group of compliers, a particular subset of the population from which an observed sample is drawn. As mentioned earlier, this implies that the substantive conclusions based on Propositions 1 and 2 may not be generally applicable for the entire population. Thus, an important question is whether one can learn anything about causal attribution for the population as a whole when an instrumental variable is available.               "
"55","To address this question, I derive the nonparametric bounds for pA, the original probability of causal attribution given in equation (1), under the same two sets of assumptions as Propositions 1 and 2. The results are summarized in the following propositions.               "
"56","Proposition 3 (Sharp Bounds on pA with an Instrumental Variable)  Under Assumptions 3, 4, and 5, the identification region of the probability of causal attribution is characterized by the following sharp bounds:"
"57","                  "
"58","Proposition 4 (Sharp Bounds on pA with an Instrument and Monotonicity)  Under Assumptions 2, 3, 4, and 5, the identification region of the probability of causal attribution is characterized by the following sharp bounds:                                    "
"59","These two propositions formally characterize the identification regions of the probability of causal attribution under the alternative sets of assumptions. Proofs are given in Appendix A.3. Proposition 3 shows that observed information is completely uninformative about the upper bound of pA even when there is an instrumental variable; we can never exclude the possibility that the hypothetical absence of x would have prevented the outcome for all units with Xi=Yi= 1. On the other hand, the lower bound may or may not be informative. Proposition 4 shows that the lower bound of pA is always informative (i.e., greater than zero) when Assumption 2 is additionally made, whereas the upper bound may or may not be less than one.               "
"60","In practice, these bounds are often too wide to be meaningful in substantive terms. The empirical study in the next section provides such an example. Nevertheless, even this kind of limited information about the probability of causal attribution may be useful for answering particular research questions. For example, suppose one’s interest is in testing whether x was a necessary cause of y, i.e., whether y would never have happened had x been absent. Then it suffices to know that pA is statistically indistinguishable from one, and thus the information about its upper bound based on equation (12) may prove to be enough to reject this hypothesis. Here again, specifying one’s causal hypothesis of interest is essential for causal inference.               "
"61","Estimation and statistical inference To estimate these large sample bounds from an observed sample, one can essentially follow the same strategies as those discussed in the previous section. The first step is to estimate the conditional distributions of Xi given Zi and also Yi given Xi, possibly also conditional on observable covariates Wi, just as one would do in a standard IV estimation procedure. A typical example is to use 2SLS, where in the first stage Xi is linearly regressed on {Zi, Wi} and in the second stage Yi is regressed on the fitted values from the first regression as well as Wi to correct the bias. Alternatively, one can use binary response models such as logit or probit to model these conditional distributions.               "
"62","Next, it is also necessary to estimate , which can be achieved by either combining the estimates of  and  for x, z∈{0, 1} from the previous step or by fitting a reduced form regression of Yi on Zi (and possibly also on Wi and averaging over the empirical distribution of Wi; Tan 2006). The marginal distribution of Zi, which is also needed to compute the quantities of interest, can be estimated simply by its sample analogue. Finally, these estimated quantities can be substituted into the corresponding probabilities in equations (9), (10), (11), and (12) to produce plug‐in estimators of the desired quantities. For uncertainty estimates, one can use the bootstrap approach as in the previous case. I apply these procedures to an empirical example on voter turnout and education at the end of the next section.               "
"63","In this section, I apply the proposed methods for the identification of causal attribution to empirical problems from various subfields of political science. First, I examine a natural experiment where successful assassinations of political leaders are considered to have occurred randomly (Jones and Olken 2009). Next, I investigate a typical observational study from the so‐called democratic peace literature (Oneal and Russett 2001), where regression adjustments are used to control for possible observable confounders. Finally, I apply the new identification results with an instrumental variable in the previous section to revisit the study of education and voter turnout by Milligan, Moretti, and Oreopoulos (2004).         "
"64","Political leadership is a contentious but somewhat understudied topic in political science. Some scholars have emphasized the roles national leaders can play in determining institutional and policy outcomes in various contexts (e.g., Allison 1971; Greenstein 2004). To study the effect of leadership, researchers face a serious endogeneity problem; that is, while changes in leadership may affect the various societal characteristics, these changes themselves are often consequences of changes in the society. Jones and Olken (2009) use a novel approach to partially cope with this major methodological challenge. They argue that because whether an assassination attempt on a political leader will succeed or fail is essentially randomly determined, they can exploit this inherent randomness as a natural experiment to isolate the effect of leadership on various outcomes. To estimate the causal effects of successful assassinations, they collect data on all publicly reported assassination attempts for all national leaders since 1875. They then analyze these data to see whether a successful assassination increases the probability of regime transition and the intensity of conflicts.            "
"65","In this section, I follow the identification strategy of Jones and Olken (2009) to estimate the probability of causal attribution (pA) for regime transition. This alternative quantity is of particular interest given the context of the study. The original authors estimate the average causal effects of successful assassination by employing both parametric and nonparametric specifications. In this context, these causal estimands correspond to the expected difference in regime type (i.e., democracy or autocracy) that would realize between hypothetical successful assassinations and unsuccessful ones. While estimating such a quantity would be useful for predicting the impact of assassinating a leader, it may not directly interest political scientists or historians who are primarily concerned with explaining why past regime transitions happened. As discussed earlier, the probability of causal attribution addresses this question because it represents the proportion of those actual regime transitions that would not have happened without successful assassinations.            "
"66","To estimate pA for successful assassination and regime transition, I employ the estimation procedure explained in the previous section. More specifically, I first estimate the conditional probability of regime transition as a function of the successful assassination indicator, using the same parametric model as the original study.10 Then the identification regions of pA are calculated for different sets of identification assumptions based on the estimated coefficients as well as equations (3) and (4). Finally, confidence intervals are computed using the nonparametric bootstrap with 2,000 resamples and the procedure of Imbens and Manski (2004). The results are presented in Figure 1.            "
"67","                Assassination of Political Leaders and Regime Change                            Note: The pair of vertical lines in each plot represents the identification regions for the probability of causal attribution (pA) under Assumptions 1 and 2 (solid circle on the left) and under Assumption 1 alone (thick bar on the right) along with their 95% confidence intervals (thin solid lines). The left panel shows the estimated probabilities that the regime changes observed after the assassinations of political leaders would not have happened had the assassination attempts failed. The right panel breaks down the estimated pA for successful assassination and democratic transition by the tenure of the assassinated leader and by the time since the assassination. For a full description of the coding scheme for these groupings, see Jones and Olken (2009). The results suggest that more than 75% of these democratic transitions can be causally attributed to the assassinations. The proportion is particularly large for the short‐run moves to democracy following the assassination of long‐tenured autocrats.                        "
"68","In each panel of Figure 1, the point estimate of pA under both exogeneity (Assumption 1) and monotone treatment effect (Assumption 2) is presented on the left, while the sharp bounds under Assumption 1 alone are given on the right, both along with the 95% confidence intervals. The left panel shows the estimates for all types of regime changes pooled together, democratic transitions, and autocratic transitions (from left to right). The results suggest that under the assumption that the success or failure of an assassination attempt is essentially random (Assumption 1), at least 63%, and possibly all, of the regime transitions following the assassination of national leaders would not have occurred if the leader had survived the attempt. The 95% confidence interval for this estimate is relatively wide but does not cover zero ([0.272, 1]), implying that a significant fraction of these past regime changes would have been prevented had the assassinations been unsuccessful. In addition, if it is also assumed that successful assassination cannot prevent the regime transition that would otherwise have happened, pA is point identified and equals the previous lower bound (0.630). The 95% confidence interval is still relatively wide ([0.204, 1]) but again does not cover zero.11 Moreover, the estimated pA dramatically increases when I focus on the democratic transitions. The lower bound under Assumption 1 (or equivalently the point estimate under Assumptions 1 and 2) is estimated to be 0.757, with the 95% confidence interval of [0.433, 1] ([0.376, 1]). Thus, a large majority of the past democratic transitions can be causally attributed to the preceding assassinations of the autocrats.            "
"69","To analyze the past democratic transitions in greater detail, the nine plots on the right decompose them on the basis of the tenure of the assassinated leaders and the duration of the new regimes. The results show that the probability of causal attribution is particularly high for the short‐run moves to democracy following the assassination of long‐tenured autocrats (upper‐right panel). Indeed, at least 84% of these democratic transitions would not have happened if the assassination attempts had failed. However, the same cannot be said for relatively new autocrats who were assassinated with fewer than 10 years of tenure (upper middle panel), as the confidence intervals essentially cover zero ([0, 1] for the point estimate and [0.062, 1] for the bounds). Interestingly, for the democracies whose former autocratic leaders were assassinated 10 years ago (middle row), pA is estimated to be roughly the same regardless of tenure. Finally, the bounds and confidence intervals are both wide and uninformative in the three panels on the bottom; this indicates, not surprisingly, that it is rather difficult to trace the cause of established democracies back to the assassinations that occurred 20 or more years ago.            "
"70","A major question in the literature of international security is whether democratic institutions are preventive of militarized international disputes (MIDs). Although this causal hypothesis has been posited in various specific forms, including sufficiency (Russett 1995) and causal effects (e.g., Maoz and Russett 1993), an interesting question is what proportion of the past MIDs could have been prevented by democratic institutions. In a famous quantitative study, Oneal and Russett (2001) used data on all state dyads that existed between the period of 1886–1992 to show that democracy has a strong negative effect on the probability of the onset of a MID after controlling for various covariates, contrary to the claim by Green, Kim, and Yoon (2001).            "
"71","By regressing MID onsets on democracy and other control variables and computing the marginal effects of democracy, Oneal and Russett (2001) and Green, Kim, and Yoon (2001) are implicitly making an inference about the causal effect of democracy on the probability of MID onset. As discussed earlier, this corresponds to the causal question of what would have been the impact of hypothetical intervention to the level of democracy at each time point of the past period covered by this dataset. While this quantity may well be of substantive interest, an alternative, perhaps more directly relevant, question is what percentage of the actually observed MIDs was causally attributable to the absence of democratic institutions. Thus, an interesting analysis is to estimate pA using this dataset. Throughout the analysis, I maintain the exogeneity assumption as in the original study.12"
"72","Figure 2 reports the estimated probability of causal attribution under the exogeneity and monotone treatment effect assumptions (Assumptions 1 and 2) as well as just under exogeneity (Assumption 1). Since democracy here is measured by the Polity score, which is a discrete scale ranging from −10 to 10, I used values from 0 to 10 as the threshold for a dyad to be defined as democratic and then calculated the probability of causal attribution for each of these coding schemes. Based on the whole period covered by the dataset (1886 to 1992, top panel), the probability of causal attribution under Assumptions 1 and 2 (or equivalently, the lower bound of this quantity under Assumption 1 alone) almost monotonically increases as we change the threshold for democracy from low to high, with a possible exception of the thresholds at 6 and 7. That is, when the comparison is between dyads with a Polity score less than zero and those greater than or equal to zero, the estimated probability is at least 0.482 with the 95% confidence interval of [0.323, 0.641]. This means that about 48.2% of the observed MIDs among the dyads in the first group would not have happened had those dyads switched to the latter category. Furthermore, this probability sharply increases as we shift the reference of comparison to more restrictive sets of democracies. Indeed, when the threshold is set at the standard defined by the Polity IV Project (6 or higher), the estimated probability of causal attribution becomes about 0.676 with the confidence interval of [0.580, 0.772], and the probability jumps to as high as about 0.768 with the confidence interval of [0.648, 0.888] when only the most developed democracies are used as the comparison group. This implies that, holding every pretreatment condition constant, about 76.8% of the past military disputes (excluding the ones fought between two fully developed democracies) would have been prevented if the states engaged in these disputes had been full democracies. This is indeed a high proportion, even compared to the original estimate of the causal effect by Oneal and Russett (2001) based on the identical model.            "
"73","                Proportion of the Past MID Onsets Attributable to the Lack of Democracy                            Note: In each panel, the horizontal axis represents the values of the Polity score used as the threshold for a dyad to be coded as democratic. The results in the top panel are based on the full dataset while the bottom panel is restricted to the postwar period. For the meaning of the graph components, see the caption of Figure 1. The results suggest that the probability of causal attribution is roughly monotonically increasing as a function of the threshold for both time periods.                        "
"74","One point of contention between Green, Kim, and Yoon (2001) and Oneal and Russett (2001) is whether the effect of democracy had changed after 1951. The results presented in the bottom panel of Figure 2 weakly support this hypothesis, albeit in a nuanced way. When the threshold for democracy is set at relatively low levels (0 to 4), the estimated probability of causal attribution is slightly higher when we focus on the period after 1951, although the confidence intervals for these estimates are rather wide. For example, the difference is as large as 0.116 when the threshold is set at one. That is, for this particular definition of democratic dyads, the MIDs involving nondemocracies became more preventable after 1951 by a margin of 11.6 percentage points. This finding is interesting and also consistent with the earler results by Farber and Gowa (1995). However, this gap effectively vanishes when the threshold is set at levels higher than five.            "
"75","The analysis has so far led to remarkable conclusions, suggesting that many of the past MIDs would have been prevented by democratic institutions. However, one should be careful about these results since they all rest on the crucial assumption of exogeneity (Assumption 1) and also monotone treatment effect (Assumption 2) if one interprets them as point estimates rather than the lower bounds of the probability of causal attribution. Unlike the previous example, which exploited the inherent randomness in the success or failure of assassination attempts, the current example relies on a more tenuous assumption that controlling for the observable covariates included in the model is sufficient to consider the level of democracy to be effectively randomly assigned by nature. This assumption, unfortunately, is difficult to justify. In fact, the original issue raised by Green, Kim, and Yoon (2001) was precisely the possible existence of unobservable confounders in this dataset. In the next example, I consider the situation where one can address this problem with the aid of an instrumental variable.            "
"76","Education has been identified as an important predictor of voter turnout by numerous empirical studies (e.g., Wolfinger and Rosenstone 1980), but whether the observed strong association between education and turnout represents a true causal relationship remains a contentious issue (e.g., Brady, Verba, and Schlozman 1995). Various unmeasured confounders, such as unobservable individual characteristics and environmental factors in which survey respondents are raised, can both increase their educational attainment and probability of voting. To cope with this endogeneity problem, Milligan, Moretti, and Oreopoulos (2004) employ an identification strategy based on instrumental variables.13 Following the approach of Acemoglu and Angrist (2000), Milligan, Moretti, and Oreopoulos use the variation in compulsory schooling laws across the United States as an exogenous encouragement for the citizens to receive different levels of education. They then estimate the causal effects of receiving a relatively high level of education (defined as high school graduation or higher) on various types of civic participation, including voting in the national election held in the year of the survey.14"
"77","While using an instrumental variable is a reasonable strategy to address the endogeneity problem, focusing on causal effects may not be entirely justified depending on the type of causal question one is interested in. For example, one empirical puzzle in the political participation literature is why voter turnout has largely stayed the same (or even declined slightly) in the United States since the 1970s despite the increase in educational levels of the electorate (Abramson and Aldrich 1982; Cassel and Luskin 1988). Because the goal underlying this question is to explain the past levels of turnout, it may be more reasonable to focus on causal attribution and estimate the extent to which citizens’ actual behavior is attributable to their educational levels. More specifically, how likely is it that those who voted would have abstained if they had been less educated? Conversely, what is the probability that the uneducated nonvoters in the past elections would have voted had they been better educated?            "
"78","Here, I apply the new identification results developed in the previous section to answer these questions. I estimate the complier probabilities of causal attribution (pC) for education and turnout for the subpopulation of actual voters and nonvoters, using the state compulsory attendance rules as an instrument. To estimate this quantity, I followed the procedures used in the original study,15 except that I used the estimated model parameters to compute the point and bound estimates of pA and pC (given in Propositions 1, 2, 3, and 4) using the procedure described in the previous section. The results are shown in Figure 3.            "
"79","                Probability of Causal Attribution and Local Average Treatment Effect of Education and Turnout                            Note: The left two panels show the estimated sharp bounds on the probabilities of causal attribution for the population (pA, left two vertical bars) and for the compliers (pC, right two vertical bars) along with their 95% confidence intervals. The first panel shows the proportions of the educated voters who would not have voted if they had been less educated, while the second panel shows the probabilities with which the uneducated nonvoters would have voted if they had been better educated. There is little evidence that the complier probability of attribution differs between the educated voters and the uneducated nonvoters, although it is clearly statistically different from zero for both subpopulations. The estimated complier average treatment effect (the rightmost panel), however, is only marginally significant.                        "
"80","The left two panels present the estimated population (left two bars) and complier (right two bars) probabilities of causal attribution, along with their 95% normal confidence intervals based on the nonparametric bootstrap with 1,000 resamples (and Imbens and Manski’s formula for bounds). Within each pair of vertical bars, the left bar corresponds to the estimate under Assumptions 2, 3, 4, and 5 (Propositions 4 and 2) while the right bar represents the bounds under Assumptions 3, 4, and 5 (Propositions 3 and 1). The first panel shows the probability of attribution for the subpopulation of educated voters, i.e., the proportion of those who would not have voted if they had been less educated. The second panel, in contrast, shows the probability of attribution for uneducated nonvoters, i.e., the probability with which they would have voted if they had been better educated. Finally, for the purpose of comparison, I also include the estimated complier average treatment effect in the rightmost panel. This is the quantity typically reported by empirical researchers when 2SLS is used to estimate the causal effect of a binary treatment (Angrist, Imbens, and Rubin 1996).            "
"81","Figure 3 shows that when the treatment is not exogenous, inference about the population probability of causal attribution is difficult even with the aid of an instrumental variable. The estimated bounds for pA are almost uninformative for the educated voters under either set of assumptions. However, there is some evidence that the probability is positive for the uneducated nonvoters. The estimated bounds for this subpopulation are [0.049, 0.969] ([0.049, 1] without Assumption 2), and their 95% confidence interval does not include zero ([0.046, 0.971]; [0.046, 1] without Assumption 2). This implies that at least about 4.9% of the uneducated nonvoters would have voted if given education better than high school.            "
"82","Inference about compliers, however, is substantially easier. The complier probability of causal attribution represents the degree to which voting (nonvoting) can be causally attributed to education among the educated (uneducated) voters whose education levels would be positively affected by compulsory attendance laws.16 For these groups, there is more evidence that turnout is attributable to education; the estimated pC for the educated compliers who voted is equal to 0.262 under Assumptions 2, 3, 4, and 5 (with the 95% confidence interval of [0.047, 0.478]) and within the bounds of [0.262, 0.703] under Assumptions 3, 4, and 5 (with the confidence interval of [0.081, 0.775]). This implies that at least about 26.2% of the educated complier voters would not have voted had they not received high education.            "
"83","Moreover, these estimates are somewhat larger for the uneducated compliers who actually did not vote; their pC is 0.349 ([0.349, 0.898] without Assumption 5) with the confidence interval of [0.110, 0.588] ([0.148, 0.920]), implying that at least about 34.9% of them would have voted if they had graduated from high school. However, these estimates are not statistically significantly different from those for the educated complier voters. This is substantively interesting because, a priori, the educated voters and uneducated nonvoters have different characteristics and their counterfacutal turnout behavior may well be much different. Finally, the estimated complier average treatment effect is only 0.152. The standard 2SLS causal estimate is thus misleading for inference about causal attribution. Indeed, because this estimate is only marginally statistically significant ([0.009, 0.296]), one may incorrectly conclude that turnout is not causally attributable to education while in fact it is on the basis of the proposed framework.            "
"84","A potential problem in the above analysis is that the compulsory schooling variable may not be an ideal instrument, as previously pointed out by Tenn (2007). If the identification assumptions are violated, the estimates shown in Figure 3 will be biased and invalid. More generally, the availability of good instrumental variables is often a major obstacle in causal inference with observational data. Researchers may find it helpful to supplement the IV‐based analysis with the more traditional approach based on conditional exogeneity (i.e., Assumption 1) in such a situation. For example, Kam and Palmer (2008) collect a large number of covariates that may confound the relationship between education and turnout, such as respondents’ preadult experiences and parental background, and use propensity score matching to estimate the causal effect of education on participation. When such extensive information about pretreatment characteristics is available, the exogeneity‐based approach may provide a viable alternative to the IV approach, especially if coupled with estimation procedures robust to functional form misspecifications (e.g., matching). Those multivariate estimation procedures can be easily incorporated for analyzing causal attribution, as illustrated through the other empirical applications in this section.            "
"85","In this article, I proposed an alternative approach to causal inference in political science. The framework starts from a specific type of causal question commonly asked in the discipline—what proportion of the past events can be attributed to a suspected cause—and defines a quantity of interest that is directly tailored for this type of question. This contrasts with the other methods for causal inference currently employed in social sciences, which are more appropriate for estimating the effect of hypothetical intervention to a causal relationship. The discussion of the differences between these two types of causal quantities also sheds light on a methodological debate about selecting on the dependent variable."
"86","Building on the previous results about the identification of this quantity under the exogeneity assumption, I derived a set of new analytical results for the situation where exogeneity is violated but an instrumental variable is available. Because the exogeneity assumption is often difficult to justify in observational studies, the existing results are limited in their applicability to many empirical problems of interest. In contrast, the results in this article expand the scope of this framework to at least some of these empirical questions. Both the previous and new results were illustrated by three empirical examples from different subfields of political science."
"87","In closing, I emphasize again that the proposed framework should not be considered as a replacement to standard methods for the estimation of causal effects. Rather, the central message of this article is that one should carefully consider the quantity of interest in light of the causal question at hand before diving into such standard analyses. Causal inference is an intricate problem which requires more than a blind application of single methodology, be it regression, matching, experiment, or combinations of those. This article provides a guideline for choosing an appropriate quantity of interest for one’s empirical question, as well as a set of methods for analyzing causal attribution."
